import Accelerate
import AVFoundation
import Combine
import CoreImage
import Foundation
import HaishinKit
import Network
import UIKit
import VideoToolbox
import os.log

extension HaishinKitManager {
  // MARK: - Manual Frame Injection Methods (ìµœì í™”ëœ ë²„ì „)

  /// í”½ì…€ ë²„í¼ ì „ì²˜ë¦¬ (ì‚¬ìš©ì ì„¤ì • í•´ìƒë„ ì •í™•íˆ ì ìš©)
  func preprocessPixelBuffer(_ pixelBuffer: CVPixelBuffer) -> CVPixelBuffer? {
    guard let settings = currentSettings else {
      logger.debug("âš ï¸ ìŠ¤íŠ¸ë¦¬ë° ì„¤ì •ì´ ì—†ì–´ ìŠ¤ì¼€ì¼ë§ ìŠ¤í‚µ")
      return pixelBuffer  // ì„¤ì •ì´ ì—†ìœ¼ë©´ ì›ë³¸ ë°˜í™˜
    }

    let currentWidth = CVPixelBufferGetWidth(pixelBuffer)
    let currentHeight = CVPixelBufferGetHeight(pixelBuffer)

    // ğŸ”§ ì‚¬ìš©ìê°€ ì„¤ì •í•œ ì •í™•í•œ í•´ìƒë„ë¡œ ë³€í™˜
    let targetSize = CGSize(width: settings.videoWidth, height: settings.videoHeight)

    // í•´ìƒë„ê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
    if currentWidth == settings.videoWidth && currentHeight == settings.videoHeight {
      logger.debug("âœ… ì‚¬ìš©ì ì„¤ì • í•´ìƒë„ ì¼ì¹˜: \(currentWidth)Ã—\(currentHeight) - ë³€í™˜ ë¶ˆí•„ìš”")
      return pixelBuffer
    }

    logger.info(
      "ğŸ”„ ì‚¬ìš©ì ì„¤ì • í•´ìƒë„ë¡œ ì •í™•íˆ ë³€í™˜: \(currentWidth)Ã—\(currentHeight) â†’ \(settings.videoWidth)Ã—\(settings.videoHeight)"
    )

    // ì„±ëŠ¥ ìµœì í™” ë§¤ë‹ˆì €ë¥¼ í†µí•œ ê³ ì„±ëŠ¥ í”„ë ˆì„ ë³€í™˜
    if let optimizedBuffer = performanceOptimizer.optimizedFrameConversion(
      pixelBuffer, targetSize: targetSize)
    {
      // ë³€í™˜ ê²°ê³¼ ê²€ì¦
      let resultWidth = CVPixelBufferGetWidth(optimizedBuffer)
      let resultHeight = CVPixelBufferGetHeight(optimizedBuffer)

      if resultWidth == settings.videoWidth && resultHeight == settings.videoHeight {
        logger.debug(
          "âœ… ì‚¬ìš©ì ì„¤ì • í•´ìƒë„ ë³€í™˜ ì„±ê³µ: \(resultWidth)Ã—\(resultHeight) (\(String(format: "%.2f", performanceOptimizer.frameProcessingTime * 1000))ms)"
        )
        return optimizedBuffer
      } else {
        logger.error(
          "âŒ í•´ìƒë„ ë³€í™˜ ê²€ì¦ ì‹¤íŒ¨: ëª©í‘œ \(settings.videoWidth)Ã—\(settings.videoHeight) vs ê²°ê³¼ \(resultWidth)Ã—\(resultHeight)"
        )
      }
    }

    // í´ë°±: ê¸°ì¡´ ë°©ì‹
    logger.warning("âš ï¸ ì„±ëŠ¥ ìµœì í™” ë§¤ë‹ˆì € ì‹¤íŒ¨ - ê¸°ì¡´ ë°©ì‹ í´ë°±")

    // 1ë‹¨ê³„: VideoToolbox ìµœì í™” í¬ë§· ë³€í™˜ (YUV420 ìš°ì„ )
    guard let formatCompatibleBuffer = convertPixelBufferForVideoToolbox(pixelBuffer) else {
      logger.error("âŒ VideoToolbox í¬ë§· ë³€í™˜ ì‹¤íŒ¨ - ì›ë³¸ í”„ë ˆì„ ì‚¬ìš©")
      return pixelBuffer
    }

    let originalWidth = CVPixelBufferGetWidth(formatCompatibleBuffer)
    let originalHeight = CVPixelBufferGetHeight(formatCompatibleBuffer)
    let targetWidth = settings.videoWidth
    let targetHeight = settings.videoHeight

    // ë¹„ìœ¨ ê³„ì‚° ë° ë¡œê¹… ì¶”ê°€ (1:1 ë¬¸ì œ ì¶”ì )
    let originalAspectRatio = Double(originalWidth) / Double(originalHeight)
    let targetAspectRatio = Double(targetWidth) / Double(targetHeight)

    logger.info("ğŸ“ í•´ìƒë„ ë° ë¹„ìœ¨ ê²€ì‚¬:")
    logger.info(
      "   â€¢ í˜„ì¬: \(originalWidth)x\(originalHeight) (ë¹„ìœ¨: \(String(format: "%.2f", originalAspectRatio)))"
    )
    logger.info(
      "   â€¢ ëª©í‘œ: \(targetWidth)x\(targetHeight) (ë¹„ìœ¨: \(String(format: "%.2f", targetAspectRatio)))")

    // 1:1 ë¹„ìœ¨ ê°ì§€ ë° ê²½ê³ 
    if abs(originalAspectRatio - 1.0) < 0.1 {
      logger.warning("âš ï¸ 1:1 ì •ì‚¬ê°í˜• ë¹„ìœ¨ ê°ì§€! Aspect Fillë¡œ 16:9 ë³€í™˜ ì˜ˆì •")
    }

    // ê³ í’ˆì§ˆ ìº¡ì²˜ëœ í”„ë ˆì„ì„ ì†¡ì¶œ í•´ìƒë„ë¡œ ë‹¤ìš´ìŠ¤ì¼€ì¼ë§
    // (480p ì†¡ì¶œì„ ìœ„í•´ 980pë¡œ ìº¡ì²˜ëœ í”„ë ˆì„ì„ 480pë¡œ ìŠ¤ì¼€ì¼ë§)
    if originalWidth != targetWidth || originalHeight != targetHeight {
      logger.info(
        "ğŸ”„ ê³ í’ˆì§ˆ ìº¡ì²˜ â†’ ì†¡ì¶œ í•´ìƒë„ ìŠ¤ì¼€ì¼ë§: \(originalWidth)x\(originalHeight) â†’ \(targetWidth)x\(targetHeight)"
      )
    } else {
      logger.debug("âœ… í•´ìƒë„ ì¼ì¹˜ - ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”")
      return formatCompatibleBuffer
    }

    let finalTargetSize = CGSize(width: targetWidth, height: targetHeight)
    guard let scaledPixelBuffer = scalePixelBuffer(formatCompatibleBuffer, to: finalTargetSize)
    else {
      logger.error("âŒ í•´ìƒë„ ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨ - í¬ë§· ë³€í™˜ëœ í”„ë ˆì„ìœ¼ë¡œ ëŒ€ì²´")
      return formatCompatibleBuffer  // ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨ ì‹œ í¬ë§·ë§Œ ë³€í™˜ëœ ë²„í¼ ë°˜í™˜
    }

    // 3ë‹¨ê³„: ìŠ¤ì¼€ì¼ë§ ì„±ê³µ ê²€ì¦
    let finalWidth = CVPixelBufferGetWidth(scaledPixelBuffer)
    let finalHeight = CVPixelBufferGetHeight(scaledPixelBuffer)

    if finalWidth == targetWidth && finalHeight == targetHeight {
      logger.info("ğŸ‰ í•´ìƒë„ ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ ë° ê²€ì¦ ì„±ê³µ: \(finalWidth)x\(finalHeight)")
      return scaledPixelBuffer
    } else {
      logger.error(
        "âŒ í•´ìƒë„ ìŠ¤ì¼€ì¼ë§ ê²€ì¦ ì‹¤íŒ¨: ëª©í‘œ \(targetWidth)x\(targetHeight) vs ê²°ê³¼ \(finalWidth)x\(finalHeight)")
      return formatCompatibleBuffer  // ê²€ì¦ ì‹¤íŒ¨ ì‹œ í¬ë§·ë§Œ ë³€í™˜ëœ ë²„í¼ ë°˜í™˜
    }
  }

  /// CVPixelBuffer í•´ìƒë„ ìŠ¤ì¼€ì¼ë§ (ê³ í’ˆì§ˆ, HaishinKit ìµœì í™”, VideoCodec í˜¸í™˜ì„± ë³´ì¥)
  func scalePixelBuffer(_ pixelBuffer: CVPixelBuffer, to targetSize: CGSize)
    -> CVPixelBuffer?
  {
    // 16ì˜ ë°°ìˆ˜ë¡œ ì •ë ¬ëœ í•´ìƒë„ ê³„ì‚° (H.264 ì¸ì½”ë” ìš”êµ¬ì‚¬í•­) - ìˆ˜ì •ëœ ë¡œì§
    let requestedWidth = Int(targetSize.width)
    let requestedHeight = Int(targetSize.height)

    // 16ì˜ ë°°ìˆ˜ ì •ë ¬ (í™”ë©´ ë¹„ìœ¨ ìœ ì§€ë¥¼ ìœ„í•´ ë‚´ë¦¼ì°¨ìˆœ ì ìš©)
    let alignedWidth = (requestedWidth / 16) * 16  // ë‚´ë¦¼ ì •ë ¬ (í™”ë©´ ë¹„ìœ¨ ìœ ì§€)
    let alignedHeight = (requestedHeight / 16) * 16  // ë‚´ë¦¼ ì •ë ¬ (í™”ë©´ ë¹„ìœ¨ ìœ ì§€)

    // ìµœì†Œ í•´ìƒë„ ë³´ì¥ (160x120)
    let finalWidth = max(alignedWidth, 160)
    let finalHeight = max(alignedHeight, 120)

    // í•´ìƒë„ ë³€ê²½ ì—¬ë¶€ ë¡œê¹…
    if finalWidth != requestedWidth || finalHeight != requestedHeight {
      logger.info(
        "ğŸ“ í•´ìƒë„ 16ì˜ ë°°ìˆ˜ ì •ë ¬: \(requestedWidth)x\(requestedHeight) â†’ \(finalWidth)x\(finalHeight)")
    } else {
      logger.debug("âœ… í•´ìƒë„ ì´ë¯¸ 16ì˜ ë°°ìˆ˜: \(finalWidth)x\(finalHeight)")
    }

    // HaishinKit ìµœì í™” ì†ì„±ìœ¼ë¡œ í”½ì…€ ë²„í¼ ìƒì„±
    let attributes: [String: Any] = [
      kCVPixelBufferCGImageCompatibilityKey as String: true,
      kCVPixelBufferCGBitmapContextCompatibilityKey as String: true,
      kCVPixelBufferIOSurfacePropertiesKey as String: [:],
      kCVPixelBufferBytesPerRowAlignmentKey as String: 64,  // 16 â†’ 64ë¡œ ì¦ê°€ (ë” ì•ˆì „í•œ ì •ë ¬)
      kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA,
      kCVPixelBufferWidthKey as String: finalWidth,
      kCVPixelBufferHeightKey as String: finalHeight,
    ]

    var outputBuffer: CVPixelBuffer?
    let status = CVPixelBufferCreate(
      kCFAllocatorDefault,
      finalWidth,
      finalHeight,
      kCVPixelFormatType_32BGRA,
      attributes as CFDictionary,
      &outputBuffer
    )

    guard status == kCVReturnSuccess, let scaledBuffer = outputBuffer else {
      logger.error("âŒ CVPixelBuffer ìƒì„± ì‹¤íŒ¨: \(status)")
      return nil
    }

    // Core Imageë¥¼ ì‚¬ìš©í•œ ê³ í’ˆì§ˆ ìŠ¤ì¼€ì¼ë§ (ê°œì„ ëœ ë°©ë²•)
    let inputImage = CIImage(cvPixelBuffer: pixelBuffer)

    // ì •í™•í•œ ìŠ¤ì¼€ì¼ë§ì„ ìœ„í•œ bounds ê³„ì‚°
    let targetRect = CGRect(x: 0, y: 0, width: finalWidth, height: finalHeight)
    let sourceRect = inputImage.extent

    // Aspect Fill ìŠ¤ì¼€ì¼ë§ (í™”ë©´ ê½‰ ì±„ìš°ê¸°, 16:9 ë¹„ìœ¨ ìœ ì§€) - 1:1 ë¬¸ì œ í•´ê²°
    let scaleX = CGFloat(finalWidth) / sourceRect.width
    let scaleY = CGFloat(finalHeight) / sourceRect.height
    let scale = max(scaleX, scaleY)  // Aspect Fill - í™”ë©´ ê½‰ ì±„ìš°ê¸° (1:1 â†’ 16:9 ë¹„ìœ¨)

    let scaledWidth = sourceRect.width * scale
    let scaledHeight = sourceRect.height * scale

    // ì¤‘ì•™ ì •ë ¬ì„ ìœ„í•œ ì˜¤í”„ì…‹ ê³„ì‚° (ë„˜ì¹˜ëŠ” ë¶€ë¶„ì€ ì˜ë¦¼)
    let offsetX = (CGFloat(finalWidth) - scaledWidth) / 2.0
    let offsetY = (CGFloat(finalHeight) - scaledHeight) / 2.0

    let transform = CGAffineTransform(scaleX: scale, y: scale)
      .concatenating(CGAffineTransform(translationX: offsetX, y: offsetY))

    let scaledImage = inputImage.transformed(by: transform)

    // GPU ê°€ì† CIContext ìƒì„± (ê°œì„ ëœ ì„¤ì •)
    let context = CIContext(options: [
      .workingColorSpace: CGColorSpace(name: CGColorSpace.sRGB)!,
      .outputColorSpace: CGColorSpace(name: CGColorSpace.sRGB)!,
      .useSoftwareRenderer: false,  // GPU ì‚¬ìš©
      .priorityRequestLow: false,  // ê³ ìš°ì„ ìˆœìœ„
      .cacheIntermediates: false,  // ë©”ëª¨ë¦¬ ì ˆì•½
    ])

    // CVPixelBufferì— ì •í™•í•œ í¬ê¸°ë¡œ ë Œë”ë§
    do {
      context.render(
        scaledImage, to: scaledBuffer, bounds: targetRect,
        colorSpace: CGColorSpace(name: CGColorSpace.sRGB)!)
    } catch {
      logger.error("âŒ CIContext ë Œë”ë§ ì‹¤íŒ¨: \(error)")
      return nil
    }

    // ìŠ¤ì¼€ì¼ë§ ê²°ê³¼ ê²€ì¦
    let resultWidth = CVPixelBufferGetWidth(scaledBuffer)
    let resultHeight = CVPixelBufferGetHeight(scaledBuffer)

    if resultWidth == finalWidth && resultHeight == finalHeight {
      let originalInputRatio =
        Double(CVPixelBufferGetWidth(pixelBuffer)) / Double(CVPixelBufferGetHeight(pixelBuffer))
      let finalOutputRatio = Double(finalWidth) / Double(finalHeight)

      logger.info("âœ… Aspect Fill ìŠ¤ì¼€ì¼ë§ ì„±ê³µ:")
      logger.info(
        "   â€¢ ì…ë ¥: \(CVPixelBufferGetWidth(pixelBuffer))x\(CVPixelBufferGetHeight(pixelBuffer)) (ë¹„ìœ¨: \(String(format: "%.2f", originalInputRatio)))"
      )
      logger.info(
        "   â€¢ ì¶œë ¥: \(finalWidth)x\(finalHeight) (ë¹„ìœ¨: \(String(format: "%.2f", finalOutputRatio)))")
      logger.info("   â€¢ 1:1 â†’ 16:9 ë³€í™˜: \(abs(originalInputRatio - 1.0) < 0.1 ? "âœ…ì™„ë£Œ" : "N/A")")
      return scaledBuffer
    } else {
      logger.error(
        "âŒ ìŠ¤ì¼€ì¼ë§ ê²°ê³¼ ë¶ˆì¼ì¹˜: ì˜ˆìƒ \(finalWidth)x\(finalHeight) vs ì‹¤ì œ \(resultWidth)x\(resultHeight)")
      return nil
    }
  }

  /// CVPixelBufferë¥¼ CMSampleBufferë¡œ ë³€í™˜ (HaishinKit ì™„ë²½ í˜¸í™˜ì„±)
  func createSampleBuffer(from pixelBuffer: CVPixelBuffer) -> CMSampleBuffer? {
    // 1. CVPixelBuffer ì…ë ¥ ê²€ì¦
    let width = CVPixelBufferGetWidth(pixelBuffer)
    let height = CVPixelBufferGetHeight(pixelBuffer)
    let pixelFormat = CVPixelBufferGetPixelFormatType(pixelBuffer)

    logger.debug("ğŸ¬ CMSampleBuffer ìƒì„± ì‹œì‘: \(width)x\(height) í¬ë§·:\(pixelFormat)")

    // 2. HaishinKit í•„ìˆ˜ í¬ë§· ê°•ì œ í™•ì¸
    let supportedFormats: [OSType] = [
      kCVPixelFormatType_32BGRA,  // ì£¼ìš” í¬ë§· (HaishinKit ê¶Œì¥)
      kCVPixelFormatType_32ARGB,  // ëŒ€ì²´ í¬ë§·
      kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange,  // YUV í¬ë§·
      kCVPixelFormatType_420YpCbCr8BiPlanarFullRange,
    ]

    if !supportedFormats.contains(pixelFormat) {
      logger.error("âŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” í”½ì…€ í¬ë§·: \(pixelFormat) â†’ í¬ë§· ë³€í™˜ ì‹œë„")

      // ê°•ì œ í¬ë§· ë³€í™˜
      if let convertedBuffer = convertToSupportedFormat(pixelBuffer) {
        logger.info("âœ… í”½ì…€ í¬ë§· ë³€í™˜ ì„±ê³µ: \(pixelFormat) â†’ \(kCVPixelFormatType_32BGRA)")
        return createSampleBuffer(from: convertedBuffer)
      } else {
        logger.error("âŒ í”½ì…€ í¬ë§· ë³€í™˜ ì‹¤íŒ¨ - CMSampleBuffer ìƒì„± ì¤‘ë‹¨")
        return nil
      }
    }

    // 3. CVFormatDescription ìƒì„± (ì¤‘ìš”: ì •í™•í•œ ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„°)
    var formatDescription: CMFormatDescription?
    let formatStatus = CMVideoFormatDescriptionCreateForImageBuffer(
      allocator: kCFAllocatorDefault,
      imageBuffer: pixelBuffer,
      formatDescriptionOut: &formatDescription
    )

    guard formatStatus == noErr, let videoDesc = formatDescription else {
      logger.error("âŒ CMVideoFormatDescription ìƒì„± ì‹¤íŒ¨: \(formatStatus)")
      return nil
    }

    // 4. CMSampleTiming ì„¤ì • (ì •í™•í•œ íƒ€ì´ë° ì •ë³´)
    let frameDuration = CMTime(value: 1, timescale: 30)  // 30fps ê¸°ì¤€
    let currentTime = CMClockGetTime(CMClockGetHostTimeClock())

    var sampleTiming = CMSampleTimingInfo(
      duration: frameDuration,
      presentationTimeStamp: currentTime,
      decodeTimeStamp: CMTime.invalid  // ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì—ì„œëŠ” invalid
    )

    // 5. CMSampleBuffer ìƒì„± (HaishinKit ìµœì í™”)
    var sampleBuffer: CMSampleBuffer?
    let sampleStatus = CMSampleBufferCreateReadyWithImageBuffer(
      allocator: kCFAllocatorDefault,
      imageBuffer: pixelBuffer,
      formatDescription: videoDesc,
      sampleTiming: &sampleTiming,
      sampleBufferOut: &sampleBuffer
    )

    guard sampleStatus == noErr, let finalBuffer = sampleBuffer else {
      logger.error("âŒ CMSampleBuffer ìƒì„± ì‹¤íŒ¨: \(sampleStatus)")
      return nil
    }

    // 6. ìµœì¢… ê²€ì¦ ë° HaishinKit í˜¸í™˜ì„± í™•ì¸
    if CMSampleBufferIsValid(finalBuffer) {
      // ì¶”ê°€ ê²€ì¦: ë°ì´í„° ë¬´ê²°ì„± í™•ì¸
      guard CMSampleBufferGetNumSamples(finalBuffer) > 0 else {
        logger.error("âŒ CMSampleBufferì— ìœ íš¨í•œ ìƒ˜í”Œì´ ì—†ìŒ")
        return nil
      }

      // CVPixelBuffer ì¬í™•ì¸
      guard CMSampleBufferGetImageBuffer(finalBuffer) != nil else {
        logger.error("âŒ CMSampleBufferì—ì„œ ImageBuffer ì¶”ì¶œ ì‹¤íŒ¨")
        return nil
      }

      logger.debug("âœ… HaishinKit í˜¸í™˜ CMSampleBuffer ìƒì„± ì™„ë£Œ: \(width)x\(height)")
      return finalBuffer
    } else {
      logger.error("âŒ ìƒì„±ëœ CMSampleBuffer ìœ íš¨ì„± ê²€ì¦ ì‹¤íŒ¨")
      return nil
    }
  }

  /// VideoCodec -12902 ì—ëŸ¬ í•´ê²°ì„ ìœ„í•œ BGRA â†’ YUV420 í¬ë§· ë³€í™˜
  func convertToSupportedFormat(_ pixelBuffer: CVPixelBuffer) -> CVPixelBuffer? {
    let originalWidth = CVPixelBufferGetWidth(pixelBuffer)
    let originalHeight = CVPixelBufferGetHeight(pixelBuffer)
    let currentFormat = CVPixelBufferGetPixelFormatType(pixelBuffer)

    // VideoCodec ì•ˆì •ì„±ì„ ìœ„í•œ í•´ìƒë„ 16ì˜ ë°°ìˆ˜ ì •ë ¬
    let width = ((originalWidth + 15) / 16) * 16  // 16ì˜ ë°°ìˆ˜ë¡œ ì˜¬ë¦¼
    let height = ((originalHeight + 15) / 16) * 16  // 16ì˜ ë°°ìˆ˜ë¡œ ì˜¬ë¦¼

    if width != originalWidth || height != originalHeight {
      logger.debug("ğŸ”§ í•´ìƒë„ 16ë°°ìˆ˜ ì •ë ¬: \(originalWidth)x\(originalHeight) â†’ \(width)x\(height)")
    }

    // VideoCodecì´ ì„ í˜¸í•˜ëŠ” YUV420 í¬ë§·ìœ¼ë¡œ ë³€í™˜ (VideoCodec -12902 ì—ëŸ¬ í•´ê²°)
    let targetFormat = kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange

    logger.info(
      "ğŸ”„ [convertToSupportedFormat] BGRAâ†’YUV420 ë³€í™˜: \(currentFormat) â†’ \(targetFormat) (\(width)x\(height))"
    )

    // ì´ë¯¸ YUV420 í¬ë§·ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if currentFormat == targetFormat {
      logger.info("âœ… [convertToSupportedFormat] ì´ë¯¸ YUV420 í¬ë§· - ë³€í™˜ ë¶ˆí•„ìš”")
      return pixelBuffer
    }

    // VideoCodec ìµœì í™”ë¥¼ ìœ„í•œ YUV420 ì†ì„± ì„¤ì •
    let attributes: [String: Any] = [
      kCVPixelBufferIOSurfacePropertiesKey as String: [:],
      kCVPixelBufferBytesPerRowAlignmentKey as String: 16,  // YUV420ì— ìµœì í™”ëœ ì •ë ¬
      kCVPixelBufferPixelFormatTypeKey as String: targetFormat,
      kCVPixelBufferWidthKey as String: width,
      kCVPixelBufferHeightKey as String: height,
      kCVPixelBufferPlaneAlignmentKey as String: 16,  // YUV420 í”Œë ˆì¸ ì •ë ¬
    ]

    var yuvBuffer: CVPixelBuffer?
    let createStatus = CVPixelBufferCreate(
      kCFAllocatorDefault,
      width,
      height,
      targetFormat,
      attributes as CFDictionary,
      &yuvBuffer
    )

    guard createStatus == kCVReturnSuccess, let outputBuffer = yuvBuffer else {
      logger.error("âŒ YUV420 í”½ì…€ë²„í¼ ìƒì„± ì‹¤íŒ¨: \(createStatus)")

      // í´ë°±: BGRA í¬ë§·ìœ¼ë¡œ ëŒ€ì²´ (ê¸°ì¡´ ë°©ì‹)
      return convertToBGRAFormat(pixelBuffer)
    }

    // í•´ìƒë„ê°€ ë³€ê²½ëœ ê²½ìš° ë¨¼ì € ìŠ¤ì¼€ì¼ë§ ìˆ˜í–‰
    var processedPixelBuffer = pixelBuffer
    if width != originalWidth || height != originalHeight {
      if let scaledBuffer = scalePixelBuffer(pixelBuffer, toWidth: width, toHeight: height) {
        processedPixelBuffer = scaledBuffer
      } else {
        logger.warning("âš ï¸ í”½ì…€ë²„í¼ ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨ - ì›ë³¸ í¬ê¸° ì‚¬ìš©")
      }
    }

    // vImageë¥¼ ì‚¬ìš©í•œ ê³ ì„±ëŠ¥ BGRA â†’ YUV420 ë³€í™˜
    let conversionSuccess = convertBGRAToYUV420UsingvImage(
      sourceBuffer: processedPixelBuffer,
      destinationBuffer: outputBuffer
    )

    if conversionSuccess {
      logger.debug("âœ… VideoCodec ìµœì í™” ë³€í™˜ ì„±ê³µ: \(width)x\(height) â†’ YUV420")
      return outputBuffer
    } else {
      logger.warning("âš ï¸ vImage ë³€í™˜ ì‹¤íŒ¨ - CIImage í´ë°± ì‹œë„")

      // í´ë°±: CIImageë¥¼ í†µí•œ ë³€í™˜
      if let fallbackBuffer = convertBGRAToYUV420UsingCIImage(pixelBuffer) {
        logger.debug("âœ… CIImage í´ë°± ë³€í™˜ ì„±ê³µ")
        return fallbackBuffer
      } else {
        logger.error("âŒ ëª¨ë“  YUV420 ë³€í™˜ ë°©ë²• ì‹¤íŒ¨ - BGRA í´ë°±")
        return convertToBGRAFormat(pixelBuffer)
      }
    }
  }

  /// vImageë¥¼ ì‚¬ìš©í•œ ê³ ì„±ëŠ¥ BGRA â†’ YUV420 ë³€í™˜ (ì±„ë„ ìˆœì„œ ë³€í™˜ í¬í•¨)
  func convertBGRAToYUV420UsingvImage(
    sourceBuffer: CVPixelBuffer, destinationBuffer: CVPixelBuffer
  ) -> Bool {
    CVPixelBufferLockBaseAddress(sourceBuffer, .readOnly)
    CVPixelBufferLockBaseAddress(destinationBuffer, [])

    defer {
      CVPixelBufferUnlockBaseAddress(sourceBuffer, .readOnly)
      CVPixelBufferUnlockBaseAddress(destinationBuffer, [])
    }

    let width = CVPixelBufferGetWidth(sourceBuffer)
    let height = CVPixelBufferGetHeight(sourceBuffer)

    // ì†ŒìŠ¤ BGRA ë²„í¼ ì •ë³´
    guard let sourceBaseAddress = CVPixelBufferGetBaseAddress(sourceBuffer) else {
      logger.error("âŒ ì†ŒìŠ¤ í”½ì…€ë²„í¼ ì£¼ì†Œ íšë“ ì‹¤íŒ¨")
      return false
    }

    let sourceBytesPerRow = CVPixelBufferGetBytesPerRow(sourceBuffer)

    // 1ë‹¨ê³„: BGRA â†’ ARGB ì±„ë„ ìˆœì„œ ë³€í™˜ì„ ìœ„í•œ ì„ì‹œ ë²„í¼ ìƒì„±
    guard let argbData = malloc(sourceBytesPerRow * height) else {
      logger.error("âŒ ARGB ë³€í™˜ìš© ì„ì‹œ ë²„í¼ í• ë‹¹ ì‹¤íŒ¨")
      return false
    }
    defer { free(argbData) }

    // BGRA â†’ ARGB ì±„ë„ ìˆœì„œ ë³€í™˜ ìˆ˜í–‰
    if !swapBGRAToARGBChannels(
      sourceData: sourceBaseAddress,
      destinationData: argbData,
      width: width,
      height: height,
      sourceBytesPerRow: sourceBytesPerRow,
      destinationBytesPerRow: sourceBytesPerRow
    ) {
      logger.error("âŒ BGRA â†’ ARGB ì±„ë„ ìˆœì„œ ë³€í™˜ ì‹¤íŒ¨")
      return false
    }

    // YUV420 ëŒ€ìƒ ë²„í¼ ì •ë³´
    guard let yPlaneAddress = CVPixelBufferGetBaseAddressOfPlane(destinationBuffer, 0),
      let uvPlaneAddress = CVPixelBufferGetBaseAddressOfPlane(destinationBuffer, 1)
    else {
      logger.error("âŒ YUV420 í”Œë ˆì¸ ì£¼ì†Œ íšë“ ì‹¤íŒ¨")
      return false
    }

    let yBytesPerRow = CVPixelBufferGetBytesPerRowOfPlane(destinationBuffer, 0)
    let uvBytesPerRow = CVPixelBufferGetBytesPerRowOfPlane(destinationBuffer, 1)

    // 2ë‹¨ê³„: vImage ë²„í¼ êµ¬ì¡°ì²´ ì„¤ì • (ARGB ë³€í™˜ëœ ë°ì´í„° ì‚¬ìš©)
    var sourceImageBuffer = vImage_Buffer(
      data: argbData,  // ë³€í™˜ëœ ARGB ë°ì´í„° ì‚¬ìš©
      height: vImagePixelCount(height),
      width: vImagePixelCount(width),
      rowBytes: sourceBytesPerRow
    )

    var yPlaneBuffer = vImage_Buffer(
      data: yPlaneAddress,
      height: vImagePixelCount(height),
      width: vImagePixelCount(width),
      rowBytes: yBytesPerRow
    )

    var uvPlaneBuffer = vImage_Buffer(
      data: uvPlaneAddress,
      height: vImagePixelCount(height / 2),
      width: vImagePixelCount(width / 2),
      rowBytes: uvBytesPerRow
    )

    // BGRA â†’ YUV420 ë³€í™˜ ì •ë³´ ì„¤ì • (ìƒ‰ìƒ ìˆœì„œ ìˆ˜ì •)
    var info = vImage_ARGBToYpCbCr()
    var pixelRange = vImage_YpCbCrPixelRange(
      Yp_bias: 16,
      CbCr_bias: 128,
      YpRangeMax: 235,
      CbCrRangeMax: 240,
      YpMax: 235,
      YpMin: 16,
      CbCrMax: 240,
      CbCrMin: 16)

    // ITU-R BT.709 ë³€í™˜ í–‰ë ¬ ì„¤ì • (HDìš©) - ARGB ìˆœì„œ ì‚¬ìš© (vImage í‘œì¤€)
    let error = vImageConvert_ARGBToYpCbCr_GenerateConversion(
      kvImage_ARGBToYpCbCrMatrix_ITU_R_709_2,
      &pixelRange,
      &info,
      kvImageARGB8888,  // vImage í‘œì¤€ ARGB í¬ë§· ì‚¬ìš©
      kvImage420Yp8_CbCr8,
      vImage_Flags(kvImageNoFlags)
    )

    guard error == kvImageNoError else {
      logger.error("âŒ vImage ë³€í™˜ ì„¤ì • ì‹¤íŒ¨: \(error)")
      return false
    }

    // BGRA ë°ì´í„°ë¥¼ ARGB ìˆœì„œë¡œ ë³€í™˜í•œ í›„ YUV420 ë³€í™˜ ìˆ˜í–‰
    // vImageëŠ” ARGB ìˆœì„œë¥¼ ê¸°ë³¸ìœ¼ë¡œ í•˜ë¯€ë¡œ ë°ì´í„° ìˆœì„œ ì¡°ì • í›„ ë³€í™˜
    let conversionError = vImageConvert_ARGB8888To420Yp8_CbCr8(
      &sourceImageBuffer,
      &yPlaneBuffer,
      &uvPlaneBuffer,
      &info,
      UnsafePointer<UInt8>?.none,  // nil ëŒ€ì‹  ëª…ì‹œì  íƒ€ì… ì§€ì •
      vImage_Flags(kvImageNoFlags)
    )

    if conversionError == kvImageNoError {
      logger.debug("âœ… vImage BGRAâ†’YUV420 ë³€í™˜ ì„±ê³µ: \(width)x\(height)")
      return true
    } else {
      logger.error("âŒ vImage BGRAâ†’YUV420 ë³€í™˜ ì‹¤íŒ¨: \(conversionError)")
      return false
    }
  }

  /// CIImageë¥¼ ì‚¬ìš©í•œ BGRA â†’ YUV420 ë³€í™˜ (í´ë°±)
  func convertBGRAToYUV420UsingCIImage(_ pixelBuffer: CVPixelBuffer) -> CVPixelBuffer? {
    let width = CVPixelBufferGetWidth(pixelBuffer)
    let height = CVPixelBufferGetHeight(pixelBuffer)

    // YUV420 ë²„í¼ ìƒì„±
    var yuvBuffer: CVPixelBuffer?
    let createStatus = CVPixelBufferCreate(
      kCFAllocatorDefault,
      width,
      height,
      kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange,
      nil,
      &yuvBuffer
    )

    guard createStatus == kCVReturnSuccess, let outputBuffer = yuvBuffer else {
      return nil
    }

    let inputImage = CIImage(cvPixelBuffer: pixelBuffer)
    let context = CIContext(options: [
      .workingColorSpace: CGColorSpace(name: CGColorSpace.itur_709)!,  // YUVì— ì í•©í•œ ìƒ‰ê³µê°„
      .outputColorSpace: CGColorSpace(name: CGColorSpace.itur_709)!,
      .useSoftwareRenderer: false,
      .cacheIntermediates: false,
    ])

    let targetRect = CGRect(x: 0, y: 0, width: width, height: height)

    do {
      context.render(
        inputImage, to: outputBuffer, bounds: targetRect,
        colorSpace: CGColorSpace(name: CGColorSpace.itur_709)!)
      return outputBuffer
    } catch {
      logger.error("âŒ CIImage YUV420 ë³€í™˜ ì‹¤íŒ¨: \(error)")
      return nil
    }
  }

  /// í´ë°±ìš© BGRA í¬ë§· ë³€í™˜ (ê¸°ì¡´ ë°©ì‹)
  func convertToBGRAFormat(_ pixelBuffer: CVPixelBuffer) -> CVPixelBuffer? {
    let width = CVPixelBufferGetWidth(pixelBuffer)
    let height = CVPixelBufferGetHeight(pixelBuffer)
    let currentFormat = CVPixelBufferGetPixelFormatType(pixelBuffer)
    let targetFormat = kCVPixelFormatType_32BGRA

    // ì´ë¯¸ BGRAë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if currentFormat == targetFormat {
      return pixelBuffer
    }

    logger.debug("ğŸ”„ í´ë°± BGRA ë³€í™˜: \(currentFormat) â†’ \(targetFormat)")

    let attributes: [String: Any] = [
      kCVPixelBufferCGImageCompatibilityKey as String: true,
      kCVPixelBufferCGBitmapContextCompatibilityKey as String: true,
      kCVPixelBufferIOSurfacePropertiesKey as String: [:],
      kCVPixelBufferBytesPerRowAlignmentKey as String: 64,
    ]

    var convertedBuffer: CVPixelBuffer?
    let status = CVPixelBufferCreate(
      kCFAllocatorDefault,
      width,
      height,
      targetFormat,
      attributes as CFDictionary,
      &convertedBuffer
    )

    guard status == kCVReturnSuccess, let outputBuffer = convertedBuffer else {
      return nil
    }

    let inputImage = CIImage(cvPixelBuffer: pixelBuffer)
    let context = CIContext(options: [.useSoftwareRenderer: false])
    let targetRect = CGRect(x: 0, y: 0, width: width, height: height)

    context.render(
      inputImage, to: outputBuffer, bounds: targetRect,
      colorSpace: CGColorSpace(name: CGColorSpace.sRGB)!)

    return outputBuffer
  }

  /// BGRA â†’ ARGB ì±„ë„ ìˆœì„œ ë³€í™˜ (vImage í˜¸í™˜ì„±ì„ ìœ„í•œ ì „ì²˜ë¦¬)
  func swapBGRAToARGBChannels(
    sourceData: UnsafeRawPointer,
    destinationData: UnsafeMutableRawPointer,
    width: Int,
    height: Int,
    sourceBytesPerRow: Int,
    destinationBytesPerRow: Int
  ) -> Bool {

    // vImageë¥¼ ì‚¬ìš©í•œ ê³ ì„±ëŠ¥ ì±„ë„ ìˆœì„œ ë³€í™˜
    var sourceBuffer = vImage_Buffer(
      data: UnsafeMutableRawPointer(mutating: sourceData),
      height: vImagePixelCount(height),
      width: vImagePixelCount(width),
      rowBytes: sourceBytesPerRow
    )

    var destinationBuffer = vImage_Buffer(
      data: destinationData,
      height: vImagePixelCount(height),
      width: vImagePixelCount(width),
      rowBytes: destinationBytesPerRow
    )

    // BGRA(0,1,2,3) â†’ ARGB(3,0,1,2) ìˆœì„œ ë³€í™˜
    // B=0, G=1, R=2, A=3 â†’ A=3, R=2, G=1, B=0
    let channelOrder: [UInt8] = [3, 2, 1, 0]  // ARGB ìˆœì„œ

    let error = vImagePermuteChannels_ARGB8888(
      &sourceBuffer,
      &destinationBuffer,
      channelOrder,
      vImage_Flags(kvImageNoFlags)
    )

    if error == kvImageNoError {
      logger.debug("âœ… BGRA â†’ ARGB ì±„ë„ ìˆœì„œ ë³€í™˜ ì„±ê³µ")
      return true
    } else {
      logger.error("âŒ BGRA â†’ ARGB ì±„ë„ ìˆœì„œ ë³€í™˜ ì‹¤íŒ¨: \(error)")

      // í´ë°±: ìˆ˜ë™ ì±„ë„ ë³€í™˜
      return swapChannelsManually(
        sourceData: sourceData,
        destinationData: destinationData,
        width: width,
        height: height,
        sourceBytesPerRow: sourceBytesPerRow,
        destinationBytesPerRow: destinationBytesPerRow
      )
    }
  }

  /// ìˆ˜ë™ ì±„ë„ ìˆœì„œ ë³€í™˜ (vImage ì‹¤íŒ¨ ì‹œ í´ë°±)
  func swapChannelsManually(
    sourceData: UnsafeRawPointer,
    destinationData: UnsafeMutableRawPointer,
    width: Int,
    height: Int,
    sourceBytesPerRow: Int,
    destinationBytesPerRow: Int
  ) -> Bool {

    let sourceBytes = sourceData.assumingMemoryBound(to: UInt8.self)
    let destinationBytes = destinationData.assumingMemoryBound(to: UInt8.self)

    for y in 0..<height {
      for x in 0..<width {
        let sourcePixelIndex = y * sourceBytesPerRow + x * 4
        let destPixelIndex = y * destinationBytesPerRow + x * 4

        // BGRA â†’ ARGB ë³€í™˜
        // ì†ŒìŠ¤: [B, G, R, A]
        // ëŒ€ìƒ: [A, R, G, B]
        destinationBytes[destPixelIndex + 0] = sourceBytes[sourcePixelIndex + 3]  // A
        destinationBytes[destPixelIndex + 1] = sourceBytes[sourcePixelIndex + 2]  // R
        destinationBytes[destPixelIndex + 2] = sourceBytes[sourcePixelIndex + 1]  // G
        destinationBytes[destPixelIndex + 3] = sourceBytes[sourcePixelIndex + 0]  // B
      }
    }

    logger.debug("âœ… ìˆ˜ë™ BGRA â†’ ARGB ì±„ë„ ìˆœì„œ ë³€í™˜ ì™„ë£Œ")
    return true
  }

  /// í”½ì…€ ë²„í¼ë¥¼ ì§€ì •ëœ í¬ê¸°ë¡œ ìŠ¤ì¼€ì¼ë§ (16ì˜ ë°°ìˆ˜ ì •ë ¬ìš©)
  func scalePixelBuffer(
    _ pixelBuffer: CVPixelBuffer, toWidth newWidth: Int, toHeight newHeight: Int
  ) -> CVPixelBuffer? {
    let originalWidth = CVPixelBufferGetWidth(pixelBuffer)
    let originalHeight = CVPixelBufferGetHeight(pixelBuffer)

    // í¬ê¸°ê°€ ê°™ìœ¼ë©´ ì›ë³¸ ë°˜í™˜
    if newWidth == originalWidth && newHeight == originalHeight {
      return pixelBuffer
    }

    logger.debug("ğŸ”§ í”½ì…€ë²„í¼ ìŠ¤ì¼€ì¼ë§: \(originalWidth)x\(originalHeight) â†’ \(newWidth)x\(newHeight)")

    // CIImageë¥¼ ì‚¬ìš©í•œ ìŠ¤ì¼€ì¼ë§
    let inputImage = CIImage(cvPixelBuffer: pixelBuffer)
    let scaleX = CGFloat(newWidth) / CGFloat(originalWidth)
    let scaleY = CGFloat(newHeight) / CGFloat(originalHeight)

    let scaledImage = inputImage.transformed(by: CGAffineTransform(scaleX: scaleX, y: scaleY))

    // ìŠ¤ì¼€ì¼ëœ í”½ì…€ ë²„í¼ ìƒì„±
    let attributes: [String: Any] = [
      kCVPixelBufferCGImageCompatibilityKey as String: true,
      kCVPixelBufferCGBitmapContextCompatibilityKey as String: true,
      kCVPixelBufferIOSurfacePropertiesKey as String: [:],
      kCVPixelBufferBytesPerRowAlignmentKey as String: 16,
    ]

    var scaledBuffer: CVPixelBuffer?
    let createStatus = CVPixelBufferCreate(
      kCFAllocatorDefault,
      newWidth,
      newHeight,
      CVPixelBufferGetPixelFormatType(pixelBuffer),
      attributes as CFDictionary,
      &scaledBuffer
    )

    guard createStatus == kCVReturnSuccess, let outputBuffer = scaledBuffer else {
      logger.error("âŒ ìŠ¤ì¼€ì¼ëœ í”½ì…€ë²„í¼ ìƒì„± ì‹¤íŒ¨: \(createStatus)")
      return nil
    }

    let context = CIContext(options: [.useSoftwareRenderer: false])
    let targetRect = CGRect(x: 0, y: 0, width: newWidth, height: newHeight)

    context.render(
      scaledImage, to: outputBuffer, bounds: targetRect,
      colorSpace: CGColorSpace(name: CGColorSpace.sRGB)!)

    return outputBuffer
  }

  /// VideoToolbox í•˜ë“œì›¨ì–´ ìµœì í™”ë¥¼ ìœ„í•œ í”½ì…€ ë²„í¼ í¬ë§· ë³€í™˜
  func convertPixelBufferForVideoToolbox(_ pixelBuffer: CVPixelBuffer) -> CVPixelBuffer? {
    let currentFormat = CVPixelBufferGetPixelFormatType(pixelBuffer)

    // VideoToolbox í•˜ë“œì›¨ì–´ ì¸ì½”ë”ê°€ ê°€ì¥ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” í¬ë§· ìš°ì„ ìˆœìœ„:
    // 1. YUV420 (í•˜ë“œì›¨ì–´ ê°€ì† ìµœì í™”)
    // 2. BGRA (í´ë°±ìš©)
    let preferredFormat = kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange

    if currentFormat == preferredFormat {
      logger.debug("âœ… ì´ë¯¸ VideoToolbox ìµœì í™” í¬ë§·(YUV420)")
      return pixelBuffer
    }

    // YUV420 ë³€í™˜ ì‹œë„ (í•˜ë“œì›¨ì–´ ê°€ì† ìµœëŒ€í™”)
    if let yuvBuffer = convertToYUV420Format(pixelBuffer) {
      logger.debug("ğŸš€ VideoToolbox YUV420 ë³€í™˜ ì„±ê³µ - í•˜ë“œì›¨ì–´ ê°€ì† ìµœì í™”")
      return yuvBuffer
    }

    // í´ë°±: BGRA í¬ë§· ë³€í™˜
    logger.debug("âš ï¸ YUV420 ë³€í™˜ ì‹¤íŒ¨ - BGRA í´ë°±")
    return convertToSupportedFormat(pixelBuffer)
  }

  /// YUV420 í¬ë§·ìœ¼ë¡œ ë³€í™˜ (VideoToolbox í•˜ë“œì›¨ì–´ ê°€ì† ìµœì í™”)
  func convertToYUV420Format(_ pixelBuffer: CVPixelBuffer) -> CVPixelBuffer? {
    let width = CVPixelBufferGetWidth(pixelBuffer)
    let height = CVPixelBufferGetHeight(pixelBuffer)

    // YUV420 í”½ì…€ ë²„í¼ ìƒì„±
    let attributes: [String: Any] = [
      kCVPixelBufferIOSurfacePropertiesKey as String: [:],
      kCVPixelBufferBytesPerRowAlignmentKey as String: 16,
      kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange,
      kCVPixelBufferWidthKey as String: width,
      kCVPixelBufferHeightKey as String: height,
      kCVPixelBufferPlaneAlignmentKey as String: 16,
    ]

    var yuvBuffer: CVPixelBuffer?
    let createStatus = CVPixelBufferCreate(
      kCFAllocatorDefault,
      width,
      height,
      kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange,
      attributes as CFDictionary,
      &yuvBuffer
    )

    guard createStatus == kCVReturnSuccess, let outputBuffer = yuvBuffer else {
      logger.warning("âš ï¸ YUV420 í”½ì…€ë²„í¼ ìƒì„± ì‹¤íŒ¨: \(createStatus)")
      return nil
    }

    // vImageë¥¼ ì‚¬ìš©í•œ ê³ ì„±ëŠ¥ BGRA â†’ YUV420 ë³€í™˜
    let conversionSuccess = convertBGRAToYUV420UsingvImage(
      sourceBuffer: pixelBuffer,
      destinationBuffer: outputBuffer
    )

    if conversionSuccess {
      logger.debug("âœ… VideoToolbox YUV420 ë³€í™˜ ì„±ê³µ")
      return outputBuffer
    } else {
      logger.warning("âš ï¸ YUV420 ë³€í™˜ ì‹¤íŒ¨")
      return nil
    }
  }

  /// CVPixelBufferë¥¼ HaishinKit í˜¸í™˜ í¬ë§·ìœ¼ë¡œ ë³€í™˜ (convertToSupportedFormat ëŒ€ì²´ìš©)
  func convertPixelBufferFormat(_ pixelBuffer: CVPixelBuffer) -> CVPixelBuffer? {
    // convertToSupportedFormatì™€ ë™ì¼í•œ ë¡œì§ ì‚¬ìš©
    return convertToSupportedFormat(pixelBuffer)
  }

  /// í™”ë©´ ìº¡ì²˜ ëª¨ë“œë¡œ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
  /// CameraPreviewUIView í™”ë©´ì„ ì†¡ì¶œí•˜ëŠ” íŠ¹ë³„í•œ ëª¨ë“œ
  public func startScreenCaptureStreaming(with settings: USBExternalCamera.LiveStreamSettings)
    async throws
  {
    logger.info("ğŸ¬ í™”ë©´ ìº¡ì²˜ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì‹œì‘")

    // ì¼ë°˜ì ì¸ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ê³¼ ë™ì¼í•˜ì§€ë§Œ ì¹´ë©”ë¼ ì—°ê²°ì€ ìƒëµ
    guard !isStreaming else {
      logger.warning("âš ï¸ ì´ë¯¸ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì…ë‹ˆë‹¤")
      throw LiveStreamError.streamingFailed("ì´ë¯¸ ìŠ¤íŠ¸ë¦¬ë°ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤")
    }

    // ì‚¬ìš©ì ì›ë³¸ ì„¤ì • ë³´ì¡´ (ë®ì–´ì“°ê¸° ë°©ì§€)
    originalUserSettings = settings

    // í˜„ì¬ ì„¤ì • ì €ì¥
    currentSettings = settings
    saveSettings(settings)

    // ìƒíƒœ ì—…ë°ì´íŠ¸
    currentStatus = .connecting
    connectionStatus = "í™”ë©´ ìº¡ì²˜ ëª¨ë“œ ì—°ê²° ì¤‘..."

    do {
      // ğŸš€ ë¹ ë¥¸ ì—°ê²°ì„ ìœ„í•œ ìµœì í™”ëœ ì‹œí€€ìŠ¤
      logger.info("ğŸš€ í™”ë©´ ìº¡ì²˜ ìŠ¤íŠ¸ë¦¬ë°: ë¹ ë¥¸ ì—°ê²° ëª¨ë“œ ì‹œì‘", category: .system)

      // 1ë‹¨ê³„: RTMP ì—°ê²° ìš°ì„  (ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„)
      let preference = StreamPreference(
        rtmpURL: settings.rtmpURL,
        streamKey: settings.streamKey
      )
      await streamSwitcher.setPreference(preference)

      // 2ë‹¨ê³„: ì‹¤ì œ RTMP ì—°ê²° ì‹œì‘ (ë³‘ë ¬ ì²˜ë¦¬ ì¤€ë¹„)
      async let rtmpConnection: () = streamSwitcher.startStreaming()

      // 3ë‹¨ê³„: ë™ì‹œì— ë¡œì»¬ ì„¤ì •ë“¤ ì´ˆê¸°í™” (RTMP ì—°ê²°ê³¼ ë³‘ë ¬)
      async let localSetup: () = setupLocalComponentsInParallel(settings)

      // 4ë‹¨ê³„: ë‘ ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
      try await rtmpConnection
      try await localSetup

      logger.info("âœ… ë³‘ë ¬ ì´ˆê¸°í™” ì™„ë£Œ: RTMP ì—°ê²° + ë¡œì»¬ ì„¤ì •", category: .system)

      // 5ë‹¨ê³„: ìµœì¢… í›„ì²˜ë¦¬ (ìµœì†Œí™”)
      try await finalizeScreenCaptureConnection()

      // ìƒíƒœ ì—…ë°ì´íŠ¸ ë° ëª¨ë‹ˆí„°ë§ ì‹œì‘
      isStreaming = true
      isScreenCaptureMode = true  // í™”ë©´ ìº¡ì²˜ ëª¨ë“œ í”Œë˜ê·¸ ì„¤ì •
      currentStatus = .streaming
      connectionStatus = "í™”ë©´ ìº¡ì²˜ ìŠ¤íŠ¸ë¦¬ë° ì¤‘..."

      startDataMonitoring()

      // ì—°ê²° ì•ˆì •í™” í›„ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ìµœì í™”: 5ì´ˆ â†’ 2ì´ˆë¡œ ë‹¨ì¶•)
      DispatchQueue.main.asyncAfter(deadline: .now() + 2.0) { [weak self] in
        self?.startConnectionHealthMonitoring()
      }

      logger.info("ğŸ‰ í™”ë©´ ìº¡ì²˜ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì„±ê³µ - ë¹ ë¥¸ ì—°ê²° ëª¨ë“œ")

    } catch {
      logger.error("âŒ í™”ë©´ ìº¡ì²˜ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì‹¤íŒ¨: \(error)")

      // ì‹¤íŒ¨ ì‹œ ì •ë¦¬
      currentStatus = .error(
        error as? LiveStreamError ?? LiveStreamError.streamingFailed(error.localizedDescription))
      connectionStatus = "í™”ë©´ ìº¡ì²˜ ì—°ê²° ì‹¤íŒ¨"
      isStreaming = false
      isScreenCaptureMode = false

      throw error
    }
  }

}
