//
//  CameraPreviewUIView.swift
//  USBExternalCamera
//
//  Created by EUN YEON on 5/25/25.
//

import AVFoundation
import HaishinKit
import SwiftUI
import UIKit
import Foundation

/// ì‹¤ì œ ì¹´ë©”ë¼ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ë‹´ë‹¹í•˜ëŠ” UIView
final class CameraPreviewUIView: UIView {

  // MARK: - Properties

  /// AVFoundation ì¹´ë©”ë¼ ë¯¸ë¦¬ë³´ê¸° ë ˆì´ì–´
  private var previewLayer: AVCaptureVideoPreviewLayer?

  /// HaishinKit ë¯¸ë¦¬ë³´ê¸° ë ˆì´ì–´ (ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì¼ ë•Œ ì‚¬ìš©)
  private var hkPreviewLayer: UIView?

  /// ë¹„ë””ì˜¤ ì¶œë ¥ (í†µê³„ ëª©ì )
  private var videoOutput: AVCaptureVideoDataOutput?
  private let videoOutputQueue = DispatchQueue(
    label: "CameraPreviewView.VideoOutput", qos: .userInteractive)

  /// í˜„ì¬ ìº¡ì²˜ ì„¸ì…˜
  var captureSession: AVCaptureSession? {
    didSet {
      // ì²˜ìŒ ì„¤ì •ë  ë•Œë§Œ í”„ë¦¬ë·° ë ˆì´ì–´ ìƒì„±
      if oldValue == nil && captureSession != nil {
        logInfo("ì´ˆê¸° ìº¡ì²˜ ì„¸ì…˜ ì„¤ì • - í”„ë¦¬ë·° ë ˆì´ì–´ ìƒì„±", category: .camera)
        updatePreviewLayer()
      } else if oldValue !== captureSession {
        logInfo("ìº¡ì²˜ ì„¸ì…˜ ë³€ê²½ ê°ì§€ - í”„ë¦¬ë·° ë ˆì´ì–´ ì—…ë°ì´íŠ¸", category: .camera)
        updatePreviewLayer()
      }
    }
  }

  /// HaishinKit ë§¤ë‹ˆì € (ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ í™•ì¸ìš©)
  var haishinKitManager: HaishinKitManager? {
    didSet {
      updateStreamingStatus()
      setupStatusMonitoring()
    }
  }

  /// ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ
  private var isStreaming: Bool = false {
    didSet {
      updateStreamingStatusView()
    }
  }

  /// ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ëª¨ë‹ˆí„°ë§ íƒ€ì´ë¨¸
  private var statusMonitorTimer: Timer?

  /// ì¹´ë©”ë¼ ì»¨íŠ¸ë¡¤ ì˜¤ë²„ë ˆì´
  private lazy var controlOverlay: CameraControlOverlay = {
    let overlay = CameraControlOverlay()
    overlay.delegate = self
    overlay.translatesAutoresizingMaskIntoConstraints = false
    overlay.backgroundColor = UIColor.clear
    return overlay
  }()

  /// ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ í‘œì‹œ
  private lazy var streamingStatusView: StreamingStatusView = {
    let statusView = StreamingStatusView()
    statusView.translatesAutoresizingMaskIntoConstraints = false
    statusView.isHidden = true
    return statusView
  }()

  // MARK: - Initialization

  override init(frame: CGRect) {
    super.init(frame: frame)
    setupView()
  }

  required init?(coder: NSCoder) {
    super.init(coder: coder)
    setupView()
  }

  // MARK: - View Setup

  private func setupView() {
    backgroundColor = .black

    // ì»¨íŠ¸ë¡¤ ì˜¤ë²„ë ˆì´ë§Œ ì¶”ê°€ (StreamingStatusViewëŠ” ì¤‘ë³µë˜ë¯€ë¡œ ì œê±°)
    addSubview(controlOverlay)

    setupConstraints()
    setupGestureRecognizers()
    setupNotifications()
  }

  private func setupNotifications() {
    // í™”ë©´ ìº¡ì²˜ ì œì–´ notification êµ¬ë…
    NotificationCenter.default.addObserver(
      self,
      selector: #selector(handleStartScreenCapture),
      name: NSNotification.Name("startScreenCapture"),
      object: nil
    )

    NotificationCenter.default.addObserver(
      self,
      selector: #selector(handleStopScreenCapture),
      name: NSNotification.Name("stopScreenCapture"),
      object: nil
    )
  }

  @objc private func handleStartScreenCapture() {
    logDebug("í™”ë©´ ìº¡ì²˜ ì‹œì‘ notification ìˆ˜ì‹ ", category: .streaming)
    startScreenCapture()
  }

  @objc private func handleStopScreenCapture() {
    logDebug("í™”ë©´ ìº¡ì²˜ ì¤‘ì§€ notification ìˆ˜ì‹ ", category: .streaming)
    stopScreenCapture()
  }

  private func setupConstraints() {
    NSLayoutConstraint.activate([
      // ì»¨íŠ¸ë¡¤ ì˜¤ë²„ë ˆì´
      controlOverlay.leadingAnchor.constraint(equalTo: leadingAnchor),
      controlOverlay.trailingAnchor.constraint(equalTo: trailingAnchor),
      controlOverlay.topAnchor.constraint(equalTo: topAnchor),
      controlOverlay.bottomAnchor.constraint(equalTo: bottomAnchor),
    ])
  }

  private func setupGestureRecognizers() {
    // í¬ì»¤ìŠ¤ íƒ­ ì œìŠ¤ì²˜
    let focusTapGesture = UITapGestureRecognizer(
      target: self, action: #selector(handleFocusTap(_:)))
    addGestureRecognizer(focusTapGesture)

    // ë…¸ì¶œ ì¡°ì ˆ ë”ë¸”íƒ­ ì œìŠ¤ì²˜
    let exposureDoubleTapGesture = UITapGestureRecognizer(
      target: self, action: #selector(handleExposureDoubleTap(_:)))
    exposureDoubleTapGesture.numberOfTapsRequired = 2
    addGestureRecognizer(exposureDoubleTapGesture)

    focusTapGesture.require(toFail: exposureDoubleTapGesture)

    // ì¤Œ í•€ì¹˜ ì œìŠ¤ì²˜
    let zoomPinchGesture = UIPinchGestureRecognizer(
      target: self, action: #selector(handleZoomPinch(_:)))
    addGestureRecognizer(zoomPinchGesture)
  }

  // MARK: - Preview Layer Management

  private func updatePreviewLayer() {
    // ê¸°ì¡´ ë ˆì´ì–´ ì œê±°
    previewLayer?.removeFromSuperlayer()
    hkPreviewLayer?.removeFromSuperview()

    guard let session = captureSession else { return }

    // í•­ìƒ AVFoundation í”„ë¦¬ë·° ì‚¬ìš© (ì•ˆì •ì„± í–¥ìƒ)
    setupAVFoundationPreview(with: session)

    // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì´ë©´ ì¶”ê°€ í‘œì‹œ
    if isStreaming {
      addStreamingIndicator()
    }
  }

  /// ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œë§Œ ì¶”ê°€ (í”„ë¦¬ë·° ë ˆì´ì–´ëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
  private func addStreamingIndicatorOnly() {
    // ê¸°ì¡´ ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì œê±°
    removeStreamingIndicator()

    logDebug("ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì¶”ê°€", category: .streaming)

    let streamingOverlay = UIView(frame: bounds)
    streamingOverlay.backgroundColor = UIColor.clear
    streamingOverlay.tag = 9999  // ì‹ë³„ìš© íƒœê·¸

    let streamingIndicator = UIView()
    streamingIndicator.backgroundColor = UIColor.red.withAlphaComponent(0.9)
    streamingIndicator.layer.cornerRadius = 12
    streamingIndicator.translatesAutoresizingMaskIntoConstraints = false

    let liveLabel = UILabel()
    liveLabel.text = "ğŸ”´ LIVE"
    liveLabel.textColor = .white
    liveLabel.font = UIFont.boldSystemFont(ofSize: 14)
    liveLabel.translatesAutoresizingMaskIntoConstraints = false

    streamingIndicator.addSubview(liveLabel)
    streamingOverlay.addSubview(streamingIndicator)

    NSLayoutConstraint.activate([
      streamingIndicator.topAnchor.constraint(
        equalTo: streamingOverlay.safeAreaLayoutGuide.topAnchor, constant: 20),
      streamingIndicator.leadingAnchor.constraint(
        equalTo: streamingOverlay.leadingAnchor, constant: 20),
      streamingIndicator.widthAnchor.constraint(equalToConstant: 80),
      streamingIndicator.heightAnchor.constraint(equalToConstant: 32),

      liveLabel.centerXAnchor.constraint(equalTo: streamingIndicator.centerXAnchor),
      liveLabel.centerYAnchor.constraint(equalTo: streamingIndicator.centerYAnchor),
    ])

    addSubview(streamingOverlay)
    hkPreviewLayer = streamingOverlay
  }

  /// ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì œê±°
  private func removeStreamingIndicator() {
    // íƒœê·¸ë¡œ ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì°¾ì•„ì„œ ì œê±°
    if let streamingOverlay = subviews.first(where: { $0.tag == 9999 }) {
      streamingOverlay.removeFromSuperview()
      logDebug("ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì œê±°", category: .streaming)
    }
    hkPreviewLayer = nil
  }

  /// ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì¶”ê°€ (ë ˆì´ì•„ì›ƒìš©)
  private func addStreamingIndicator() {
    addStreamingIndicatorOnly()
  }

  /// í”„ë¦¬ë·° ë ˆì´ì–´ê°€ í™œì„± ìƒíƒœì¸ì§€ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ë³µêµ¬
  private func ensurePreviewLayerActive() {
    guard let session = captureSession else {
      logError("ìº¡ì²˜ ì„¸ì…˜ì´ ì—†ì–´ í”„ë¦¬ë·° ë³´í˜¸ ë¶ˆê°€", category: .camera)
      return
    }

    // í”„ë¦¬ë·° ë ˆì´ì–´ê°€ ì—†ê±°ë‚˜ ì„¸ì…˜ì´ ë‹¤ë¥´ë©´ ë³µêµ¬
    if previewLayer == nil || previewLayer?.session !== session {
      logInfo("í”„ë¦¬ë·° ë ˆì´ì–´ ë³µêµ¬ í•„ìš” - ì¬ìƒì„±", category: .camera)
      setupAVFoundationPreview(with: session)
    } else if let layer = previewLayer {
      // í”„ë¦¬ë·° ë ˆì´ì–´ê°€ ìŠˆí¼ë ˆì´ì–´ì—ì„œ ì œê±°ë˜ì—ˆìœ¼ë©´ ë‹¤ì‹œ ì¶”ê°€
      if layer.superlayer == nil {
        logInfo("í”„ë¦¬ë·° ë ˆì´ì–´ ë‹¤ì‹œ ì¶”ê°€", category: .camera)
        self.layer.insertSublayer(layer, at: 0)
      }

      // í”„ë ˆì„ ì—…ë°ì´íŠ¸
      layer.frame = bounds
    }

    logDebug("í”„ë¦¬ë·° ë ˆì´ì–´ ë³´í˜¸ ì™„ë£Œ", category: .camera)
  }

  /// ë¹„ë””ì˜¤ í”„ë ˆì„ ëª¨ë‹ˆí„°ë§ ì„¤ì • (í†µê³„ ëª©ì )
  private func setupVideoMonitoring(with session: AVCaptureSession) {
    // ê¸°ì¡´ ë¹„ë””ì˜¤ ì¶œë ¥ ì œê±°
    if let existingOutput = videoOutput {
      session.removeOutput(existingOutput)
    }

    // ìƒˆë¡œìš´ ë¹„ë””ì˜¤ ì¶œë ¥ ìƒì„± (í†µê³„ ëª©ì )
    let newVideoOutput = AVCaptureVideoDataOutput()
    newVideoOutput.setSampleBufferDelegate(self, queue: videoOutputQueue)

    // ë¹„ë””ì˜¤ ì„¤ì • (ê°€ë²¼ìš´ ì²˜ë¦¬ìš©)
    newVideoOutput.videoSettings = [
      kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA
    ]

    // í”„ë ˆì„ ë“œë¡­ í—ˆìš© (ì„±ëŠ¥ ìµœì í™”)
    newVideoOutput.alwaysDiscardsLateVideoFrames = true

    // ì„¸ì…˜ì— ì¶”ê°€
    if session.canAddOutput(newVideoOutput) {
      session.addOutput(newVideoOutput)
      videoOutput = newVideoOutput
    } else {
      logError("ë¹„ë””ì˜¤ í”„ë ˆì„ ëª¨ë‹ˆí„°ë§ ì„¤ì • ì‹¤íŒ¨", category: .camera)
    }
  }

  /// ë¹„ë””ì˜¤ í”„ë ˆì„ ëª¨ë‹ˆí„°ë§ í•´ì œ
  private func removeVideoMonitoring() {
    guard let session = captureSession, let output = videoOutput else { return }

    session.removeOutput(output)
    videoOutput = nil
  }

  /// ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ì—…ë°ì´íŠ¸ (ê°œì„ ëœ ë²„ì „)
  private func updateStreamingStatus() {
    guard let manager = haishinKitManager else {
      isStreaming = false
      return
    }

    // ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœì™€ ì—°ê²° ìƒíƒœ ëª¨ë‘ í™•ì¸
    let newStreamingState = manager.isStreaming
    let connectionStatus = manager.connectionStatus
    let currentStatus = manager.currentStatus

    if isStreaming != newStreamingState {
      isStreaming = newStreamingState

      // ìƒíƒœ ë³€í™”ë¥¼ ë¡œê¹…
      if isStreaming {
        logInfo("ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ë¨ - ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì¶”ê°€ ë° í”„ë¦¬ë·° ë³´í˜¸", category: .streaming)

        // ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì¶”ê°€ ë° ë¹„ë””ì˜¤ ëª¨ë‹ˆí„°ë§ ì„¤ì •
        DispatchQueue.main.async { [weak self] in
          self?.addStreamingIndicatorOnly()
          // í”„ë¦¬ë·° ë ˆì´ì–´ê°€ í™œì„± ìƒíƒœì¸ì§€ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ë³µêµ¬
          self?.ensurePreviewLayerActive()
          // ë¹„ë””ì˜¤ í”„ë ˆì„ ëª¨ë‹ˆí„°ë§ ì„¤ì • (í†µê³„ ëª©ì )
          if let session = self?.captureSession {
            self?.setupVideoMonitoring(with: session)
          }
        }
      } else {
        logInfo("ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œë¨ - ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì œê±°", category: .streaming)

        // ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì œê±° ë° ë¹„ë””ì˜¤ ëª¨ë‹ˆí„°ë§ í•´ì œ
        DispatchQueue.main.async { [weak self] in
          self?.removeStreamingIndicator()
          // ë¹„ë””ì˜¤ í”„ë ˆì„ ëª¨ë‹ˆí„°ë§ í•´ì œ
          self?.removeVideoMonitoring()
          // í”„ë¦¬ë·° ë ˆì´ì–´ ë³µêµ¬
          self?.ensurePreviewLayerActive()
        }
      }
    }

    // ì—°ê²° ìƒíƒœì— ë”°ë¥¸ ìƒì„¸ UI ì—…ë°ì´íŠ¸
    DispatchQueue.main.async { [weak self] in
      self?.updateDetailedStreamingStatus(
        isStreaming: newStreamingState,
        connectionStatus: connectionStatus,
        status: currentStatus
      )
    }
  }

  /// ìƒì„¸ ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ UI ì—…ë°ì´íŠ¸ (ë¹„í™œì„±í™” - ì¤‘ë³µ ë°©ì§€)
  private func updateDetailedStreamingStatus(
    isStreaming: Bool,
    connectionStatus: String,
    status: LiveStreamStatus
  ) {
    // StreamingStatusView ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ì¤‘ë³µ ë°©ì§€)
  }

  /// ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ í‘œì‹œ ë·° ì—…ë°ì´íŠ¸ (ë¹„í™œì„±í™” - ì¤‘ë³µ ë°©ì§€)
  private func updateStreamingStatusView() {
    // StreamingStatusView ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ì¤‘ë³µ ë°©ì§€)
    logDebug("ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ë·° ì—…ë°ì´íŠ¸ ê±´ë„ˆëœ€ (ì¤‘ë³µ ë°©ì§€)", category: .streaming)
  }

  /// ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ëª¨ë‹ˆí„°ë§ ì„¤ì •
  private func setupStatusMonitoring() {
    // ê¸°ì¡´ íƒ€ì´ë¨¸ ì •ë¦¬
    statusMonitorTimer?.invalidate()

    // ìƒˆ íƒ€ì´ë¨¸ ì„¤ì • (1ì´ˆë§ˆë‹¤ ìƒíƒœ í™•ì¸)
    statusMonitorTimer = Timer.scheduledTimer(withTimeInterval: 1.0, repeats: true) {
      [weak self] _ in
      self?.updateStreamingStatus()
    }
  }

  /// ì •ë¦¬ ì‘ì—…
  deinit {
    statusMonitorTimer?.invalidate()
  }

  /// í”„ë¦¬ë·° ë ˆì´ì–´ ê°•ì œ ìƒˆë¡œê³ ì¹¨ (ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ë³€í™” ì‹œ)
  func refreshPreviewLayer() {
    logInfo("í”„ë¦¬ë·° ë ˆì´ì–´ ìƒˆë¡œê³ ì¹¨ ì‹œì‘ (ìŠ¤íŠ¸ë¦¬ë°: \(isStreaming))", category: .camera)

    guard let session = captureSession else {
      logError("ìº¡ì²˜ ì„¸ì…˜ì´ ì—†ì–´ ìƒˆë¡œê³ ì¹¨ ì‹¤íŒ¨", category: .camera)
      return
    }

    // ê¸°ì¡´ í”„ë¦¬ë·° ë ˆì´ì–´ ì™„ì „ ì œê±°
    previewLayer?.removeFromSuperlayer()
    previewLayer = nil
    hkPreviewLayer?.removeFromSuperview()
    hkPreviewLayer = nil

    // ì ì‹œ ëŒ€ê¸° í›„ ìƒíƒœì— ë§ëŠ” í”„ë¦¬ë·° ë ˆì´ì–´ ìƒì„±
    DispatchQueue.main.asyncAfter(deadline: .now() + 0.1) { [weak self] in
      guard let self = self else { return }

      logInfo("AVFoundation í”„ë¦¬ë·° ì„¤ì •", category: .camera)
      self.setupAVFoundationPreview(with: session)

      if self.isStreaming {
        logInfo("ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì¶”ê°€", category: .streaming)
        self.addStreamingIndicator()
      }

      logInfo("í”„ë¦¬ë·° ë ˆì´ì–´ ìƒˆë¡œê³ ì¹¨ ì™„ë£Œ", category: .camera)
    }
  }

  private func setupAVFoundationPreview(with session: AVCaptureSession) {
    logInfo("AVFoundation í”„ë¦¬ë·° ë ˆì´ì–´ ì„¤ì • ì¤‘...", category: .camera)

    let newPreviewLayer = AVCaptureVideoPreviewLayer(session: session)
    
    // 16:9 ë¹„ìœ¨ ê³„ì‚° ë° ì ìš©
    let aspectRatio: CGFloat = 16.0 / 9.0
    let viewBounds = bounds
    
    // 16:9 ë¹„ìœ¨ì— ë§ëŠ” í”„ë ˆì„ ê³„ì‚°
    let previewFrame: CGRect
    if viewBounds.width / viewBounds.height > aspectRatio {
      // ì„¸ë¡œê°€ ê¸°ì¤€: ë†’ì´ì— ë§ì¶°ì„œ ë„ˆë¹„ ê³„ì‚°
      let width = viewBounds.height * aspectRatio
      let offsetX = (viewBounds.width - width) / 2
      previewFrame = CGRect(x: offsetX, y: 0, width: width, height: viewBounds.height)
    } else {
      // ê°€ë¡œê°€ ê¸°ì¤€: ë„ˆë¹„ì— ë§ì¶°ì„œ ë†’ì´ ê³„ì‚°
      let height = viewBounds.width / aspectRatio
      let offsetY = (viewBounds.height - height) / 2
      previewFrame = CGRect(x: 0, y: offsetY, width: viewBounds.width, height: height)
    }
    
    newPreviewLayer.frame = previewFrame
    
    // ì‹¤ì œ ì†¡ì¶œ ì˜ì—­ê³¼ ì¼ì¹˜: resizeAspectFill ì‚¬ìš©
    // ì¹´ë©”ë¼ ì´ë¯¸ì§€ê°€ í”„ë ˆì„ì„ ì™„ì „íˆ ì±„ìš°ë„ë¡ ì„¤ì •
    newPreviewLayer.videoGravity = .resizeAspectFill

    if #available(iOS 17.0, *) {
      newPreviewLayer.connection?.videoRotationAngle = 0
    } else {
      newPreviewLayer.connection?.videoOrientation = .portrait
    }

    layer.insertSublayer(newPreviewLayer, at: 0)
    previewLayer = newPreviewLayer

    logInfo("AVFoundation í”„ë¦¬ë·° ë ˆì´ì–´ ì„¤ì • ì™„ë£Œ", category: .camera)
    logDebug("16:9 ë¹„ìœ¨ í”„ë ˆì„: \(previewFrame)", category: .camera)
    logDebug("videoGravity: resizeAspectFill (ì†¡ì¶œ ì˜ì—­ê³¼ ì¼ì¹˜)", category: .camera)
  }

  override func layoutSubviews() {
    super.layoutSubviews()

    // í”„ë¦¬ë·° ë ˆì´ì–´ í”„ë ˆì„ ì—…ë°ì´íŠ¸ (16:9 ë¹„ìœ¨ ìœ ì§€)
    DispatchQueue.main.async { [weak self] in
      guard let self = self else { return }
      
      // 16:9 ë¹„ìœ¨ ê³„ì‚°
      let aspectRatio: CGFloat = 16.0 / 9.0
      let viewBounds = self.bounds
      
      // 16:9 ë¹„ìœ¨ì— ë§ëŠ” í”„ë ˆì„ ì¬ê³„ì‚°
      let previewFrame: CGRect
      if viewBounds.width / viewBounds.height > aspectRatio {
        // ì„¸ë¡œê°€ ê¸°ì¤€: ë†’ì´ì— ë§ì¶°ì„œ ë„ˆë¹„ ê³„ì‚°
        let width = viewBounds.height * aspectRatio
        let offsetX = (viewBounds.width - width) / 2
        previewFrame = CGRect(x: offsetX, y: 0, width: width, height: viewBounds.height)
      } else {
        // ê°€ë¡œê°€ ê¸°ì¤€: ë„ˆë¹„ì— ë§ì¶°ì„œ ë†’ì´ ê³„ì‚°
        let height = viewBounds.width / aspectRatio
        let offsetY = (viewBounds.height - height) / 2
        previewFrame = CGRect(x: 0, y: offsetY, width: viewBounds.width, height: height)
      }
      
      // í”„ë¦¬ë·° ë ˆì´ì–´ í”„ë ˆì„ ì—…ë°ì´íŠ¸ (16:9 ë¹„ìœ¨ ì ìš©)
      self.previewLayer?.frame = previewFrame
      self.hkPreviewLayer?.frame = previewFrame

      // ë ˆì´ì–´ê°€ ì˜¬ë°”ë¥´ê²Œ í‘œì‹œë˜ë„ë¡ ê°•ì œ ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸
      if let layer = self.previewLayer {
        layer.setNeedsLayout()
        layer.layoutIfNeeded()
      }
      
      logDebug("ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸ - 16:9 í”„ë ˆì„: \(previewFrame)", category: .camera)
    }
  }

  // MARK: - Gesture Handlers

  @objc private func handleFocusTap(_ gesture: UITapGestureRecognizer) {
    let point = gesture.location(in: self)
    let focusPoint = CGPoint(
      x: point.x / bounds.width,
      y: point.y / bounds.height
    )

    setFocusPoint(focusPoint)
    showFocusIndicator(at: point)
  }

  @objc private func handleExposureDoubleTap(_ gesture: UITapGestureRecognizer) {
    let point = gesture.location(in: self)
    let exposurePoint = CGPoint(
      x: point.x / bounds.width,
      y: point.y / bounds.height
    )

    setExposurePoint(exposurePoint)
    showExposureIndicator(at: point)
  }

  @objc private func handleZoomPinch(_ gesture: UIPinchGestureRecognizer) {
    guard let device = getCurrentCameraDevice() else { return }

    do {
      try device.lockForConfiguration()

      let maxZoom = min(device.activeFormat.videoMaxZoomFactor, 4.0)
      let currentZoom = device.videoZoomFactor
      let newZoom = currentZoom * gesture.scale

      device.videoZoomFactor = max(1.0, min(newZoom, maxZoom))

      device.unlockForConfiguration()
      gesture.scale = 1.0

    } catch {
      logError("Zoom adjustment failed: \(error)", category: .camera)
    }
  }

  // MARK: - Camera Control Methods

  private func setFocusPoint(_ point: CGPoint) {
    guard let device = getCurrentCameraDevice() else { return }

    do {
      try device.lockForConfiguration()

      if device.isFocusPointOfInterestSupported {
        device.focusPointOfInterest = point
        device.focusMode = .autoFocus
      }

      if device.isExposurePointOfInterestSupported {
        device.exposurePointOfInterest = point
        device.exposureMode = .autoExpose
      }

      device.unlockForConfiguration()
    } catch {
      logError("Focus adjustment failed: \(error)", category: .camera)
    }
  }

  private func setExposurePoint(_ point: CGPoint) {
    guard let device = getCurrentCameraDevice() else { return }

    do {
      try device.lockForConfiguration()

      if device.isExposurePointOfInterestSupported {
        device.exposurePointOfInterest = point
        device.exposureMode = .continuousAutoExposure
      }

      device.unlockForConfiguration()
    } catch {
      logError("Exposure adjustment failed: \(error)", category: .camera)
    }
  }

  private func getCurrentCameraDevice() -> AVCaptureDevice? {
    return captureSession?.inputs.compactMap { input in
      (input as? AVCaptureDeviceInput)?.device
    }.first { $0.hasMediaType(.video) }
  }

  // MARK: - Visual Feedback

  private func showFocusIndicator(at point: CGPoint) {
    let indicator = FocusIndicatorView(frame: CGRect(x: 0, y: 0, width: 80, height: 80))
    indicator.center = point
    addSubview(indicator)

    indicator.animate {
      DispatchQueue.main.asyncAfter(deadline: .now() + 1.5) {
        indicator.removeFromSuperview()
      }
    }
  }

  private func showExposureIndicator(at point: CGPoint) {
    let indicator = ExposureIndicatorView(frame: CGRect(x: 0, y: 0, width: 60, height: 60))
    indicator.center = point
    addSubview(indicator)

    indicator.animate {
      DispatchQueue.main.asyncAfter(deadline: .now() + 1.5) {
        indicator.removeFromSuperview()
      }
    }
  }

  // MARK: - Streaming State Management

  func updateStreamingState(_ isStreaming: Bool) {
    self.isStreaming = isStreaming
    streamingStatusView.isHidden = !isStreaming
    updatePreviewLayer()
  }

  func updateStreamingStats(_ stats: StreamStats) {
    streamingStatusView.updateStats(stats)
  }
}

// MARK: - CameraControlOverlayDelegate

extension CameraPreviewUIView: CameraControlOverlayDelegate {
  func didTapRecord() {
    // ë…¹í™” ê¸°ëŠ¥ì€ ì œì™¸
    logInfo("Recording functionality not implemented", category: .general)
  }
}

// MARK: - AVCaptureVideoDataOutputSampleBufferDelegate

extension CameraPreviewUIView: AVCaptureVideoDataOutputSampleBufferDelegate {
  /// AVCaptureVideoDataOutputì—ì„œ í”„ë ˆì„ì„ ë°›ëŠ” ë¸ë¦¬ê²Œì´íŠ¸ ë©”ì„œë“œ
  func captureOutput(
    _ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer,
    from connection: AVCaptureConnection
  ) {
    // ğŸ¬ í™”ë©´ ìº¡ì²˜ ëª¨ë“œ: ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í”„ë ˆì„ ì €ì¥ (CameraScreenCapture.swift)
    processVideoFrameForScreenCapture(sampleBuffer)
    
    // ğŸ“¡ ì¼ë°˜ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ: HaishinKitì— í”„ë ˆì„ í†µê³„ ì „ë‹¬
    guard isStreaming, let manager = haishinKitManager else { return }

    // HaishinKitì— í”„ë ˆì„ í†µê³„ ì •ë³´ ì „ë‹¬ (ë¹„ë™ê¸° ì²˜ë¦¬)
    Task {
      await manager.processVideoFrame(sampleBuffer)
    }
  }

  func captureOutput(
    _ output: AVCaptureOutput, didDrop sampleBuffer: CMSampleBuffer,
    from connection: AVCaptureConnection
  ) {
    // í”„ë ˆì„ ë“œë¡­ì€ ì •ìƒì ì¸ í˜„ìƒì´ë¯€ë¡œ ë¡œê·¸ ë¹„í™œì„±í™”
  }
} 