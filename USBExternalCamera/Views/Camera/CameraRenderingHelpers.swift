//
//  CameraRenderingHelpers.swift
//  USBExternalCamera
//
//  Created by EUN YEON on 5/25/25.
//

import AVFoundation
import HaishinKit
import SwiftUI
import UIKit

// MARK: - Rendering Helpers Extension for CameraPreviewUIView

extension CameraPreviewUIView {

  /// ì†¡ì¶œìš© ê³ í•´ìƒë„ ì¹´ë©”ë¼ í”„ë ˆì„ê³¼ UI í•©ì„±
  ///
  /// 1920x1080 í¬ê¸°ë¡œ ê³ í’ˆì§ˆ ë Œë”ë§í•˜ì—¬ ì—…ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ì¸í•œ í™”ì§ˆ ì €í•˜ ë°©ì§€
  ///
  /// - Parameter cameraFrame: ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í”„ë ˆì„ (CVPixelBuffer)
  /// - Parameter streamingSize: ì†¡ì¶œ ëª©í‘œ í•´ìƒë„ (1920x1080)
  /// - Returns: ê³ í•´ìƒë„ í•©ì„± ì´ë¯¸ì§€ ë˜ëŠ” nil
  func renderCameraFrameWithUIForStreaming(cameraFrame: CVPixelBuffer, streamingSize: CGSize)
    -> UIImage?
  {

    // Step 1: ì¹´ë©”ë¼ í”„ë ˆì„ì„ UIImageë¡œ ë³€í™˜
    guard let cameraImage = cameraFrame.toUIImage() else {
      logError("ì¹´ë©”ë¼ í”„ë ˆì„ â†’ UIImage ë³€í™˜ ì‹¤íŒ¨", category: .performance)
      return nil
    }
    logDebug("ì¹´ë©”ë¼ ì´ë¯¸ì§€ ë³€í™˜ ì„±ê³µ: \(cameraImage.size)", category: .performance)

    // Step 2: UI ì˜¤ë²„ë ˆì´ë¥¼ ê³ í•´ìƒë„ë¡œ ìƒì„± (1:1 â†’ 16:9 ë¹„ìœ¨ ê°•ì œ ë³€í™˜)
    // ë‹¨ë§ í¬ê¸°ì—ì„œ ì†¡ì¶œ í¬ê¸°ë¡œ ìŠ¤ì¼€ì¼ë§ ë¹„ìœ¨ ê³„ì‚°
    let currentSize = bounds.size
    let originalAspectRatio = currentSize.width / currentSize.height
    let targetAspectRatio = streamingSize.width / streamingSize.height

    let scaleX = streamingSize.width / currentSize.width
    let scaleY = streamingSize.height / currentSize.height
    let scale = max(scaleX, scaleY)  // **Aspect Fill**: í™”ë©´ ê½‰ ì±„ìš°ê¸° (1:1 ë¬¸ì œ í•´ê²°)

    logDebug("ë¹„ìœ¨ ë¶„ì„:", category: .performance)
    logDebug(
      "  â€¢ ì›ë³¸ UI: \(currentSize) (ë¹„ìœ¨: \(String(format: "%.2f", originalAspectRatio)))",
      category: .performance)
    logDebug(
      "  â€¢ ëª©í‘œ ì†¡ì¶œ: \(streamingSize) (ë¹„ìœ¨: \(String(format: "%.2f", targetAspectRatio)))",
      category: .performance)
    logDebug("  â€¢ Aspect Fill ìŠ¤ì¼€ì¼: \(String(format: "%.2f", scale))x", category: .performance)

    // 1:1 ë¹„ìœ¨ ë¬¸ì œ ê°ì§€
    if abs(originalAspectRatio - 1.0) < 0.2 {
      logWarning("1:1 ë¬¸ì œ ê°ì§€ - ì¹´ë©”ë¼+UI í•©ì„±ì—ì„œ ì •ì‚¬ê°í˜• UI ê°ì§€ â†’ Aspect Fill ì ìš©", category: .performance)
    }

    let uiRenderer = UIGraphicsImageRenderer(size: streamingSize)
    let uiOverlay = uiRenderer.image { context in
      // Aspect Fill ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ UI ë Œë”ë§ (í™”ë©´ ê½‰ ì±„ìš°ê¸°)
      context.cgContext.scaleBy(x: scale, y: scale)

      // UIê°€ ì˜ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¤‘ì•™ ì •ë ¬
      let scaledSize = CGSize(width: currentSize.width * scale, height: currentSize.height * scale)
      let offsetX = (streamingSize.width - scaledSize.width) / 2.0
      let offsetY = (streamingSize.height - scaledSize.height) / 2.0
      context.cgContext.translateBy(x: offsetX / scale, y: offsetY / scale)

      // í”„ë¦¬ë·° ë ˆì´ì–´ë¥¼ ì œì™¸í•œ ëª¨ë“  ì„œë¸Œë·° ë Œë”ë§
      for subview in subviews {
        // AVCaptureVideoPreviewLayerëŠ” ì œì™¸ (ì¹´ë©”ë¼ í”„ë ˆì„ìœ¼ë¡œ ëŒ€ì²´ë¨)
        if !(subview.layer is AVCaptureVideoPreviewLayer) {
          subview.layer.render(in: context.cgContext)
        }
      }
    }
    logDebug("UI ì˜¤ë²„ë ˆì´ ìƒì„± ì™„ë£Œ: \(streamingSize)", category: .performance)

    // Step 3: ì¹´ë©”ë¼ ì´ë¯¸ì§€ì™€ UI ì˜¤ë²„ë ˆì´ë¥¼ ê³ í•´ìƒë„ë¡œ í•©ì„±
    let finalRenderer = UIGraphicsImageRenderer(size: streamingSize)
    let compositeImage = finalRenderer.image { context in
      let rect = CGRect(origin: .zero, size: streamingSize)

      // 3-1: ì¹´ë©”ë¼ ì´ë¯¸ì§€ë¥¼ UIì™€ ë™ì¼í•œ ë¹„ìœ¨ë¡œ ì—…ìŠ¤ì¼€ì¼ë§
      // ë‹¨ë§ì—ì„œì˜ ì¹´ë©”ë¼ í”„ë¦¬ë·° ì˜ì—­ì„ ê³„ì‚°
      let cameraPreviewRect = calculateCameraPreviewRect(in: currentSize)

      // ì¹´ë©”ë¼ í”„ë¦¬ë·° ì˜ì—­ì„ ë™ì¼í•œ ìŠ¤ì¼€ì¼ ë¹„ìœ¨ë¡œ ì—…ìŠ¤ì¼€ì¼ë§
      let scaledCameraRect = CGRect(
        x: cameraPreviewRect.origin.x * scale,
        y: cameraPreviewRect.origin.y * scale,
        width: cameraPreviewRect.size.width * scale,
        height: cameraPreviewRect.size.height * scale
      )

      logDebug("ì¹´ë©”ë¼ ì˜ì—­ ìŠ¤ì¼€ì¼ë§: \(cameraPreviewRect) â†’ \(scaledCameraRect)", category: .performance)

      // ì¹´ë©”ë¼ ì´ë¯¸ì§€ë¥¼ ìŠ¤ì¼€ì¼ëœ ì˜ì—­ì— ë§ì¶° ê·¸ë¦¬ê¸° (Aspect Fill ë°©ì‹)
      // Aspect Fillë¡œ ê·¸ë ¤ì„œ ì¹´ë©”ë¼ ì´ë¯¸ì§€ê°€ ì˜ë¦¬ì§€ ì•Šë„ë¡ í•¨
      let cameraAspectRatio = cameraImage.size.width / cameraImage.size.height
      let rectAspectRatio = scaledCameraRect.width / scaledCameraRect.height

      let drawRect: CGRect
      if cameraAspectRatio > rectAspectRatio {
        // ì¹´ë©”ë¼ê°€ ë” ë„“ìŒ: ë†’ì´ë¥¼ ë§ì¶”ê³  ê°€ë¡œëŠ” ë„˜ì¹¨
        let drawHeight = scaledCameraRect.height
        let drawWidth = drawHeight * cameraAspectRatio
        let offsetX = scaledCameraRect.origin.x + (scaledCameraRect.width - drawWidth) / 2
        drawRect = CGRect(
          x: offsetX, y: scaledCameraRect.origin.y, width: drawWidth, height: drawHeight)
      } else {
        // ì¹´ë©”ë¼ê°€ ë” ë†’ìŒ: ë„ˆë¹„ë¥¼ ë§ì¶”ê³  ì„¸ë¡œëŠ” ë„˜ì¹¨
        let drawWidth = scaledCameraRect.width
        let drawHeight = drawWidth / cameraAspectRatio
        let offsetY = scaledCameraRect.origin.y + (scaledCameraRect.height - drawHeight) / 2
        drawRect = CGRect(
          x: scaledCameraRect.origin.x, y: offsetY, width: drawWidth, height: drawHeight)
      }

      logDebug("ì¹´ë©”ë¼ ì´ë¯¸ì§€ Aspect Fill ê·¸ë¦¬ê¸°: \(scaledCameraRect) â†’ \(drawRect)", category: .performance)
      cameraImage.draw(in: drawRect)

      // 3-2: UI ì˜¤ë²„ë ˆì´ë¥¼ ì „ì²´ í™”ë©´ì— í•©ì„±
      uiOverlay.draw(in: rect, blendMode: .normal, alpha: 1.0)
    }

    logDebug("ìµœì¢… ì´ë¯¸ì§€ í•©ì„± ì™„ë£Œ: \(streamingSize)", category: .performance)
    return compositeImage
  }

  /// ë‹¨ë§ í™”ë©´ì—ì„œ ì¹´ë©”ë¼ í”„ë¦¬ë·°ê°€ ì°¨ì§€í•˜ëŠ” 16:9 ì˜ì—­ ê³„ì‚°
  ///
  /// ì‹¤ì œ ì†¡ì¶œë˜ëŠ” 16:9 ë¹„ìœ¨ ì˜ì—­ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
  /// ì´ë¥¼ í†µí•´ í”„ë¦¬ë·°ì™€ ì†¡ì¶œ í™”ë©´ì´ ì •í™•íˆ ì¼ì¹˜í•˜ë„ë¡ í•©ë‹ˆë‹¤.
  ///
  /// - Parameter containerSize: ì»¨í…Œì´ë„ˆ ë·°ì˜ í¬ê¸° (ë‹¨ë§ í™”ë©´ í¬ê¸°)
  /// - Returns: 16:9 ë¹„ìœ¨ë¡œ ê³„ì‚°ëœ ì¹´ë©”ë¼ í”„ë¦¬ë·° ì˜ì—­
  func calculateCameraPreviewRect(in containerSize: CGSize) -> CGRect {
    // 16:9 ë¹„ìœ¨ë¡œ ê³ ì •ëœ ì†¡ì¶œ ì˜ì—­ ê³„ì‚°
    let aspectRatio: CGFloat = 16.0 / 9.0

    let previewFrame: CGRect
    if containerSize.width / containerSize.height > aspectRatio {
      // ì„¸ë¡œê°€ ê¸°ì¤€: ë†’ì´ì— ë§ì¶°ì„œ ë„ˆë¹„ ê³„ì‚°
      let width = containerSize.height * aspectRatio
      let offsetX = (containerSize.width - width) / 2
      previewFrame = CGRect(x: offsetX, y: 0, width: width, height: containerSize.height)
    } else {
      // ê°€ë¡œê°€ ê¸°ì¤€: ë„ˆë¹„ì— ë§ì¶°ì„œ ë†’ì´ ê³„ì‚°
      let height = containerSize.width / aspectRatio
      let offsetY = (containerSize.height - height) / 2
      previewFrame = CGRect(x: 0, y: offsetY, width: containerSize.width, height: height)
    }

    logDebug("16:9 ë¹„ìœ¨ ì†¡ì¶œ ì˜ì—­: \(previewFrame)", category: .camera)
    return previewFrame
  }

  /// AVCaptureVideoPreviewLayerì˜ ì‹¤ì œ ë¹„ë””ì˜¤ í‘œì‹œ ì˜ì—­ ê³„ì‚°
  ///
  /// videoGravity ì„¤ì •ì— ë”°ë¼ ì‹¤ì œë¡œ ë¹„ë””ì˜¤ê°€ í‘œì‹œë˜ëŠ” ì˜ì—­ì„ ì •í™•íˆ ê³„ì‚°í•©ë‹ˆë‹¤.
  /// - resizeAspect: ë¹„ë””ì˜¤ ë¹„ìœ¨ ìœ ì§€, ë ˆì´ì–´ ë‚´ë¶€ì— ë§ì¶¤ (ê²€ì€ ì—¬ë°± ê°€ëŠ¥)
  /// - resizeAspectFill: ë¹„ë””ì˜¤ ë¹„ìœ¨ ìœ ì§€, ë ˆì´ì–´ ì „ì²´ë¥¼ ì±„ì›€ (ì¼ë¶€ ì˜ë¦¼ ê°€ëŠ¥)
  /// - resize: ë¹„ë””ì˜¤ë¥¼ ë ˆì´ì–´ í¬ê¸°ì— ë§ì¶° ëŠ˜ë¦¼ (ë¹„ìœ¨ ì™œê³¡ ê°€ëŠ¥)
  ///
  /// - Parameter previewLayer: ì¹´ë©”ë¼ í”„ë¦¬ë·° ë ˆì´ì–´
  /// - Returns: ì‹¤ì œ ë¹„ë””ì˜¤ê°€ í‘œì‹œë˜ëŠ” ì˜ì—­
  func calculateActualVideoRect(previewLayer: AVCaptureVideoPreviewLayer) -> CGRect {
    let layerBounds = previewLayer.bounds
    let videoGravity = previewLayer.videoGravity

    // ì¹´ë©”ë¼ ì„¸ì…˜ì—ì„œ ë¹„ë””ì˜¤ ì…ë ¥ì˜ ì‹¤ì œ í•´ìƒë„ ê°€ì ¸ì˜¤ê¸°
    guard let session = previewLayer.session else {
      logWarning("ì„¸ì…˜ ì—†ìŒ, ë ˆì´ì–´ ì „ì²´ ì˜ì—­ ë°˜í™˜: \(layerBounds)", category: .camera)
      return layerBounds
    }

    // í˜„ì¬ í™œì„± ë¹„ë””ì˜¤ ì…ë ¥ì˜ í•´ìƒë„ ì°¾ê¸°
    var videoSize: CGSize?
    for input in session.inputs {
      if let deviceInput = input as? AVCaptureDeviceInput,
        deviceInput.device.hasMediaType(.video)
      {
        let format = deviceInput.device.activeFormat
        let dimensions = CMVideoFormatDescriptionGetDimensions(format.formatDescription)
        videoSize = CGSize(width: Int(dimensions.width), height: Int(dimensions.height))
        break
      }
    }

    guard let actualVideoSize = videoSize else {
      logWarning("ë¹„ë””ì˜¤ í¬ê¸° í™•ì¸ ë¶ˆê°€, ë ˆì´ì–´ ì „ì²´ ì˜ì—­ ë°˜í™˜: \(layerBounds)", category: .camera)
      return layerBounds
    }

    logDebug(
      "ë¹„ë””ì˜¤ í¬ê¸°: \(actualVideoSize), ë ˆì´ì–´ í¬ê¸°: \(layerBounds.size), ì¤‘ë ¥: \(videoGravity)",
      category: .camera)

    let videoRect: CGRect

    switch videoGravity {
    case .resizeAspectFill:
      // Aspect Fill: ë¹„ë””ì˜¤ ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ ë ˆì´ì–´ ì „ì²´ë¥¼ ì±„ì›€ (ì¼ë¶€ ì˜ë¦¼ ê°€ëŠ¥)
      let videoAspectRatio = actualVideoSize.width / actualVideoSize.height
      let layerAspectRatio = layerBounds.width / layerBounds.height

      if videoAspectRatio > layerAspectRatio {
        // ë¹„ë””ì˜¤ê°€ ë” ë„“ìŒ: ì„¸ë¡œë¥¼ ë ˆì´ì–´ì— ë§ì¶”ê³  ê°€ë¡œëŠ” ë„˜ì¹¨
        let scaledHeight = layerBounds.height
        let scaledWidth = scaledHeight * videoAspectRatio
        let offsetX = (layerBounds.width - scaledWidth) / 2
        videoRect = CGRect(x: offsetX, y: 0, width: scaledWidth, height: scaledHeight)
      } else {
        // ë¹„ë””ì˜¤ê°€ ë” ë†’ìŒ: ê°€ë¡œë¥¼ ë ˆì´ì–´ì— ë§ì¶”ê³  ì„¸ë¡œëŠ” ë„˜ì¹¨
        let scaledWidth = layerBounds.width
        let scaledHeight = scaledWidth / videoAspectRatio
        let offsetY = (layerBounds.height - scaledHeight) / 2
        videoRect = CGRect(x: 0, y: offsetY, width: scaledWidth, height: scaledHeight)
      }

    case .resizeAspect:
      // Aspect Fit: ë¹„ë””ì˜¤ ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ ë ˆì´ì–´ ë‚´ë¶€ì— ë§ì¶¤ (ê²€ì€ ì—¬ë°± ê°€ëŠ¥)
      videoRect = AVMakeRect(aspectRatio: actualVideoSize, insideRect: layerBounds)

    case .resize:
      // ë¹„ìœ¨ ë¬´ì‹œí•˜ê³  ë ˆì´ì–´ ì „ì²´ë¥¼ ì±„ì›€
      videoRect = layerBounds

    default:
      videoRect = layerBounds
    }

    logDebug("ê³„ì‚°ëœ ì‹¤ì œ ë¹„ë””ì˜¤ ì˜ì—­: \(videoRect)", category: .camera)
    return videoRect
  }

  /// ì†¡ì¶œìš© ê³ í•´ìƒë„ UIë§Œ ë Œë”ë§ (ì¹´ë©”ë¼ í”„ë ˆì„ ì—†ì„ ë•Œ)
  ///
  /// **1:1 â†’ 16:9 ë¹„ìœ¨ ê°•ì œ ë³€í™˜ ì ìš©**
  /// - Parameter streamingSize: ì†¡ì¶œ ëª©í‘œ í•´ìƒë„ (1920x1080)
  /// - Returns: ê³ í•´ìƒë„ UI ì´ë¯¸ì§€ ë˜ëŠ” nil
  func renderUIOnlyForStreaming(streamingSize: CGSize) -> UIImage? {
    let currentSize = bounds.size
    guard currentSize.width > 0 && currentSize.height > 0 else {
      logError("ìœ íš¨í•˜ì§€ ì•Šì€ ë·° í¬ê¸°: \(currentSize)", category: .performance)
      return nil
    }

    // ì›ë³¸ UI ë¹„ìœ¨ ê³„ì‚°
    let originalAspectRatio = currentSize.width / currentSize.height
    let targetAspectRatio = streamingSize.width / streamingSize.height

    logDebug("ë¹„ìœ¨ ë¶„ì„:", category: .performance)
    logDebug(
      "  â€¢ ì›ë³¸ UI: \(currentSize) (ë¹„ìœ¨: \(String(format: "%.2f", originalAspectRatio)))",
      category: .performance)
    logDebug(
      "  â€¢ ëª©í‘œ ì†¡ì¶œ: \(streamingSize) (ë¹„ìœ¨: \(String(format: "%.2f", targetAspectRatio)))",
      category: .performance)

    // **Aspect Fill ë°©ì‹**: í™”ë©´ì„ ê½‰ ì±„ìš°ê¸° ìœ„í•´ max ì‚¬ìš© (1:1 ë¬¸ì œ í•´ê²°)
    let scaleX = streamingSize.width / currentSize.width
    let scaleY = streamingSize.height / currentSize.height
    let scale = max(scaleX, scaleY)  // Aspect Fill - í™”ë©´ ê½‰ ì±„ìš°ê¸°

    logDebug(
      "  â€¢ ìŠ¤ì¼€ì¼ë§: scaleX=\(String(format: "%.2f", scaleX)), scaleY=\(String(format: "%.2f", scaleY))",
      category: .performance)
    logDebug("  â€¢ Aspect Fill ìµœì¢… ìŠ¤ì¼€ì¼: \(String(format: "%.2f", scale))x", category: .performance)

    // 1:1 ë¹„ìœ¨ ë¬¸ì œ ê°ì§€ ê²½ê³  (ê°œì„ ëœ ê°ì§€)
    if abs(originalAspectRatio - 1.0) < 0.2 {  // 0.8~1.2 ì‚¬ì´ëŠ” ì •ì‚¬ê°í˜•ìœ¼ë¡œ ê°„ì£¼
      logWarning(
        "1:1 ë¬¸ì œ ê°ì§€ - ì›ë³¸ UIê°€ ì •ì‚¬ê°í˜•ì— ê°€ê¹Œì›€ (ë¹„ìœ¨: \(String(format: "%.2f", originalAspectRatio))) â†’ Aspect Fillë¡œ 16:9 ë³€í™˜",
        category: .performance)
    }

    let renderer = UIGraphicsImageRenderer(size: streamingSize)
    return renderer.image { context in
      // ë°°ê²½ì„ ê²€ì€ìƒ‰ìœ¼ë¡œ ì±„ìš°ê¸° (ì¹´ë©”ë¼ í”„ë ˆì„ì´ ì—†ì„ ë•Œ)
      context.cgContext.setFillColor(UIColor.black.cgColor)
      context.cgContext.fill(CGRect(origin: .zero, size: streamingSize))

      // Aspect Fill ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ UI ë Œë”ë§ (í™”ë©´ ê½‰ ì±„ìš°ê¸°)
      context.cgContext.scaleBy(x: scale, y: scale)

      // UIê°€ ì˜ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¤‘ì•™ ì •ë ¬
      let scaledSize = CGSize(width: currentSize.width * scale, height: currentSize.height * scale)
      let offsetX = (streamingSize.width - scaledSize.width) / 2.0
      let offsetY = (streamingSize.height - scaledSize.height) / 2.0
      context.cgContext.translateBy(x: offsetX / scale, y: offsetY / scale)

      layer.render(in: context.cgContext)

      logDebug(
        "Aspect Fill ë Œë”ë§ ì™„ë£Œ: \(originalAspectRatio) â†’ \(targetAspectRatio)", category: .performance)
    }
  }

  /// ë‹¨ë§ í‘œì‹œìš© ì¹´ë©”ë¼ í”„ë ˆì„ê³¼ UI í•©ì„± (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
  ///
  /// ì´ ë©”ì„œë“œëŠ” ë‹¤ìŒ 3ë‹¨ê³„ë¡œ ì´ë¯¸ì§€ë¥¼ í•©ì„±í•©ë‹ˆë‹¤:
  /// 1. CVPixelBuffer(ì¹´ë©”ë¼ í”„ë ˆì„)ë¥¼ UIImageë¡œ ë³€í™˜
  /// 2. UI ì„œë¸Œë·°ë“¤ì„ ë³„ë„ ì´ë¯¸ì§€ë¡œ ë Œë”ë§ (ì˜¤ë²„ë ˆì´)
  /// 3. ì¹´ë©”ë¼ ì´ë¯¸ì§€ ìœ„ì— UI ì˜¤ë²„ë ˆì´ë¥¼ í•©ì„±
  ///
  /// **í•©ì„± ë°©ì‹:**
  /// - ì¹´ë©”ë¼ ì´ë¯¸ì§€: aspect fillë¡œ ë°°ì¹˜ (ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ í™”ë©´ ì „ì²´ ì±„ì›€)
  /// - UI ì˜¤ë²„ë ˆì´: ì „ì²´ í™”ë©´ì— normal ë¸”ë Œë“œ ëª¨ë“œë¡œ í•©ì„±
  ///
  /// - Parameter cameraFrame: ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í”„ë ˆì„ (CVPixelBuffer)
  /// - Parameter viewSize: ìµœì¢… ì¶œë ¥ ì´ë¯¸ì§€ í¬ê¸° (ë‹¨ë§ í™”ë©´ í¬ê¸°)
  /// - Returns: í•©ì„±ëœ ìµœì¢… ì´ë¯¸ì§€ ë˜ëŠ” nil
  func renderCameraFrameWithUI(cameraFrame: CVPixelBuffer, viewSize: CGSize) -> UIImage? {

    // Step 1: ì¹´ë©”ë¼ í”„ë ˆì„ì„ UIImageë¡œ ë³€í™˜
    guard let cameraImage = cameraFrame.toUIImage() else {
      logError("ì¹´ë©”ë¼ í”„ë ˆì„ â†’ UIImage ë³€í™˜ ì‹¤íŒ¨", category: .performance)
      return nil
    }
    logDebug("ì¹´ë©”ë¼ ì´ë¯¸ì§€ ë³€í™˜ ì„±ê³µ: \(cameraImage.size)", category: .performance)

    // Step 2: UI ì˜¤ë²„ë ˆì´ ìƒì„± (ì¹´ë©”ë¼ í”„ë¦¬ë·° ë ˆì´ì–´ ì œì™¸)
    // ëª¨ë“  ì„œë¸Œë·°(ë²„íŠ¼, ë¼ë²¨, ì›Œí„°ë§ˆí¬ ë“±)ë¥¼ ë³„ë„ ì´ë¯¸ì§€ë¡œ ë Œë”ë§
    let uiRenderer = UIGraphicsImageRenderer(size: viewSize)
    let uiOverlay = uiRenderer.image { context in
      // í”„ë¦¬ë·° ë ˆì´ì–´ë¥¼ ì œì™¸í•œ ëª¨ë“  ì„œë¸Œë·° ë Œë”ë§
      // (ì¹´ë©”ë¼ í”„ë¦¬ë·°ëŠ” ì´ë¯¸ cameraImageì— í¬í•¨ë˜ì–´ ìˆìŒ)
      for subview in subviews {
        subview.layer.render(in: context.cgContext)
      }
    }
    logDebug("UI ì˜¤ë²„ë ˆì´ ìƒì„± ì™„ë£Œ", category: .performance)

    // Step 3: ì¹´ë©”ë¼ ì´ë¯¸ì§€ì™€ UI ì˜¤ë²„ë ˆì´ í•©ì„±
    let finalRenderer = UIGraphicsImageRenderer(size: viewSize)
    let compositeImage = finalRenderer.image { context in
      let rect = CGRect(origin: .zero, size: viewSize)

      // 3-1: ì¹´ë©”ë¼ ì´ë¯¸ì§€ë¥¼ ë·° í¬ê¸°ì— ë§ê²Œ ê·¸ë¦¬ê¸° (aspect fill ì ìš©)
      // Aspect Fill: ì›ë³¸ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ ì „ì²´ ì˜ì—­ì„ ì±„ì›€ (ì¼ë¶€ ì˜ë¦¼ ê°€ëŠ¥í•˜ì§€ë§Œ í™”ë©´ ê½‰ ì±„ì›€)
      let cameraAspectRatio = cameraImage.size.width / cameraImage.size.height
      let rectAspectRatio = rect.width / rect.height

      let drawRect: CGRect
      if cameraAspectRatio > rectAspectRatio {
        // ì¹´ë©”ë¼ê°€ ë” ë„“ìŒ: ë†’ì´ë¥¼ ë§ì¶”ê³  ê°€ë¡œëŠ” ë„˜ì¹¨
        let drawHeight = rect.height
        let drawWidth = drawHeight * cameraAspectRatio
        let offsetX = (rect.width - drawWidth) / 2
        drawRect = CGRect(x: offsetX, y: 0, width: drawWidth, height: drawHeight)
      } else {
        // ì¹´ë©”ë¼ê°€ ë” ë†’ìŒ: ë„ˆë¹„ë¥¼ ë§ì¶”ê³  ì„¸ë¡œëŠ” ë„˜ì¹¨
        let drawWidth = rect.width
        let drawHeight = drawWidth / cameraAspectRatio
        let offsetY = (rect.height - drawHeight) / 2
        drawRect = CGRect(x: 0, y: offsetY, width: drawWidth, height: drawHeight)
      }

      cameraImage.draw(in: drawRect)

      // 3-2: UI ì˜¤ë²„ë ˆì´ë¥¼ ì „ì²´ í™”ë©´ì— í•©ì„±
      // normal ë¸”ë Œë“œ ëª¨ë“œ: íˆ¬ëª… ì˜ì—­ì€ ê·¸ëŒ€ë¡œ ë‘ê³  ë¶ˆíˆ¬ëª… ì˜ì—­ë§Œ ë®ì–´ì”€
      uiOverlay.draw(in: rect, blendMode: .normal, alpha: 1.0)
    }

    logDebug("ìµœì¢… ì´ë¯¸ì§€ í•©ì„± ì™„ë£Œ: \(viewSize)", category: .performance)
    return compositeImage
  }

  /// ì†¡ì¶œ í•´ìƒë„ì— ë”°ë¥¸ ìµœì  ìº¡ì²˜ ì‚¬ì´ì¦ˆ ê³„ì‚° (16:9 ë¹„ìœ¨ ê³ ì •)
  ///
  /// **16:9 ë¹„ìœ¨ ê°•ì œ ì ìš©:**
  /// - 480p(854x480) â†’ 16:9 ë¹„ìœ¨ë¡œ ìˆ˜ì • í›„ 2ë°° ì—…ìŠ¤ì¼€ì¼
  /// - 720p(1280x720) â†’ 2ë°° ì—…ìŠ¤ì¼€ì¼
  /// - 1080p(1920x1080) â†’ ë™ì¼ í•´ìƒë„ ìº¡ì²˜
  /// - ëª¨ë“  í•´ìƒë„ë¥¼ 16:9 ë¹„ìœ¨ë¡œ ê°•ì œ ë³€í™˜
  ///
  /// - Returns: 16:9 ë¹„ìœ¨ì´ ë³´ì¥ëœ ìµœì  ìº¡ì²˜ í•´ìƒë„
  func getOptimalCaptureSize() -> CGSize {
    // HaishinKitManagerì—ì„œ í˜„ì¬ ìŠ¤íŠ¸ë¦¬ë° ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    guard let manager = haishinKitManager,
      let settings = manager.getCurrentSettings()
    else {
      // ê¸°ë³¸ê°’: 720p (16:9 ë¹„ìœ¨)
      return CGSize(width: 1280, height: 720)
    }

    let streamWidth = settings.videoWidth
    let streamHeight = settings.videoHeight

    // 16:9 ë¹„ìœ¨ ê°•ì œ ì ìš© (ìœ íŠœë¸Œ ë¼ì´ë¸Œ í‘œì¤€)
    let aspectRatio: CGFloat = 16.0 / 9.0

    // ì†¡ì¶œ í•´ìƒë„ë¥¼ 16:9 ë¹„ìœ¨ë¡œ ìˆ˜ì •
    let correctedStreamSize: CGSize
    let currentAspectRatio = CGFloat(streamWidth) / CGFloat(streamHeight)

    if abs(currentAspectRatio - aspectRatio) > 0.1 {
      // ë¹„ìœ¨ì´ 16:9ê°€ ì•„ë‹ˆë©´ ê°•ì œë¡œ ìˆ˜ì •
      let correctedHeight = CGFloat(streamWidth) / aspectRatio
      correctedStreamSize = CGSize(width: streamWidth, height: Int(correctedHeight))
      logInfo(
        "ë¹„ìœ¨ìˆ˜ì •: \(streamWidth)x\(streamHeight) (ë¹„ìœ¨: \(String(format: "%.2f", currentAspectRatio))) â†’ \(correctedStreamSize) (16:9)",
        category: .streaming)
    } else {
      correctedStreamSize = CGSize(width: streamWidth, height: streamHeight)
      logDebug("ì´ë¯¸ 16:9 ë¹„ìœ¨: \(correctedStreamSize)", category: .streaming)
    }

    // 16:9 ë¹„ìœ¨ ê¸°ë°˜ ìµœì  ìº¡ì²˜ í•´ìƒë„ ê³„ì‚°
    let captureSize: CGSize
    let width = Int(correctedStreamSize.width)
    let height = Int(correctedStreamSize.height)

    switch (width, height) {
    case (640...854, 360...480):
      // 480p ê³„ì—´ â†’ 2ë°° ì—…ìŠ¤ì¼€ì¼
      captureSize = CGSize(width: 1280, height: 720)  // 720pë¡œ ìº¡ì²˜
      logDebug("16:9 ìº¡ì²˜ - 480pê³„ì—´ ì†¡ì¶œ â†’ 720p ìº¡ì²˜: \(captureSize)", category: .streaming)

    case (1280, 720):
      // ğŸ¯ 720p ëŠê¹€ ê°œì„ : 1.5ë°° ì—…ìŠ¤ì¼€ì¼ë¡œ ì„±ëŠ¥ ë¶€í•˜ ê°ì†Œ
      captureSize = CGSize(width: 1920, height: 1080)  // 1080pë¡œ ìº¡ì²˜ (ê¸°ì¡´ 1440p â†’ 1080p)
      logDebug("16:9 ìº¡ì²˜ - 720p ì†¡ì¶œ â†’ 1080p ìº¡ì²˜ (ëŠê¹€ ê°œì„ ): \(captureSize)", category: .streaming)

    case (1920, 1080):
      // 1080p â†’ ë™ì¼ í•´ìƒë„ (ì•ˆì •ì„± ìš°ì„ )
      captureSize = CGSize(width: 1920, height: 1080)
      logDebug("16:9 ìº¡ì²˜ - 1080p ì†¡ì¶œ â†’ 1080p ìº¡ì²˜: \(captureSize)", category: .streaming)

    default:
      // ì‚¬ìš©ì ì •ì˜ â†’ 16:9 ë¹„ìœ¨ë¡œ ê°•ì œ ë³€í™˜ í›„ ìº¡ì²˜
      let targetWidth = max(width, 1280)  // ìµœì†Œ 720p ë„ˆë¹„
      let targetHeight = Int(CGFloat(targetWidth) / aspectRatio)
      captureSize = CGSize(width: targetWidth, height: targetHeight)
      logDebug("16:9 ìº¡ì²˜ - ì‚¬ìš©ìì •ì˜ â†’ 16:9 ê°•ì œë³€í™˜ ìº¡ì²˜: \(captureSize)", category: .streaming)
    }

    // 16ì˜ ë°°ìˆ˜ë¡œ ì •ë ¬ (VideoCodec í˜¸í™˜ì„±)
    let alignedWidth = ((Int(captureSize.width) + 15) / 16) * 16
    let alignedHeight = ((Int(captureSize.height) + 15) / 16) * 16
    let finalSize = CGSize(width: alignedWidth, height: alignedHeight)

    // ìµœì¢… 16:9 ë¹„ìœ¨ ê²€ì¦
    let finalAspectRatio = CGFloat(alignedWidth) / CGFloat(alignedHeight)
    logDebug("ìµœì¢…ê²€ì¦ - 16ë°°ìˆ˜ ì •ë ¬: \(captureSize) â†’ \(finalSize)", category: .streaming)
    logDebug(
      "ìµœì¢…ê²€ì¦ - ë¹„ìœ¨ í™•ì¸: \(String(format: "%.2f", finalAspectRatio)) (16:9 â‰ˆ 1.78)",
      category: .streaming)

    return finalSize
  }
}
