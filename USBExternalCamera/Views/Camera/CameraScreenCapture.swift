//
//  CameraScreenCapture.swift
//  USBExternalCamera
//
//  Created by EUN YEON on 5/25/25.
//

import AVFoundation
import HaishinKit
import SwiftUI
import UIKit
import Foundation

// MARK: - Screen Capture Extension for CameraPreviewUIView

extension CameraPreviewUIView {
  
  // MARK: - Screen Capture Properties
  
  /// í™”ë©´ ìº¡ì²˜ìš© íƒ€ì´ë¨¸
  private var screenCaptureTimer: Timer? {
    get {
      return objc_getAssociatedObject(self, &AssociatedKeys.screenCaptureTimer) as? Timer
    }
    set {
      objc_setAssociatedObject(self, &AssociatedKeys.screenCaptureTimer, newValue, .OBJC_ASSOCIATION_RETAIN_NONATOMIC)
    }
  }

  /// í™”ë©´ ìº¡ì²˜ ìƒíƒœ
  var isScreenCapturing: Bool {
    get {
      return objc_getAssociatedObject(self, &AssociatedKeys.isScreenCapturing) as? Bool ?? false
    }
    set {
      objc_setAssociatedObject(self, &AssociatedKeys.isScreenCapturing, newValue, .OBJC_ASSOCIATION_RETAIN_NONATOMIC)
    }
  }
  
  /// ìµœê·¼ ì¹´ë©”ë¼ í”„ë ˆì„ (í™”ë©´ ìº¡ì²˜ìš©)
  var latestCameraFrame: CVPixelBuffer? {
    get {
      let object = objc_getAssociatedObject(self, &AssociatedKeys.latestCameraFrame)
      return object.map { $0 as! CVPixelBuffer }
    }
    set {
      objc_setAssociatedObject(self, &AssociatedKeys.latestCameraFrame, newValue, .OBJC_ASSOCIATION_RETAIN_NONATOMIC)
    }
  }
  
  /// í”„ë ˆì„ ì²˜ë¦¬ í
  var frameProcessingQueue: DispatchQueue {
    if let queue = objc_getAssociatedObject(self, &AssociatedKeys.frameProcessingQueue) as? DispatchQueue {
      return queue
    }
    let queue = DispatchQueue(label: "CameraFrameProcessing", qos: .userInteractive)
    objc_setAssociatedObject(self, &AssociatedKeys.frameProcessingQueue, queue, .OBJC_ASSOCIATION_RETAIN_NONATOMIC)
    return queue
  }
  
  /// í”„ë ˆì„ ì¹´ìš´í„° (í†µê³„ ì¶œë ¥ìš©)
  var frameCounter: Int {
    get {
      return objc_getAssociatedObject(self, &AssociatedKeys.frameCounter) as? Int ?? 0
    }
    set {
      objc_setAssociatedObject(self, &AssociatedKeys.frameCounter, newValue, .OBJC_ASSOCIATION_RETAIN_NONATOMIC)
    }
  }

  // MARK: - Screen Capture for Streaming

  /// CameraPreviewUIViewì˜ í™”ë©´ ìº¡ì²˜ ì†¡ì¶œ ê¸°ëŠ¥
  /// 
  /// ì´ ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤:
  /// 1. ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í”„ë ˆì„ì„ CVPixelBufferë¡œ ìº¡ì²˜
  /// 2. UI ì˜¤ë²„ë ˆì´(ë²„íŠ¼, ë¼ë²¨, ì›Œí„°ë§ˆí¬ ë“±)ë¥¼ ë³„ë„ë¡œ ë Œë”ë§
  /// 3. ì¹´ë©”ë¼ í”„ë ˆì„ê³¼ UIë¥¼ í•©ì„±í•˜ì—¬ ìµœì¢… ì´ë¯¸ì§€ ìƒì„±
  /// 4. 30fpsë¡œ HaishinKitì„ í†µí•´ ìŠ¤íŠ¸ë¦¬ë° ì„œë²„ì— ì „ì†¡
  ///
  /// **ì£¼ì˜ì‚¬í•­:**
  /// - ì¹´ë©”ë¼ í”„ë ˆì„ì´ ì—†ì„ ê²½ìš° UIë§Œ ìº¡ì²˜ë©ë‹ˆë‹¤
  /// - AVCaptureVideoPreviewLayerëŠ” í•˜ë“œì›¨ì–´ ê°€ì† ë ˆì´ì–´ì´ë¯€ë¡œ ì§ì ‘ ìº¡ì²˜ê°€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤
  /// - ë”°ë¼ì„œ AVCaptureVideoDataOutputì—ì„œ ë°›ì€ ì‹¤ì œ ì¹´ë©”ë¼ í”„ë ˆì„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤

  /// í™”ë©´ ìº¡ì²˜ ì†¡ì¶œ ì‹œì‘
  /// 
  /// 30fps íƒ€ì´ë¨¸ë¥¼ ì‹œì‘í•˜ì—¬ ì§€ì†ì ìœ¼ë¡œ í™”ë©´ì„ ìº¡ì²˜í•˜ê³  ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.
  /// ì¹´ë©”ë¼ í”„ë ˆì„ê³¼ UIë¥¼ í•©ì„±í•œ ì™„ì „í•œ í™”ë©´ì´ ì†¡ì¶œë©ë‹ˆë‹¤.
  func startScreenCapture() {
    guard !isScreenCapturing else { 
      logWarning("ì´ë¯¸ í™”ë©´ ìº¡ì²˜ê°€ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤", category: .streaming)
      return 
    }

    isScreenCapturing = true
    logInfo("í™”ë©´ ìº¡ì²˜ ì†¡ì¶œ ì‹œì‘", category: .streaming)

    // **ì„±ëŠ¥ ìµœì í™”**: 30fps â†’ 25fpsë¡œ ë‚®ì¶°ì„œ CPU ë¶€í•˜ ê°ì†Œ
    // 25fpsëŠ” ì—¬ì „íˆ ë¶€ë“œëŸ¬ìš´ ìŠ¤íŠ¸ë¦¬ë°ì„ ì œê³µí•˜ë©´ì„œ ì‹œìŠ¤í…œ ë¶€í•˜ë¥¼ ì¤„ì„
    screenCaptureTimer = Timer.scheduledTimer(withTimeInterval: 1.0 / 25.0, repeats: true) {
      [weak self] _ in
      self?.captureCurrentFrame()
    }
  }
  
  /// í™”ë©´ ìº¡ì²˜ ì†¡ì¶œ ì¤‘ì§€
  /// 
  /// íƒ€ì´ë¨¸ë¥¼ ì¤‘ì§€í•˜ê³  ìº¡ì²˜ëœ í”„ë ˆì„ ë°ì´í„°ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
  func stopScreenCapture() {
    guard isScreenCapturing else { 
      logWarning("í™”ë©´ ìº¡ì²˜ê°€ ì‹¤í–‰ ì¤‘ì´ì§€ ì•ŠìŠµë‹ˆë‹¤", category: .streaming)
      return 
    }

    isScreenCapturing = false
    screenCaptureTimer?.invalidate()
    screenCaptureTimer = nil
    
    // ë©”ëª¨ë¦¬ ì •ë¦¬: ìµœê·¼ ìº¡ì²˜ëœ ì¹´ë©”ë¼ í”„ë ˆì„ ì œê±°
    frameProcessingQueue.async { [weak self] in
      self?.latestCameraFrame = nil
    }
    
    logInfo("í™”ë©´ ìº¡ì²˜ ì†¡ì¶œ ì¤‘ì§€ ë° ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ", category: .streaming)
  }

  /// í˜„ì¬ í”„ë ˆì„ ìº¡ì²˜ ë° HaishinKit ì „ì†¡
  /// 
  /// ì´ ë©”ì„œë“œëŠ” 30fps íƒ€ì´ë¨¸ì— ì˜í•´ í˜¸ì¶œë˜ë©°, ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤:
  /// 1. ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ UI ë Œë”ë§ ìˆ˜í–‰
  /// 2. ì¹´ë©”ë¼ í”„ë ˆì„ê³¼ UIë¥¼ í•©ì„±í•˜ì—¬ ìµœì¢… ì´ë¯¸ì§€ ìƒì„±
  /// 3. UIImageë¥¼ CVPixelBufferë¡œ ë³€í™˜
  /// 4. HaishinKitì„ í†µí•´ ìŠ¤íŠ¸ë¦¬ë° ì„œë²„ì— ì „ì†¡
  private func captureCurrentFrame() {
    DispatchQueue.main.async { [weak self] in
      guard let self = self else { return }

      // í™”ë©´ ìº¡ì²˜ ìƒíƒœ ì¬í™•ì¸ (íƒ€ì´ë¨¸ ì§€ì—°ìœ¼ë¡œ ì¸í•œ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€)
      guard self.isScreenCapturing else { return }

      // Step 1: í˜„ì¬ í™”ë©´ì„ ì´ë¯¸ì§€ë¡œ ë Œë”ë§ (ì¹´ë©”ë¼ í”„ë ˆì„ + UI í•©ì„±)
      guard let capturedImage = self.renderToImage() else {
        return
      }

      // Step 2: UIImageë¥¼ CVPixelBufferë¡œ ë³€í™˜ (HaishinKit í˜¸í™˜ í¬ë§·)
      guard let pixelBuffer = capturedImage.toCVPixelBuffer() else {
        return
      }

      // Step 3: HaishinKitì„ í†µí•´ ìŠ¤íŠ¸ë¦¬ë° ì„œë²„ì— ì „ì†¡
      self.sendFrameToHaishinKit(pixelBuffer)
    }
  }

  /// UIViewë¥¼ UIImageë¡œ ë Œë”ë§ (ì¹´ë©”ë¼ í”„ë ˆì„ + UI í•©ì„±)
  /// 
  /// ì´ ë©”ì„œë“œëŠ” í™”ë©´ ìº¡ì²˜ì˜ í•µì‹¬ ë¡œì§ì…ë‹ˆë‹¤:
  /// - ì¹´ë©”ë¼ í”„ë ˆì„ì´ ìˆìœ¼ë©´: ì¹´ë©”ë¼ ì˜ìƒ + UI ì˜¤ë²„ë ˆì´ í•©ì„±
  /// - ì¹´ë©”ë¼ í”„ë ˆì„ì´ ì—†ìœ¼ë©´: UIë§Œ ìº¡ì²˜ (ê¸°ë³¸ ë ˆì´ì–´ ë Œë”ë§)
  ///
  /// **ê¸°ìˆ ì  ë°°ê²½:**
  /// AVCaptureVideoPreviewLayerëŠ” í•˜ë“œì›¨ì–´ ê°€ì†ì„ ì‚¬ìš©í•˜ë¯€ë¡œ 
  /// ì¼ë°˜ì ì¸ layer.render() ë°©ì‹ìœ¼ë¡œëŠ” ìº¡ì²˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
  /// ë”°ë¼ì„œ AVCaptureVideoDataOutputì—ì„œ ë°›ì€ ì‹¤ì œ í”„ë ˆì„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
  ///
  /// - Returns: ìº¡ì²˜ëœ ìµœì¢… ì´ë¯¸ì§€ (ì¹´ë©”ë¼ + UI í•©ì„±) ë˜ëŠ” nil
  private func renderToImage() -> UIImage? {
    // ì†¡ì¶œìš© ê³ í•´ìƒë„ ë Œë”ë§ ì‚¬ìš© (í•´ìƒë„ ë¬¸ì œ í•´ê²°)
    return renderToImageForStreaming()
  }
  
  /// ì†¡ì¶œìš© ê³ í•´ìƒë„ UI ë Œë”ë§ (í•´ìƒë„ ë¬¸ì œ í•´ê²°)
  /// 
  /// **ê°œì„ ëœ ì „ëµ:**
  /// - 480p ì†¡ì¶œ â†’ ì•½ 1000p(1712x960) ìº¡ì²˜
  /// - 720p ì†¡ì¶œ â†’ ì•½ 1400p(2560x1440) ìº¡ì²˜  
  /// - 1080p ì†¡ì¶œ â†’ ë™ì¼ í•´ìƒë„(1920x1080) ìº¡ì²˜ (ì•ˆì •ì„± ìš°ì„ )
  /// - ì†¡ì¶œ í•´ìƒë„ë³´ë‹¤ 2ë°° ì •ë„ ë†’ì€ í•´ìƒë„ë¡œ ìº¡ì²˜í•˜ì—¬ ê³ í’ˆì§ˆ ìœ ì§€
  /// 
  /// - Returns: ì†¡ì¶œ í•´ìƒë„ì— ë”°ë¼ ìµœì í™”ëœ ê³ í’ˆì§ˆ ì´ë¯¸ì§€
  private func renderToImageForStreaming() -> UIImage? {
    // HaishinKitManagerì—ì„œ í˜„ì¬ ìŠ¤íŠ¸ë¦¬ë° ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    let streamingSize = getOptimalCaptureSize()
    
    logDebug("ì†¡ì¶œìš© UI ë Œë”ë§ ì‹œì‘: \(streamingSize)", category: .performance)
    
    // ìµœê·¼ ì¹´ë©”ë¼ í”„ë ˆì„ì´ ìˆëŠ”ì§€ í™•ì¸
    if let cameraFrame = latestCameraFrame {
      return renderCameraFrameWithUIForStreaming(cameraFrame: cameraFrame, streamingSize: streamingSize)
    } else {
      logDebug("UIë§Œ ìº¡ì²˜ ëª¨ë“œ (ê³ í•´ìƒë„)", category: .performance)
      return renderUIOnlyForStreaming(streamingSize: streamingSize)
    }
  }
  
  /// ë‹¨ë§ í‘œì‹œìš© ì¼ë°˜ í•´ìƒë„ ë Œë”ë§ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
  /// 
  /// ì‚¬ìš©ìê°€ iPadì—ì„œ ë³´ëŠ” í™”ë©´ìš©ìœ¼ë¡œ ê¸°ì¡´ í¬ê¸° ìœ ì§€
  /// - Returns: ë‹¨ë§ í™”ë©´ í¬ê¸°ì˜ ì´ë¯¸ì§€
  private func renderToImageForDisplay() -> UIImage? {
    let size = bounds.size
    guard size.width > 0 && size.height > 0 else { 
      logError("ìœ íš¨í•˜ì§€ ì•Šì€ ë·° í¬ê¸°: \(size)", category: .performance)
      return nil 
    }
    
    logDebug("í‘œì‹œìš© UI ë Œë”ë§: \(size)", category: .performance)
    
    // ìµœê·¼ ì¹´ë©”ë¼ í”„ë ˆì„ì´ ìˆëŠ”ì§€ í™•ì¸
    if let cameraFrame = latestCameraFrame {
      return renderCameraFrameWithUI(cameraFrame: cameraFrame, viewSize: size)
    } else {
      logDebug("UIë§Œ ìº¡ì²˜ ëª¨ë“œ", category: .performance)
      let renderer = UIGraphicsImageRenderer(bounds: bounds)
      return renderer.image { context in
        layer.render(in: context.cgContext)
      }
    }
  }
  
  /// CVPixelBufferë¥¼ HaishinKitì— ì „ë‹¬í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë°
  /// 
  /// ìº¡ì²˜ëœ í”„ë ˆì„ì„ HaishinKitì˜ ìˆ˜ë™ í”„ë ˆì„ ì „ì†¡ ê¸°ëŠ¥ì„ í†µí•´
  /// ìŠ¤íŠ¸ë¦¬ë° ì„œë²„ë¡œ ì „ì†¡í•©ë‹ˆë‹¤.
  ///
  /// **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§:**
  /// - 5ì´ˆë§ˆë‹¤ ì „ì†¡ í†µê³„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤
  /// - ì„±ê³µ/ì‹¤íŒ¨ ì¹´ìš´íŠ¸ì™€ í˜„ì¬ FPSë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
  ///
  /// - Parameter pixelBuffer: ì „ì†¡í•  í”„ë ˆì„ ë°ì´í„°
  private func sendFrameToHaishinKit(_ pixelBuffer: CVPixelBuffer) {
    // HaishinKitManagerë¥¼ í†µí•œ ì‹¤ì œ í”„ë ˆì„ ì „ì†¡
    if let manager = haishinKitManager {
      Task {
        await manager.sendManualFrame(pixelBuffer)
      }

      // ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§: 5ì´ˆë§ˆë‹¤ ì „ì†¡ í†µê³„ ì¶œë ¥ (25fps ê¸°ì¤€)
      if frameCounter % 125 == 0 { // 25fps ê¸°ì¤€ 5ì´ˆë§ˆë‹¤ = 125í”„ë ˆì„ë§ˆë‹¤
        let stats = manager.getScreenCaptureStats()
        let successRate = stats.frameCount > 0 ? (Double(stats.successCount) / Double(stats.frameCount)) * 100 : 0
        logInfo("""
        í™”ë©´ìº¡ì²˜ í†µê³„ 
        - í˜„ì¬ FPS: \(String(format: "%.1f", stats.currentFPS))
        - ì„±ê³µ ì „ì†¡: \(stats.successCount)í”„ë ˆì„
        - ì‹¤íŒ¨ ì „ì†¡: \(stats.failureCount)í”„ë ˆì„
        - ì„±ê³µë¥ : \(String(format: "%.1f", successRate))%
        - ì´ ì²˜ë¦¬: \(stats.frameCount)í”„ë ˆì„
        """, category: .performance)
      }
      frameCounter += 1
    } else {
      logWarning("HaishinKitManager ì—†ìŒ - í”„ë ˆì„ ì „ë‹¬ ë¶ˆê°€", category: .streaming)
    }
  }

  /// í™”ë©´ ìº¡ì²˜ ìƒíƒœì™€ í†µê³„ í™•ì¸ (ê³µê°œ ë©”ì„œë“œ)
  public func getScreenCaptureStatus() -> (isCapturing: Bool, stats: String?) {
    let stats = haishinKitManager?.getScreenCaptureStats()
    return (isScreenCapturing, stats?.summary)
  }

  /// í™”ë©´ ìº¡ì²˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
  public func testScreenCapturePerformance() {
    guard let manager = haishinKitManager else {
      logError("HaishinKitManagerê°€ ì—†ìŒ", category: .streaming)
      return
    }

    logInfo("í™”ë©´ ìº¡ì²˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...", category: .performance)
    manager.resetScreenCaptureStats()

    // 10í”„ë ˆì„ ì—°ì† ì „ì†¡ í…ŒìŠ¤íŠ¸
    for i in 1...10 {
      DispatchQueue.main.asyncAfter(deadline: .now() + Double(i) * 0.1) { [weak self] in
        if let image = self?.renderToImage(),
          let pixelBuffer = image.toCVPixelBuffer()
        {
          Task {
            await manager.sendManualFrame(pixelBuffer)
          }

          if i == 10 {
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
              let stats = manager.getScreenCaptureStats()
              logInfo("í…ŒìŠ¤íŠ¸ ì™„ë£Œ:", category: .performance)
              logInfo(stats.summary, category: .performance)
            }
          }
        }
      }
    }
  }
  
  /// ë‹¨ë§ í‘œì‹œìš© í™”ë©´ ìº¡ì²˜ (ì‚¬ìš©ì í™”ë©´ì— í‘œì‹œìš©)
  /// 
  /// ì†¡ì¶œê³¼ ë³„ë„ë¡œ ì‚¬ìš©ìê°€ iPadì—ì„œ ë³¼ ìˆ˜ ìˆëŠ” í™”ë©´ ìº¡ì²˜ ê¸°ëŠ¥
  /// - Returns: ë‹¨ë§ í™”ë©´ í¬ê¸°ì˜ ì´ë¯¸ì§€
  public func captureForDisplay() -> UIImage? {
    return renderToImageForDisplay()
  }
  
  /// ì†¡ì¶œìš©ê³¼ ë‹¨ë§ìš© ì´ë¯¸ì§€ ë™ì‹œ ìƒì„±
  /// 
  /// - Returns: (ì†¡ì¶œìš©: 1920x1080, ë‹¨ë§ìš©: 986x865) íŠœí”Œ
  public func captureForBothPurposes() -> (streaming: UIImage?, display: UIImage?) {
    let streamingImage = renderToImageForStreaming()
    let displayImage = renderToImageForDisplay()
    
    logDebug("ì´ì¤‘ìº¡ì²˜ - ì†¡ì¶œìš©: \(streamingImage?.size ?? CGSize.zero), ë‹¨ë§ìš©: \(displayImage?.size ?? CGSize.zero)", category: .performance)
    
    return (streamingImage, displayImage)
  }
  
  /// ë‹¨ë§ í™”ë©´ ìº¡ì²˜ ì €ì¥ (ì‚¬ì§„ ì•±ì— ì €ì¥)
  /// 
  /// ì‚¬ìš©ìê°€ í˜„ì¬ í™”ë©´ì„ ì‚¬ì§„ìœ¼ë¡œ ì €ì¥í•  ë•Œ ì‚¬ìš©
  public func saveDisplayCapture(completion: @escaping (Bool, Error?) -> Void) {
    guard let displayImage = renderToImageForDisplay() else {
      completion(false, NSError(domain: "CameraPreview", code: 1, userInfo: [NSLocalizedDescriptionKey: NSLocalizedString("camera_unavailable", comment: "ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")]))
      return
    }
    
    UIImageWriteToSavedPhotosAlbum(displayImage, nil, nil, nil)
    logInfo("í™”ë©´ ìº¡ì²˜ ì‚¬ì§„ ì•±ì— ì €ì¥ ì™„ë£Œ: \(displayImage.size)", category: .general)
    completion(true, nil)
  }

  /// í™”ë©´ ìº¡ì²˜ ìƒíƒœ í™•ì¸
  var isCapturingScreen: Bool {
    return isScreenCapturing
  }
}

// MARK: - Screen Capture Video Frame Processing Extension

extension CameraPreviewUIView {
  
  /// í™”ë©´ ìº¡ì²˜ ëª¨ë“œë¥¼ ìœ„í•œ ë¹„ë””ì˜¤ í”„ë ˆì„ ì²˜ë¦¬
  func processVideoFrameForScreenCapture(_ sampleBuffer: CMSampleBuffer) {
    // ğŸ¬ í™”ë©´ ìº¡ì²˜ ëª¨ë“œ: ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í”„ë ˆì„ ì €ì¥
    // UIì™€ í•©ì„±í•˜ê¸° ìœ„í•´ ìµœì‹  í”„ë ˆì„ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì €ì¥
    if isScreenCapturing {
      guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { 
        logWarning("CMSampleBufferì—ì„œ pixelBuffer ì¶”ì¶œ ì‹¤íŒ¨", category: .camera)
        return 
      }
      
      // ë°±ê·¸ë¼ìš´ë“œ íì—ì„œ í”„ë ˆì„ ì €ì¥ (ë©”ì¸ ìŠ¤ë ˆë“œ ë¸”ë¡í‚¹ ë°©ì§€)
      frameProcessingQueue.async { [weak self] in
        self?.latestCameraFrame = pixelBuffer
      }
    }
  }
}

// MARK: - Associated Keys for Runtime Properties

private struct AssociatedKeys {
  static var screenCaptureTimer = "screenCaptureTimer"
  static var isScreenCapturing = "isScreenCapturing"
  static var latestCameraFrame = "latestCameraFrame"
  static var frameProcessingQueue = "frameProcessingQueue"
  static var frameCounter = "frameCounter"
} 