//
//  CameraPreviewView.swift
//  USBExternalCamera
//
//  Created by EUN YEON on 5/25/25.
//

import AVFoundation
import HaishinKit
import SwiftUI

// MARK: - String Extension for Regex

extension String {
  func matches(for regex: String) -> [String] {
    do {
      let regex = try NSRegularExpression(pattern: regex)
      let results = regex.matches(in: self, range: NSRange(self.startIndex..., in: self))
      return results.map {
        String(self[Range($0.range, in: self)!])
      }
    } catch {
      return []
    }
  }
}

/// **ì‹¤ì œ HaishinKit RTMP ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ ì¹´ë©”ë¼ ë¯¸ë¦¬ë³´ê¸°**
struct CameraPreviewView: UIViewRepresentable {
  let session: AVCaptureSession
  var streamViewModel: LiveStreamViewModel?
  var haishinKitManager: HaishinKitManager?

  init(
    session: AVCaptureSession, streamViewModel: LiveStreamViewModel? = nil,
    haishinKitManager: HaishinKitManager? = nil
  ) {
    self.session = session
    self.streamViewModel = streamViewModel
    self.haishinKitManager = haishinKitManager
  }

  func makeUIView(context: Context) -> UIView {
    // í•­ìƒ AVCaptureVideoPreviewLayer ì‚¬ìš©í•˜ì—¬ ì¹´ë©”ë¼ ë¯¸ë¦¬ë³´ê¸° ìœ ì§€
    // HaishinKitì€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìŠ¤íŠ¸ë¦¬ë°ë§Œ ì²˜ë¦¬
    let view = CameraPreviewUIView()
    view.captureSession = session
    view.haishinKitManager = haishinKitManager
    return view
  }

  func updateUIView(_ uiView: UIView, context: Context) {
    if let previewView = uiView as? CameraPreviewUIView {
      // ì„¸ì…˜ì´ë‚˜ ë§¤ë‹ˆì €ê°€ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ ì—…ë°ì´íŠ¸
      let sessionChanged = previewView.captureSession !== session
      let managerChanged = previewView.haishinKitManager !== haishinKitManager

      if sessionChanged {
        print("ðŸ”„ [CameraPreview] ìº¡ì²˜ ì„¸ì…˜ ë³€ê²½ ê°ì§€ - ì—…ë°ì´íŠ¸")
        previewView.captureSession = session
      }

      if managerChanged {
        print("ðŸ”„ [CameraPreview] HaishinKit ë§¤ë‹ˆì € ë³€ê²½ ê°ì§€ - ì—…ë°ì´íŠ¸")
        previewView.haishinKitManager = haishinKitManager
      }

      // í”„ë¦¬ë·° ìƒˆë¡œê³ ì¹¨ì€ í•˜ì§€ ì•ŠìŒ (ì•ˆì •ì„± í–¥ìƒ)
      print("ðŸ”„ [CameraPreview] ì—…ë°ì´íŠ¸ ì™„ë£Œ - í”„ë¦¬ë·° ìƒˆë¡œê³ ì¹¨ ê±´ë„ˆëœ€")
    }
  }

  // MARK: - Screen Capture Control Methods

  /// í™”ë©´ ìº¡ì²˜ ì†¡ì¶œ ì‹œìž‘ (ì™¸ë¶€ì—ì„œ í˜¸ì¶œ ê°€ëŠ¥)
  func startScreenCapture() {
    // UIViewRepresentableì—ì„œ UIViewì— ì ‘ê·¼í•˜ëŠ” ë°©ë²•ì´ ì œí•œì ì´ë¯€ë¡œ
    // HaishinKitManagerë¥¼ í†µí•´ ì œì–´í•˜ëŠ” ê²ƒì„ ê¶Œìž¥
    print("ðŸŽ¬ [CameraPreviewView] í™”ë©´ ìº¡ì²˜ ìš”ì²­ë¨ - HaishinKitManager ì‚¬ìš© ê¶Œìž¥")
  }

  /// í™”ë©´ ìº¡ì²˜ ì†¡ì¶œ ì¤‘ì§€ (ì™¸ë¶€ì—ì„œ í˜¸ì¶œ ê°€ëŠ¥)
  func stopScreenCapture() {
    print("ðŸŽ¬ [CameraPreviewView] í™”ë©´ ìº¡ì²˜ ì¤‘ì§€ ìš”ì²­ë¨")

    // í™”ë©´ ìº¡ì²˜ ì¤‘ì§€ ì•Œë¦¼ ì „ì†¡
    DispatchQueue.main.async {
      NotificationCenter.default.post(name: .stopScreenCapture, object: nil)
    }
  }
}

/// ì‹¤ì œ ì¹´ë©”ë¼ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ë‹´ë‹¹í•˜ëŠ” UIView
final class CameraPreviewUIView: UIView {

  // MARK: - Properties

  /// AVFoundation ì¹´ë©”ë¼ ë¯¸ë¦¬ë³´ê¸° ë ˆì´ì–´
  private var previewLayer: AVCaptureVideoPreviewLayer?

  /// HaishinKit ë¯¸ë¦¬ë³´ê¸° ë ˆì´ì–´ (ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì¼ ë•Œ ì‚¬ìš©)
  private var hkPreviewLayer: UIView?

  /// ë¹„ë””ì˜¤ ì¶œë ¥ (í†µê³„ ëª©ì )
  private var videoOutput: AVCaptureVideoDataOutput?
  private let videoOutputQueue = DispatchQueue(
    label: "CameraPreviewView.VideoOutput", qos: .userInteractive)

  /// í˜„ìž¬ ìº¡ì²˜ ì„¸ì…˜
  var captureSession: AVCaptureSession? {
    didSet {
      // ì²˜ìŒ ì„¤ì •ë  ë•Œë§Œ í”„ë¦¬ë·° ë ˆì´ì–´ ìƒì„±
      if oldValue == nil && captureSession != nil {
        print("ðŸŽ¥ [CameraPreview] ì´ˆê¸° ìº¡ì²˜ ì„¸ì…˜ ì„¤ì • - í”„ë¦¬ë·° ë ˆì´ì–´ ìƒì„±")
        updatePreviewLayer()
      } else if oldValue !== captureSession {
        print("ðŸŽ¥ [CameraPreview] ìº¡ì²˜ ì„¸ì…˜ ë³€ê²½ ê°ì§€ - í”„ë¦¬ë·° ë ˆì´ì–´ ì—…ë°ì´íŠ¸")
        updatePreviewLayer()
      }
    }
  }

  /// HaishinKit ë§¤ë‹ˆì € (ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ í™•ì¸ìš©)
  var haishinKitManager: HaishinKitManager? {
    didSet {
      updateStreamingStatus()
      setupStatusMonitoring()
    }
  }

  /// ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ
  private var isStreaming: Bool = false {
    didSet {
      updateStreamingStatusView()
    }
  }

  /// ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ëª¨ë‹ˆí„°ë§ íƒ€ì´ë¨¸
  private var statusMonitorTimer: Timer?

  /// ì¹´ë©”ë¼ ì»¨íŠ¸ë¡¤ ì˜¤ë²„ë ˆì´
  private lazy var controlOverlay: CameraControlOverlay = {
    let overlay = CameraControlOverlay()
    overlay.delegate = self
    overlay.translatesAutoresizingMaskIntoConstraints = false
    overlay.backgroundColor = UIColor.clear
    return overlay
  }()

  /// ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ í‘œì‹œ
  private lazy var streamingStatusView: StreamingStatusView = {
    let statusView = StreamingStatusView()
    statusView.translatesAutoresizingMaskIntoConstraints = false
    statusView.isHidden = true
    return statusView
  }()

  /// í™”ë©´ ìº¡ì²˜ìš© íƒ€ì´ë¨¸
  private var screenCaptureTimer: Timer?

  /// í™”ë©´ ìº¡ì²˜ ìƒíƒœ
  private var isScreenCapturing: Bool = false
  
  /// ìµœê·¼ ì¹´ë©”ë¼ í”„ë ˆìž„ (í™”ë©´ ìº¡ì²˜ìš©)
  private var latestCameraFrame: CVPixelBuffer?
  private let frameProcessingQueue = DispatchQueue(label: "CameraFrameProcessing", qos: .userInteractive)

  // MARK: - Initialization

  override init(frame: CGRect) {
    super.init(frame: frame)
    setupView()
  }

  required init?(coder: NSCoder) {
    super.init(coder: coder)
    setupView()
  }

  // MARK: - View Setup

  private func setupView() {
    backgroundColor = .black

    // ì»¨íŠ¸ë¡¤ ì˜¤ë²„ë ˆì´ë§Œ ì¶”ê°€ (StreamingStatusViewëŠ” ì¤‘ë³µë˜ë¯€ë¡œ ì œê±°)
    addSubview(controlOverlay)
    // addSubview(streamingStatusView) // ì¤‘ë³µ ì œê±°

    setupConstraints()
    setupGestureRecognizers()
    setupNotifications()
    setupWatermark()
  }

  private func setupNotifications() {
    // í™”ë©´ ìº¡ì²˜ ì œì–´ notification êµ¬ë…
    NotificationCenter.default.addObserver(
      self,
      selector: #selector(handleStartScreenCapture),
      name: NSNotification.Name("startScreenCapture"),
      object: nil
    )

    NotificationCenter.default.addObserver(
      self,
      selector: #selector(handleStopScreenCapture),
      name: NSNotification.Name("stopScreenCapture"),
      object: nil
    )

    NotificationCenter.default.addObserver(
      self,
      selector: #selector(handleTestWatermarkCapture),
      name: NSNotification.Name("testWatermarkCapture"),
      object: nil
    )
  }

  @objc private func handleStartScreenCapture() {
    print("ðŸ“© [CameraPreview] í™”ë©´ ìº¡ì²˜ ì‹œìž‘ notification ìˆ˜ì‹ ")
    startScreenCapture()
  }

  @objc private func handleStopScreenCapture() {
    print("ðŸ“© [CameraPreview] í™”ë©´ ìº¡ì²˜ ì¤‘ì§€ notification ìˆ˜ì‹ ")
    stopScreenCapture()
  }

  @objc private func handleTestWatermarkCapture() {
    print("ðŸ§ª [CameraPreview] ì›Œí„°ë§ˆí¬ ìº¡ì²˜ í…ŒìŠ¤íŠ¸ notification ìˆ˜ì‹ ")

    // ì¦‰ì‹œ í•œ ë²ˆì˜ í”„ë ˆìž„ ìº¡ì²˜ ì‹¤í–‰
    DispatchQueue.main.async { [weak self] in
      self?.captureCurrentFrame()
    }
  }

  private func setupWatermark() {
    // ì¤‘ì•™ ëŒ€í˜• ì›Œí„°ë§ˆí¬ ìƒì„±
    let watermarkContainer = UIView()
    watermarkContainer.backgroundColor = UIColor.clear
    watermarkContainer.translatesAutoresizingMaskIntoConstraints = false
    watermarkContainer.tag = 8888  // ì›Œí„°ë§ˆí¬ ì‹ë³„ìš© íƒœê·¸

    // AAA TEST ë©”ì¸ ì›Œí„°ë§ˆí¬
    let mainWatermark = UILabel()
    mainWatermark.text = "AAA TEST"
    mainWatermark.font = UIFont.boldSystemFont(ofSize: 48)
    mainWatermark.textColor = .white
    mainWatermark.backgroundColor = UIColor.red.withAlphaComponent(0.9)
    mainWatermark.textAlignment = .center
    mainWatermark.layer.cornerRadius = 16
    mainWatermark.layer.borderWidth = 4
    mainWatermark.layer.borderColor = UIColor.yellow.cgColor
    mainWatermark.clipsToBounds = true
    mainWatermark.translatesAutoresizingMaskIntoConstraints = false

    // ê·¸ë¦¼ìž íš¨ê³¼
    mainWatermark.layer.shadowColor = UIColor.black.cgColor
    mainWatermark.layer.shadowOffset = CGSize(width: 2, height: 2)
    mainWatermark.layer.shadowRadius = 4
    mainWatermark.layer.shadowOpacity = 0.8

    // ì„œë¸Œ ì›Œí„°ë§ˆí¬
    let subWatermark = UILabel()
    subWatermark.text = "ðŸŽ¬ SCREEN CAPTURE TEST"
    subWatermark.font = UIFont.boldSystemFont(ofSize: 20)
    subWatermark.textColor = .yellow
    subWatermark.backgroundColor = UIColor.blue.withAlphaComponent(0.8)
    subWatermark.textAlignment = .center
    subWatermark.layer.cornerRadius = 12
    subWatermark.clipsToBounds = true
    subWatermark.translatesAutoresizingMaskIntoConstraints = false

    // ë¼ì´ë¸Œ í‘œì‹œ
    let liveIndicator = UILabel()
    liveIndicator.text = "â— LIVE STREAMING â—"
    liveIndicator.font = UIFont.boldSystemFont(ofSize: 16)
    liveIndicator.textColor = .green
    liveIndicator.backgroundColor = UIColor.black.withAlphaComponent(0.7)
    liveIndicator.textAlignment = .center
    liveIndicator.layer.cornerRadius = 8
    liveIndicator.clipsToBounds = true
    liveIndicator.translatesAutoresizingMaskIntoConstraints = false

    // ìš°í•˜ë‹¨ ì½”ë„ˆ ì›Œí„°ë§ˆí¬
    let cornerWatermark = UILabel()
    cornerWatermark.text = "ðŸ“± CAPTURE\\nON AIR"
    cornerWatermark.numberOfLines = 2
    cornerWatermark.font = UIFont.boldSystemFont(ofSize: 14)
    cornerWatermark.textColor = .white
    cornerWatermark.backgroundColor = UIColor.black.withAlphaComponent(0.6)
    cornerWatermark.textAlignment = .center
    cornerWatermark.layer.cornerRadius = 8
    cornerWatermark.clipsToBounds = true
    cornerWatermark.translatesAutoresizingMaskIntoConstraints = false

    // ì»¨í…Œì´ë„ˆì— ì¶”ê°€
    watermarkContainer.addSubview(mainWatermark)
    watermarkContainer.addSubview(subWatermark)
    watermarkContainer.addSubview(liveIndicator)
    watermarkContainer.addSubview(cornerWatermark)

    // ë©”ì¸ ë·°ì— ì¶”ê°€
    addSubview(watermarkContainer)

    // ì œì•½ ì¡°ê±´ ì„¤ì •
    NSLayoutConstraint.activate([
      // ì»¨í…Œì´ë„ˆ
      watermarkContainer.leadingAnchor.constraint(equalTo: leadingAnchor),
      watermarkContainer.trailingAnchor.constraint(equalTo: trailingAnchor),
      watermarkContainer.topAnchor.constraint(equalTo: topAnchor),
      watermarkContainer.bottomAnchor.constraint(equalTo: bottomAnchor),

      // ë©”ì¸ ì›Œí„°ë§ˆí¬ (ì¤‘ì•™)
      mainWatermark.centerXAnchor.constraint(equalTo: watermarkContainer.centerXAnchor),
      mainWatermark.centerYAnchor.constraint(equalTo: watermarkContainer.centerYAnchor),
      mainWatermark.widthAnchor.constraint(equalToConstant: 300),
      mainWatermark.heightAnchor.constraint(equalToConstant: 80),

      // ì„œë¸Œ ì›Œí„°ë§ˆí¬ (ë©”ì¸ ì›Œí„°ë§ˆí¬ ì•„ëž˜)
      subWatermark.centerXAnchor.constraint(equalTo: mainWatermark.centerXAnchor),
      subWatermark.topAnchor.constraint(equalTo: mainWatermark.bottomAnchor, constant: 16),
      subWatermark.widthAnchor.constraint(equalToConstant: 350),
      subWatermark.heightAnchor.constraint(equalToConstant: 40),

      // ë¼ì´ë¸Œ í‘œì‹œ (ì„œë¸Œ ì›Œí„°ë§ˆí¬ ì•„ëž˜)
      liveIndicator.centerXAnchor.constraint(equalTo: subWatermark.centerXAnchor),
      liveIndicator.topAnchor.constraint(equalTo: subWatermark.bottomAnchor, constant: 12),
      liveIndicator.widthAnchor.constraint(equalToConstant: 200),
      liveIndicator.heightAnchor.constraint(equalToConstant: 30),

      // ì½”ë„ˆ ì›Œí„°ë§ˆí¬ (ìš°í•˜ë‹¨)
      cornerWatermark.trailingAnchor.constraint(
        equalTo: watermarkContainer.trailingAnchor, constant: -16),
      cornerWatermark.bottomAnchor.constraint(
        equalTo: watermarkContainer.bottomAnchor, constant: -20),
      cornerWatermark.widthAnchor.constraint(equalToConstant: 80),
      cornerWatermark.heightAnchor.constraint(equalToConstant: 50),
    ])

    print("ðŸŽ¨ [CameraPreview] ì›Œí„°ë§ˆí¬ UIView ì¶”ê°€ ì™„ë£Œ")
  }

  private func setupConstraints() {
    NSLayoutConstraint.activate([
      // ì»¨íŠ¸ë¡¤ ì˜¤ë²„ë ˆì´
      controlOverlay.leadingAnchor.constraint(equalTo: leadingAnchor),
      controlOverlay.trailingAnchor.constraint(equalTo: trailingAnchor),
      controlOverlay.topAnchor.constraint(equalTo: topAnchor),
      controlOverlay.bottomAnchor.constraint(equalTo: bottomAnchor),

      // ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ í‘œì‹œ ì œì•½ ì œê±° (ì¤‘ë³µ ë°©ì§€)
    ])
  }

  private func setupGestureRecognizers() {
    // í¬ì»¤ìŠ¤ íƒ­ ì œìŠ¤ì²˜
    let focusTapGesture = UITapGestureRecognizer(
      target: self, action: #selector(handleFocusTap(_:)))
    addGestureRecognizer(focusTapGesture)

    // ë…¸ì¶œ ì¡°ì ˆ ë”ë¸”íƒ­ ì œìŠ¤ì²˜
    let exposureDoubleTapGesture = UITapGestureRecognizer(
      target: self, action: #selector(handleExposureDoubleTap(_:)))
    exposureDoubleTapGesture.numberOfTapsRequired = 2
    addGestureRecognizer(exposureDoubleTapGesture)

    focusTapGesture.require(toFail: exposureDoubleTapGesture)

    // ì¤Œ í•€ì¹˜ ì œìŠ¤ì²˜
    let zoomPinchGesture = UIPinchGestureRecognizer(
      target: self, action: #selector(handleZoomPinch(_:)))
    addGestureRecognizer(zoomPinchGesture)
  }

  // MARK: - Preview Layer Management

  private func updatePreviewLayer() {
    // ê¸°ì¡´ ë ˆì´ì–´ ì œê±°
    previewLayer?.removeFromSuperlayer()
    hkPreviewLayer?.removeFromSuperview()

    guard let session = captureSession else { return }

    // í•­ìƒ AVFoundation í”„ë¦¬ë·° ì‚¬ìš© (ì•ˆì •ì„± í–¥ìƒ)
    setupAVFoundationPreview(with: session)

    // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì´ë©´ ì¶”ê°€ í‘œì‹œ
    if isStreaming {
      addStreamingIndicator()
    }
  }

  /// ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œë§Œ ì¶”ê°€ (í”„ë¦¬ë·° ë ˆì´ì–´ëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
  private func addStreamingIndicatorOnly() {
    // ê¸°ì¡´ ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì œê±°
    removeStreamingIndicator()

    print("ðŸ”´ [CameraPreview] ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì¶”ê°€")

    let streamingOverlay = UIView(frame: bounds)
    streamingOverlay.backgroundColor = UIColor.clear
    streamingOverlay.tag = 9999  // ì‹ë³„ìš© íƒœê·¸

    let streamingIndicator = UIView()
    streamingIndicator.backgroundColor = UIColor.red.withAlphaComponent(0.9)
    streamingIndicator.layer.cornerRadius = 12
    streamingIndicator.translatesAutoresizingMaskIntoConstraints = false

    let liveLabel = UILabel()
    liveLabel.text = "ðŸ”´ LIVE"
    liveLabel.textColor = .white
    liveLabel.font = UIFont.boldSystemFont(ofSize: 14)
    liveLabel.translatesAutoresizingMaskIntoConstraints = false

    streamingIndicator.addSubview(liveLabel)
    streamingOverlay.addSubview(streamingIndicator)

    NSLayoutConstraint.activate([
      streamingIndicator.topAnchor.constraint(
        equalTo: streamingOverlay.safeAreaLayoutGuide.topAnchor, constant: 20),
      streamingIndicator.leadingAnchor.constraint(
        equalTo: streamingOverlay.leadingAnchor, constant: 20),
      streamingIndicator.widthAnchor.constraint(equalToConstant: 80),
      streamingIndicator.heightAnchor.constraint(equalToConstant: 32),

      liveLabel.centerXAnchor.constraint(equalTo: streamingIndicator.centerXAnchor),
      liveLabel.centerYAnchor.constraint(equalTo: streamingIndicator.centerYAnchor),
    ])

    addSubview(streamingOverlay)
    hkPreviewLayer = streamingOverlay
  }

  /// ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì œê±°
  private func removeStreamingIndicator() {
    // íƒœê·¸ë¡œ ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì°¾ì•„ì„œ ì œê±°
    if let streamingOverlay = subviews.first(where: { $0.tag == 9999 }) {
      streamingOverlay.removeFromSuperview()
      print("ðŸ”´ [CameraPreview] ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì œê±°")
    }
    hkPreviewLayer = nil
  }

  /// ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì¶”ê°€ (ë ˆì´ì•„ì›ƒìš©)
  private func addStreamingIndicator() {
    addStreamingIndicatorOnly()
  }

  /// í”„ë¦¬ë·° ë ˆì´ì–´ê°€ í™œì„± ìƒíƒœì¸ì§€ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ë³µêµ¬
  private func ensurePreviewLayerActive() {
    guard let session = captureSession else {
      print("âŒ [CameraPreview] ìº¡ì²˜ ì„¸ì…˜ì´ ì—†ì–´ í”„ë¦¬ë·° ë³´í˜¸ ë¶ˆê°€")
      return
    }

    // í”„ë¦¬ë·° ë ˆì´ì–´ê°€ ì—†ê±°ë‚˜ ì„¸ì…˜ì´ ë‹¤ë¥´ë©´ ë³µêµ¬
    if previewLayer == nil || previewLayer?.session !== session {
      print("ðŸ”§ [CameraPreview] í”„ë¦¬ë·° ë ˆì´ì–´ ë³µêµ¬ í•„ìš” - ìž¬ìƒì„±")
      setupAVFoundationPreview(with: session)
    } else if let layer = previewLayer {
      // í”„ë¦¬ë·° ë ˆì´ì–´ê°€ ìŠˆí¼ë ˆì´ì–´ì—ì„œ ì œê±°ë˜ì—ˆìœ¼ë©´ ë‹¤ì‹œ ì¶”ê°€
      if layer.superlayer == nil {
        print("ðŸ”§ [CameraPreview] í”„ë¦¬ë·° ë ˆì´ì–´ ë‹¤ì‹œ ì¶”ê°€")
        self.layer.insertSublayer(layer, at: 0)
      }

      // í”„ë ˆìž„ ì—…ë°ì´íŠ¸
      layer.frame = bounds
    }

    print("âœ… [CameraPreview] í”„ë¦¬ë·° ë ˆì´ì–´ ë³´í˜¸ ì™„ë£Œ")
  }

  /// ë¹„ë””ì˜¤ í”„ë ˆìž„ ëª¨ë‹ˆí„°ë§ ì„¤ì • (í†µê³„ ëª©ì )
  private func setupVideoMonitoring(with session: AVCaptureSession) {
    print("ðŸ“¹ [CameraPreview] ë¹„ë””ì˜¤ í”„ë ˆìž„ ëª¨ë‹ˆí„°ë§ ì„¤ì •")

    // ê¸°ì¡´ ë¹„ë””ì˜¤ ì¶œë ¥ ì œê±°
    if let existingOutput = videoOutput {
      session.removeOutput(existingOutput)
    }

    // ìƒˆë¡œìš´ ë¹„ë””ì˜¤ ì¶œë ¥ ìƒì„± (í†µê³„ ëª©ì )
    let newVideoOutput = AVCaptureVideoDataOutput()
    newVideoOutput.setSampleBufferDelegate(self, queue: videoOutputQueue)

    // ë¹„ë””ì˜¤ ì„¤ì • (ê°€ë²¼ìš´ ì²˜ë¦¬ìš©)
    newVideoOutput.videoSettings = [
      kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA
    ]

    // í”„ë ˆìž„ ë“œë¡­ í—ˆìš© (ì„±ëŠ¥ ìµœì í™”)
    newVideoOutput.alwaysDiscardsLateVideoFrames = true

    // ì„¸ì…˜ì— ì¶”ê°€
    if session.canAddOutput(newVideoOutput) {
      session.addOutput(newVideoOutput)
      videoOutput = newVideoOutput
      print("âœ… [CameraPreview] ë¹„ë””ì˜¤ í”„ë ˆìž„ ëª¨ë‹ˆí„°ë§ ì„¤ì • ì™„ë£Œ")
    } else {
      print("âŒ [CameraPreview] ë¹„ë””ì˜¤ í”„ë ˆìž„ ëª¨ë‹ˆí„°ë§ ì„¤ì • ì‹¤íŒ¨")
    }
  }

  /// ë¹„ë””ì˜¤ í”„ë ˆìž„ ëª¨ë‹ˆí„°ë§ í•´ì œ
  private func removeVideoMonitoring() {
    guard let session = captureSession, let output = videoOutput else { return }

    print("ðŸ“¹ [CameraPreview] ë¹„ë””ì˜¤ í”„ë ˆìž„ ëª¨ë‹ˆí„°ë§ í•´ì œ")
    session.removeOutput(output)
    videoOutput = nil
  }

  /// ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ì—…ë°ì´íŠ¸ (ê°œì„ ëœ ë²„ì „)
  private func updateStreamingStatus() {
    guard let manager = haishinKitManager else {
      isStreaming = false
      // StreamingStatusViewëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ì¤‘ë³µ ë°©ì§€)
      return
    }

    // ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœì™€ ì—°ê²° ìƒíƒœ ëª¨ë‘ í™•ì¸
    let newStreamingState = manager.isStreaming
    let connectionStatus = manager.connectionStatus
    let currentStatus = manager.currentStatus

    if isStreaming != newStreamingState {
      isStreaming = newStreamingState

      // ìƒíƒœ ë³€í™”ë¥¼ ë¡œê¹…
      if isStreaming {
        print("ðŸŽ¥ [CameraPreview] ìŠ¤íŠ¸ë¦¬ë° ì‹œìž‘ë¨ - ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì¶”ê°€ ë° í”„ë¦¬ë·° ë³´í˜¸")

        // ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì¶”ê°€ ë° ë¹„ë””ì˜¤ ëª¨ë‹ˆí„°ë§ ì„¤ì •
        DispatchQueue.main.async { [weak self] in
          self?.addStreamingIndicatorOnly()
          // í”„ë¦¬ë·° ë ˆì´ì–´ê°€ í™œì„± ìƒíƒœì¸ì§€ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ë³µêµ¬
          self?.ensurePreviewLayerActive()
          // ë¹„ë””ì˜¤ í”„ë ˆìž„ ëª¨ë‹ˆí„°ë§ ì„¤ì • (í†µê³„ ëª©ì )
          if let session = self?.captureSession {
            self?.setupVideoMonitoring(with: session)
          }
        }
      } else {
        print("ðŸŽ¥ [CameraPreview] ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œë¨ - ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì œê±°")

        // ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì œê±° ë° ë¹„ë””ì˜¤ ëª¨ë‹ˆí„°ë§ í•´ì œ
        DispatchQueue.main.async { [weak self] in
          self?.removeStreamingIndicator()
          // ë¹„ë””ì˜¤ í”„ë ˆìž„ ëª¨ë‹ˆí„°ë§ í•´ì œ
          self?.removeVideoMonitoring()
          // í”„ë¦¬ë·° ë ˆì´ì–´ ë³µêµ¬
          self?.ensurePreviewLayerActive()
        }
      }
    }

    // ì—°ê²° ìƒíƒœì— ë”°ë¥¸ ìƒì„¸ UI ì—…ë°ì´íŠ¸
    DispatchQueue.main.async { [weak self] in
      self?.updateDetailedStreamingStatus(
        isStreaming: newStreamingState,
        connectionStatus: connectionStatus,
        status: currentStatus
      )
    }
  }

  /// ìƒì„¸ ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ UI ì—…ë°ì´íŠ¸ (ë¹„í™œì„±í™” - ì¤‘ë³µ ë°©ì§€)
  private func updateDetailedStreamingStatus(
    isStreaming: Bool,
    connectionStatus: String,
    status: LiveStreamStatus
  ) {
    // StreamingStatusView ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ì¤‘ë³µ ë°©ì§€)
    // ìž‘ì€ ë¼ì´ë¸Œ í‘œì‹œë§Œ ì‚¬ìš©
    //        print("ðŸ“Š [CameraPreview] ìƒì„¸ ìƒíƒœ ì—…ë°ì´íŠ¸ ê±´ë„ˆëœ€ (ì¤‘ë³µ ë°©ì§€)")
  }

  /// ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ í‘œì‹œ ë·° ì—…ë°ì´íŠ¸ (ë¹„í™œì„±í™” - ì¤‘ë³µ ë°©ì§€)
  private func updateStreamingStatusView() {
    // StreamingStatusView ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ì¤‘ë³µ ë°©ì§€)
    // ìž‘ì€ ë¼ì´ë¸Œ í‘œì‹œë§Œ ì‚¬ìš©
    print("ðŸ“Š [CameraPreview] ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ë·° ì—…ë°ì´íŠ¸ ê±´ë„ˆëœ€ (ì¤‘ë³µ ë°©ì§€)")
  }

  /// ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ëª¨ë‹ˆí„°ë§ ì„¤ì •
  private func setupStatusMonitoring() {
    // ê¸°ì¡´ íƒ€ì´ë¨¸ ì •ë¦¬
    statusMonitorTimer?.invalidate()

    // ìƒˆ íƒ€ì´ë¨¸ ì„¤ì • (1ì´ˆë§ˆë‹¤ ìƒíƒœ í™•ì¸)
    statusMonitorTimer = Timer.scheduledTimer(withTimeInterval: 1.0, repeats: true) {
      [weak self] _ in
      self?.updateStreamingStatus()
    }
  }

  /// ì •ë¦¬ ìž‘ì—…
  deinit {
    statusMonitorTimer?.invalidate()
  }

  /// í”„ë¦¬ë·° ë ˆì´ì–´ ê°•ì œ ìƒˆë¡œê³ ì¹¨ (ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ë³€í™” ì‹œ)
  func refreshPreviewLayer() {
    print("ðŸ”„ [CameraPreview] í”„ë¦¬ë·° ë ˆì´ì–´ ìƒˆë¡œê³ ì¹¨ ì‹œìž‘ (ìŠ¤íŠ¸ë¦¬ë°: \(isStreaming))")

    guard let session = captureSession else {
      print("âŒ [CameraPreview] ìº¡ì²˜ ì„¸ì…˜ì´ ì—†ì–´ ìƒˆë¡œê³ ì¹¨ ì‹¤íŒ¨")
      return
    }

    // ê¸°ì¡´ í”„ë¦¬ë·° ë ˆì´ì–´ ì™„ì „ ì œê±°
    previewLayer?.removeFromSuperlayer()
    previewLayer = nil
    hkPreviewLayer?.removeFromSuperview()
    hkPreviewLayer = nil

    // ìž ì‹œ ëŒ€ê¸° í›„ ìƒíƒœì— ë§žëŠ” í”„ë¦¬ë·° ë ˆì´ì–´ ìƒì„±
    DispatchQueue.main.asyncAfter(deadline: .now() + 0.1) { [weak self] in
      guard let self = self else { return }

      print("ðŸŽ¥ [CameraPreview] AVFoundation í”„ë¦¬ë·° ì„¤ì •")
      self.setupAVFoundationPreview(with: session)

      if self.isStreaming {
        print("ðŸŽ¥ [CameraPreview] ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì¶”ê°€")
        self.addStreamingIndicator()
      }

      print("âœ… [CameraPreview] í”„ë¦¬ë·° ë ˆì´ì–´ ìƒˆë¡œê³ ì¹¨ ì™„ë£Œ")
    }
  }

  private func setupAVFoundationPreview(with session: AVCaptureSession) {
    print("ðŸŽ¥ [CameraPreview] AVFoundation í”„ë¦¬ë·° ë ˆì´ì–´ ì„¤ì • ì¤‘...")

    let newPreviewLayer = AVCaptureVideoPreviewLayer(session: session)
    newPreviewLayer.frame = bounds
    newPreviewLayer.videoGravity = .resizeAspect

    if #available(iOS 17.0, *) {
      newPreviewLayer.connection?.videoRotationAngle = 0
    } else {
      newPreviewLayer.connection?.videoOrientation = .portrait
    }

    layer.insertSublayer(newPreviewLayer, at: 0)
    previewLayer = newPreviewLayer

    print("âœ… [CameraPreview] AVFoundation í”„ë¦¬ë·° ë ˆì´ì–´ ì„¤ì • ì™„ë£Œ")
  }

  override func layoutSubviews() {
    super.layoutSubviews()

    // í”„ë¦¬ë·° ë ˆì´ì–´ í”„ë ˆìž„ ì—…ë°ì´íŠ¸
    DispatchQueue.main.async { [weak self] in
      guard let self = self else { return }
      self.previewLayer?.frame = self.bounds
      self.hkPreviewLayer?.frame = self.bounds

      // ë ˆì´ì–´ê°€ ì˜¬ë°”ë¥´ê²Œ í‘œì‹œë˜ë„ë¡ ê°•ì œ ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸
      if let layer = self.previewLayer {
        layer.setNeedsLayout()
        layer.layoutIfNeeded()
      }
    }
  }

  // MARK: - Gesture Handlers

  @objc private func handleFocusTap(_ gesture: UITapGestureRecognizer) {
    let point = gesture.location(in: self)
    let focusPoint = CGPoint(
      x: point.x / bounds.width,
      y: point.y / bounds.height
    )

    setFocusPoint(focusPoint)
    showFocusIndicator(at: point)
  }

  @objc private func handleExposureDoubleTap(_ gesture: UITapGestureRecognizer) {
    let point = gesture.location(in: self)
    let exposurePoint = CGPoint(
      x: point.x / bounds.width,
      y: point.y / bounds.height
    )

    setExposurePoint(exposurePoint)
    showExposureIndicator(at: point)
  }

  @objc private func handleZoomPinch(_ gesture: UIPinchGestureRecognizer) {
    guard let device = getCurrentCameraDevice() else { return }

    do {
      try device.lockForConfiguration()

      let maxZoom = min(device.activeFormat.videoMaxZoomFactor, 4.0)
      let currentZoom = device.videoZoomFactor
      let newZoom = currentZoom * gesture.scale

      device.videoZoomFactor = max(1.0, min(newZoom, maxZoom))

      device.unlockForConfiguration()
      gesture.scale = 1.0

    } catch {
      print("âŒ Zoom adjustment failed: \(error)")
    }
  }

  // MARK: - Camera Control Methods

  private func setFocusPoint(_ point: CGPoint) {
    guard let device = getCurrentCameraDevice() else { return }

    do {
      try device.lockForConfiguration()

      if device.isFocusPointOfInterestSupported {
        device.focusPointOfInterest = point
        device.focusMode = .autoFocus
      }

      if device.isExposurePointOfInterestSupported {
        device.exposurePointOfInterest = point
        device.exposureMode = .autoExpose
      }

      device.unlockForConfiguration()
    } catch {
      print("âŒ Focus adjustment failed: \(error)")
    }
  }

  private func setExposurePoint(_ point: CGPoint) {
    guard let device = getCurrentCameraDevice() else { return }

    do {
      try device.lockForConfiguration()

      if device.isExposurePointOfInterestSupported {
        device.exposurePointOfInterest = point
        device.exposureMode = .continuousAutoExposure
      }

      device.unlockForConfiguration()
    } catch {
      print("âŒ Exposure adjustment failed: \(error)")
    }
  }

  private func getCurrentCameraDevice() -> AVCaptureDevice? {
    return captureSession?.inputs.compactMap { input in
      (input as? AVCaptureDeviceInput)?.device
    }.first { $0.hasMediaType(.video) }
  }

  // MARK: - Visual Feedback

  private func showFocusIndicator(at point: CGPoint) {
    let indicator = FocusIndicatorView(frame: CGRect(x: 0, y: 0, width: 80, height: 80))
    indicator.center = point
    addSubview(indicator)

    indicator.animate {
      DispatchQueue.main.asyncAfter(deadline: .now() + 1.5) {
        indicator.removeFromSuperview()
      }
    }
  }

  private func showExposureIndicator(at point: CGPoint) {
    let indicator = ExposureIndicatorView(frame: CGRect(x: 0, y: 0, width: 60, height: 60))
    indicator.center = point
    addSubview(indicator)

    indicator.animate {
      DispatchQueue.main.asyncAfter(deadline: .now() + 1.5) {
        indicator.removeFromSuperview()
      }
    }
  }

  // MARK: - Streaming State Management

  func updateStreamingState(_ isStreaming: Bool) {
    self.isStreaming = isStreaming
    streamingStatusView.isHidden = !isStreaming
    updatePreviewLayer()
  }

  func updateStreamingStats(_ stats: StreamStats) {
    streamingStatusView.updateStats(stats)
  }

  // MARK: - Screen Capture for Streaming

  /// CameraPreviewUIViewì˜ í™”ë©´ ìº¡ì²˜ ì†¡ì¶œ ê¸°ëŠ¥
  /// 
  /// ì´ ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ìœ¼ë¡œ ë™ìž‘í•©ë‹ˆë‹¤:
  /// 1. ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í”„ë ˆìž„ì„ CVPixelBufferë¡œ ìº¡ì²˜
  /// 2. UI ì˜¤ë²„ë ˆì´(ë²„íŠ¼, ë¼ë²¨, ì›Œí„°ë§ˆí¬ ë“±)ë¥¼ ë³„ë„ë¡œ ë Œë”ë§
  /// 3. ì¹´ë©”ë¼ í”„ë ˆìž„ê³¼ UIë¥¼ í•©ì„±í•˜ì—¬ ìµœì¢… ì´ë¯¸ì§€ ìƒì„±
  /// 4. 30fpsë¡œ HaishinKitì„ í†µí•´ ìŠ¤íŠ¸ë¦¬ë° ì„œë²„ì— ì „ì†¡
  ///
  /// **ì£¼ì˜ì‚¬í•­:**
  /// - ì¹´ë©”ë¼ í”„ë ˆìž„ì´ ì—†ì„ ê²½ìš° UIë§Œ ìº¡ì²˜ë©ë‹ˆë‹¤
  /// - AVCaptureVideoPreviewLayerëŠ” í•˜ë“œì›¨ì–´ ê°€ì† ë ˆì´ì–´ì´ë¯€ë¡œ ì§ì ‘ ìº¡ì²˜ê°€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤
  /// - ë”°ë¼ì„œ AVCaptureVideoDataOutputì—ì„œ ë°›ì€ ì‹¤ì œ ì¹´ë©”ë¼ í”„ë ˆìž„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤

  /// í™”ë©´ ìº¡ì²˜ ì†¡ì¶œ ì‹œìž‘
  /// 
  /// 30fps íƒ€ì´ë¨¸ë¥¼ ì‹œìž‘í•˜ì—¬ ì§€ì†ì ìœ¼ë¡œ í™”ë©´ì„ ìº¡ì²˜í•˜ê³  ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.
  /// ì¹´ë©”ë¼ í”„ë ˆìž„ê³¼ UIë¥¼ í•©ì„±í•œ ì™„ì „í•œ í™”ë©´ì´ ì†¡ì¶œë©ë‹ˆë‹¤.
  func startScreenCapture() {
    guard !isScreenCapturing else { 
      print("âš ï¸ [CameraPreview] ì´ë¯¸ í™”ë©´ ìº¡ì²˜ê°€ ì§„í–‰ ì¤‘ìž…ë‹ˆë‹¤")
      return 
    }

    isScreenCapturing = true
    print("ðŸŽ¬ [CameraPreview] í™”ë©´ ìº¡ì²˜ ì†¡ì¶œ ì‹œìž‘ - ì¹´ë©”ë¼ í”„ë ˆìž„ + UI í•©ì„± ëª¨ë“œ")

    // 30fpsë¡œ í™”ë©´ ìº¡ì²˜ (1ì´ˆì— 30ë²ˆ ìº¡ì²˜)
    // ë” ë†’ì€ í”„ë ˆìž„ìœ¨ì€ ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ 30fpsë¡œ ì œí•œ
    screenCaptureTimer = Timer.scheduledTimer(withTimeInterval: 1.0 / 30.0, repeats: true) {
      [weak self] _ in
      self?.captureCurrentFrame()
    }
    
    print("âœ… [CameraPreview] í™”ë©´ ìº¡ì²˜ íƒ€ì´ë¨¸ ì‹œìž‘ë¨ (30fps)")
  }
  
  /// í™”ë©´ ìº¡ì²˜ ì†¡ì¶œ ì¤‘ì§€
  /// 
  /// íƒ€ì´ë¨¸ë¥¼ ì¤‘ì§€í•˜ê³  ìº¡ì²˜ëœ í”„ë ˆìž„ ë°ì´í„°ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
  func stopScreenCapture() {
    guard isScreenCapturing else { 
      print("âš ï¸ [CameraPreview] í™”ë©´ ìº¡ì²˜ê°€ ì‹¤í–‰ ì¤‘ì´ì§€ ì•ŠìŠµë‹ˆë‹¤")
      return 
    }

    isScreenCapturing = false
    screenCaptureTimer?.invalidate()
    screenCaptureTimer = nil
    
    // ë©”ëª¨ë¦¬ ì •ë¦¬: ìµœê·¼ ìº¡ì²˜ëœ ì¹´ë©”ë¼ í”„ë ˆìž„ ì œê±°
    frameProcessingQueue.async { [weak self] in
      self?.latestCameraFrame = nil
    }
    
    print("ðŸŽ¬ [CameraPreview] í™”ë©´ ìº¡ì²˜ ì†¡ì¶œ ì¤‘ì§€ ë° ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
  }

  /// í˜„ìž¬ í”„ë ˆìž„ ìº¡ì²˜ ë° HaishinKit ì „ì†¡
  /// 
  /// ì´ ë©”ì„œë“œëŠ” 30fps íƒ€ì´ë¨¸ì— ì˜í•´ í˜¸ì¶œë˜ë©°, ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤:
  /// 1. ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ UI ë Œë”ë§ ìˆ˜í–‰
  /// 2. ì¹´ë©”ë¼ í”„ë ˆìž„ê³¼ UIë¥¼ í•©ì„±í•˜ì—¬ ìµœì¢… ì´ë¯¸ì§€ ìƒì„±
  /// 3. UIImageë¥¼ CVPixelBufferë¡œ ë³€í™˜
  /// 4. HaishinKitì„ í†µí•´ ìŠ¤íŠ¸ë¦¬ë° ì„œë²„ì— ì „ì†¡
  private func captureCurrentFrame() {
    DispatchQueue.main.async { [weak self] in
      guard let self = self else { return }

      // í™”ë©´ ìº¡ì²˜ ìƒíƒœ ìž¬í™•ì¸ (íƒ€ì´ë¨¸ ì§€ì—°ìœ¼ë¡œ ì¸í•œ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€)
      guard self.isScreenCapturing else { return }

      // Step 1: í˜„ìž¬ í™”ë©´ì„ ì´ë¯¸ì§€ë¡œ ë Œë”ë§ (ì¹´ë©”ë¼ í”„ë ˆìž„ + UI í•©ì„±)
      guard let capturedImage = self.renderToImage() else {
        print("âŒ [í™”ë©´ìº¡ì²˜] UIImage ë Œë”ë§ ì‹¤íŒ¨ - í”„ë ˆìž„ ìŠ¤í‚µ")
        return
      }
      
      print("âœ… [í™”ë©´ìº¡ì²˜] í™”ë©´ ë Œë”ë§ ì„±ê³µ: \(capturedImage.size)")

      // Step 2: UIImageë¥¼ CVPixelBufferë¡œ ë³€í™˜ (HaishinKit í˜¸í™˜ í¬ë§·)
      guard let pixelBuffer = capturedImage.toCVPixelBuffer() else {
        print("âŒ [í™”ë©´ìº¡ì²˜] CVPixelBuffer ë³€í™˜ ì‹¤íŒ¨ - í”„ë ˆìž„ ìŠ¤í‚µ")
        return
      }
      
      let width = CVPixelBufferGetWidth(pixelBuffer)
      let height = CVPixelBufferGetHeight(pixelBuffer)
      print("âœ… [í™”ë©´ìº¡ì²˜] CVPixelBuffer ë³€í™˜ ì„±ê³µ: \(width)x\(height)")

      // Step 3: HaishinKitì„ í†µí•´ ìŠ¤íŠ¸ë¦¬ë° ì„œë²„ì— ì „ì†¡
      self.sendFrameToHaishinKit(pixelBuffer)
    }
  }

  /// UIViewë¥¼ UIImageë¡œ ë Œë”ë§ (ì¹´ë©”ë¼ í”„ë ˆìž„ + UI í•©ì„±)
  /// 
  /// ì´ ë©”ì„œë“œëŠ” í™”ë©´ ìº¡ì²˜ì˜ í•µì‹¬ ë¡œì§ìž…ë‹ˆë‹¤:
  /// - ì¹´ë©”ë¼ í”„ë ˆìž„ì´ ìžˆìœ¼ë©´: ì¹´ë©”ë¼ ì˜ìƒ + UI ì˜¤ë²„ë ˆì´ í•©ì„±
  /// - ì¹´ë©”ë¼ í”„ë ˆìž„ì´ ì—†ìœ¼ë©´: UIë§Œ ìº¡ì²˜ (ê¸°ë³¸ ë ˆì´ì–´ ë Œë”ë§)
  ///
  /// **ê¸°ìˆ ì  ë°°ê²½:**
  /// AVCaptureVideoPreviewLayerëŠ” í•˜ë“œì›¨ì–´ ê°€ì†ì„ ì‚¬ìš©í•˜ë¯€ë¡œ 
  /// ì¼ë°˜ì ì¸ layer.render() ë°©ì‹ìœ¼ë¡œëŠ” ìº¡ì²˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
  /// ë”°ë¼ì„œ AVCaptureVideoDataOutputì—ì„œ ë°›ì€ ì‹¤ì œ í”„ë ˆìž„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
  ///
  /// - Returns: ìº¡ì²˜ëœ ìµœì¢… ì´ë¯¸ì§€ (ì¹´ë©”ë¼ + UI í•©ì„±) ë˜ëŠ” nil
  private func renderToImage() -> UIImage? {
    let size = bounds.size
    guard size.width > 0 && size.height > 0 else { 
      print("âŒ [ë Œë”ë§] ìœ íš¨í•˜ì§€ ì•Šì€ ë·° í¬ê¸°: \(size)")
      return nil 
    }
    
    // ìµœê·¼ ì¹´ë©”ë¼ í”„ë ˆìž„ì´ ìžˆëŠ”ì§€ í™•ì¸
    if let cameraFrame = latestCameraFrame {
      // ì¼€ì´ìŠ¤ 1: ì¹´ë©”ë¼ í”„ë ˆìž„ + UI í•©ì„± (ê¶Œìž¥ ëª¨ë“œ)
      print("ðŸŽ¥ [ë Œë”ë§] ì¹´ë©”ë¼ í”„ë ˆìž„ + UI í•©ì„± ëª¨ë“œ")
      return renderCameraFrameWithUI(cameraFrame: cameraFrame, viewSize: size)
    } else {
      // ì¼€ì´ìŠ¤ 2: UIë§Œ ìº¡ì²˜ (ì¹´ë©”ë¼ í”„ë ˆìž„ ì—†ìŒ - í´ë°± ëª¨ë“œ)
      print("ðŸ“± [ë Œë”ë§] UIë§Œ ìº¡ì²˜ ëª¨ë“œ (ì¹´ë©”ë¼ í”„ë ˆìž„ ì—†ìŒ)")
      let renderer = UIGraphicsImageRenderer(bounds: bounds)
      return renderer.image { context in
        layer.render(in: context.cgContext)
      }
    }
  }
  
  /// ì¹´ë©”ë¼ í”„ë ˆìž„ê³¼ UIë¥¼ í•©ì„±í•˜ì—¬ ìµœì¢… ì´ë¯¸ì§€ ìƒì„±
  /// 
  /// ì´ ë©”ì„œë“œëŠ” ë‹¤ìŒ 3ë‹¨ê³„ë¡œ ì´ë¯¸ì§€ë¥¼ í•©ì„±í•©ë‹ˆë‹¤:
  /// 1. CVPixelBuffer(ì¹´ë©”ë¼ í”„ë ˆìž„)ë¥¼ UIImageë¡œ ë³€í™˜
  /// 2. UI ì„œë¸Œë·°ë“¤ì„ ë³„ë„ ì´ë¯¸ì§€ë¡œ ë Œë”ë§ (ì˜¤ë²„ë ˆì´)
  /// 3. ì¹´ë©”ë¼ ì´ë¯¸ì§€ ìœ„ì— UI ì˜¤ë²„ë ˆì´ë¥¼ í•©ì„±
  ///
  /// **í•©ì„± ë°©ì‹:**
  /// - ì¹´ë©”ë¼ ì´ë¯¸ì§€: aspect fitìœ¼ë¡œ ë°°ì¹˜ (ë¹„ìœ¨ ìœ ì§€)
  /// - UI ì˜¤ë²„ë ˆì´: ì „ì²´ í™”ë©´ì— normal ë¸”ë Œë“œ ëª¨ë“œë¡œ í•©ì„±
  ///
  /// - Parameter cameraFrame: ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í”„ë ˆìž„ (CVPixelBuffer)
  /// - Parameter viewSize: ìµœì¢… ì¶œë ¥ ì´ë¯¸ì§€ í¬ê¸°
  /// - Returns: í•©ì„±ëœ ìµœì¢… ì´ë¯¸ì§€ ë˜ëŠ” nil
  private func renderCameraFrameWithUI(cameraFrame: CVPixelBuffer, viewSize: CGSize) -> UIImage? {
    
    // Step 1: ì¹´ë©”ë¼ í”„ë ˆìž„ì„ UIImageë¡œ ë³€í™˜
    guard let cameraImage = cameraFrame.toUIImage() else {
      print("âŒ [í•©ì„±] ì¹´ë©”ë¼ í”„ë ˆìž„ â†’ UIImage ë³€í™˜ ì‹¤íŒ¨")
      return nil
    }
    print("âœ… [í•©ì„±] ì¹´ë©”ë¼ ì´ë¯¸ì§€ ë³€í™˜ ì„±ê³µ: \(cameraImage.size)")
    
    // Step 2: UI ì˜¤ë²„ë ˆì´ ìƒì„± (ì¹´ë©”ë¼ í”„ë¦¬ë·° ë ˆì´ì–´ ì œì™¸)
    // ëª¨ë“  ì„œë¸Œë·°(ë²„íŠ¼, ë¼ë²¨, ì›Œí„°ë§ˆí¬ ë“±)ë¥¼ ë³„ë„ ì´ë¯¸ì§€ë¡œ ë Œë”ë§
    let uiRenderer = UIGraphicsImageRenderer(size: viewSize)
    let uiOverlay = uiRenderer.image { context in
      // í”„ë¦¬ë·° ë ˆì´ì–´ë¥¼ ì œì™¸í•œ ëª¨ë“  ì„œë¸Œë·° ë Œë”ë§
      // (ì¹´ë©”ë¼ í”„ë¦¬ë·°ëŠ” ì´ë¯¸ cameraImageì— í¬í•¨ë˜ì–´ ìžˆìŒ)
      for subview in subviews {
        subview.layer.render(in: context.cgContext)
      }
    }
    print("âœ… [í•©ì„±] UI ì˜¤ë²„ë ˆì´ ìƒì„± ì™„ë£Œ")
    
    // Step 3: ì¹´ë©”ë¼ ì´ë¯¸ì§€ì™€ UI ì˜¤ë²„ë ˆì´ í•©ì„±
    let finalRenderer = UIGraphicsImageRenderer(size: viewSize)
    let compositeImage = finalRenderer.image { context in
      let rect = CGRect(origin: .zero, size: viewSize)
      
      // 3-1: ì¹´ë©”ë¼ ì´ë¯¸ì§€ë¥¼ ë·° í¬ê¸°ì— ë§žê²Œ ê·¸ë¦¬ê¸° (aspect fit ìœ ì§€)
      // AVMakeRect: ì›ë³¸ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ ì£¼ì–´ì§„ ì˜ì—­ì— ë§žì¶¤
      let aspectFitRect = AVMakeRect(aspectRatio: cameraImage.size, insideRect: rect)
      cameraImage.draw(in: aspectFitRect)
      
      // 3-2: UI ì˜¤ë²„ë ˆì´ë¥¼ ì „ì²´ í™”ë©´ì— í•©ì„±
      // normal ë¸”ë Œë“œ ëª¨ë“œ: íˆ¬ëª… ì˜ì—­ì€ ê·¸ëŒ€ë¡œ ë‘ê³  ë¶ˆíˆ¬ëª… ì˜ì—­ë§Œ ë®ì–´ì”€
      uiOverlay.draw(in: rect, blendMode: .normal, alpha: 1.0)
    }
    
    print("âœ… [í•©ì„±] ìµœì¢… ì´ë¯¸ì§€ í•©ì„± ì™„ë£Œ: \(viewSize)")
    return compositeImage
  }

  /// CVPixelBufferë¥¼ HaishinKitì— ì „ë‹¬í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë°
  /// 
  /// ìº¡ì²˜ëœ í”„ë ˆìž„ì„ HaishinKitì˜ ìˆ˜ë™ í”„ë ˆìž„ ì „ì†¡ ê¸°ëŠ¥ì„ í†µí•´
  /// ìŠ¤íŠ¸ë¦¬ë° ì„œë²„ë¡œ ì „ì†¡í•©ë‹ˆë‹¤.
  ///
  /// **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§:**
  /// - 5ì´ˆë§ˆë‹¤ ì „ì†¡ í†µê³„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤
  /// - ì„±ê³µ/ì‹¤íŒ¨ ì¹´ìš´íŠ¸ì™€ í˜„ìž¬ FPSë¥¼ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤
  ///
  /// - Parameter pixelBuffer: ì „ì†¡í•  í”„ë ˆìž„ ë°ì´í„°
  private func sendFrameToHaishinKit(_ pixelBuffer: CVPixelBuffer) {
    let width = CVPixelBufferGetWidth(pixelBuffer)
    let height = CVPixelBufferGetHeight(pixelBuffer)

    print("ðŸ“¡ [ì „ì†¡] HaishinKit í”„ë ˆìž„ ì „ë‹¬: \(width)x\(height)")

    // HaishinKitManagerë¥¼ í†µí•œ ì‹¤ì œ í”„ë ˆìž„ ì „ì†¡
    if let manager = haishinKitManager {
      manager.sendManualFrame(pixelBuffer)

      // ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§: 5ì´ˆë§ˆë‹¤ ì „ì†¡ í†µê³„ ì¶œë ¥
      if Int(Date().timeIntervalSince1970) % 5 == 0 {
        let stats = manager.getScreenCaptureStats()
        print("""
        ðŸ“Š [í™”ë©´ìº¡ì²˜ í†µê³„] 
        - í˜„ìž¬ FPS: \(String(format: "%.1f", stats.currentFPS))
        - ì„±ê³µ ì „ì†¡: \(stats.successCount)í”„ë ˆìž„
        - ì‹¤íŒ¨ ì „ì†¡: \(stats.failureCount)í”„ë ˆìž„
        """)
      }
    } else {
      print("âš ï¸ [ì „ì†¡] HaishinKitManager ì—†ìŒ - í”„ë ˆìž„ ì „ë‹¬ ë¶ˆê°€")
    }
  }

  /// í™”ë©´ ìº¡ì²˜ ìƒíƒœì™€ í†µê³„ í™•ì¸ (ê³µê°œ ë©”ì„œë“œ)
  public func getScreenCaptureStatus() -> (isCapturing: Bool, stats: String?) {
    let stats = haishinKitManager?.getScreenCaptureStats()
    return (isScreenCapturing, stats?.summary)
  }

  /// í™”ë©´ ìº¡ì²˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
  public func testScreenCapturePerformance() {
    guard let manager = haishinKitManager else {
      print("âŒ HaishinKitManagerê°€ ì—†ìŒ")
      return
    }

    print("ðŸ§ª í™”ë©´ ìº¡ì²˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œìž‘...")
    manager.resetScreenCaptureStats()

    // 10í”„ë ˆìž„ ì—°ì† ì „ì†¡ í…ŒìŠ¤íŠ¸
    for i in 1...10 {
      DispatchQueue.main.asyncAfter(deadline: .now() + Double(i) * 0.1) { [weak self] in
        if let image = self?.renderToImage(),
          let pixelBuffer = image.toCVPixelBuffer()
        {
          manager.sendManualFrame(pixelBuffer)

          if i == 10 {
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
              let stats = manager.getScreenCaptureStats()
              print("ðŸ§ª í…ŒìŠ¤íŠ¸ ì™„ë£Œ:")
              print(stats.summary)
            }
          }
        }
      }
    }
  }

  /// í™”ë©´ ìº¡ì²˜ ìƒíƒœ í™•ì¸
  var isCapturingScreen: Bool {
    return isScreenCapturing
  }

  // MARK: - Usage Example & Notes

  /*
   ì‚¬ìš© ì˜ˆì‹œ:
  
   1. ì¼ë°˜ ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¬ë°:
      try await haishinKitManager.startStreaming(with: settings, captureSession: captureSession)
  
   2. í™”ë©´ ìº¡ì²˜ ìŠ¤íŠ¸ë¦¬ë°:
      // Step 1: í™”ë©´ ìº¡ì²˜ ëª¨ë“œë¡œ ìŠ¤íŠ¸ë¦¬ë° ì‹œìž‘
      try await haishinKitManager.startScreenCaptureStreaming(with: settings)
  
      // Step 2: CameraPreviewUIViewì—ì„œ í™”ë©´ ìº¡ì²˜ ì‹œìž‘
      cameraPreviewUIView.startScreenCapture()
  
      // Step 3: ì¤‘ì§€í•  ë•Œ
      cameraPreviewUIView.stopScreenCapture()
      await haishinKitManager.stopStreaming()
  
   ì£¼ì˜ì‚¬í•­:
   - í™”ë©´ ìº¡ì²˜ëŠ” 30fpsë¡œ ë™ìž‘í•˜ë¯€ë¡œ ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤
   - UIView ë Œë”ë§ì€ ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ë˜ë¯€ë¡œ UI ë¸”ë¡œí‚¹ ê°€ëŠ¥ì„±ì´ ìžˆìŠµë‹ˆë‹¤
   - í™”ë©´ì— ë³´ì´ëŠ” ëª¨ë“  UI ìš”ì†Œ(ë²„íŠ¼, ë¼ë²¨ ë“±)ê°€ ì†¡ì¶œì— í¬í•¨ë©ë‹ˆë‹¤
   - ì‹¤ì œ HaishinKit manual capture êµ¬í˜„ì€ ì¶”ê°€ ìž‘ì—…ì´ í•„ìš”í•©ë‹ˆë‹¤
   */
}

// MARK: - CameraControlOverlayDelegate

extension CameraPreviewUIView: CameraControlOverlayDelegate {
  func didTapRecord() {
    // ë…¹í™” ê¸°ëŠ¥ì€ ì œì™¸
    print("ðŸ“¹ Recording functionality not implemented")
  }
}

// MARK: - AVCaptureVideoDataOutputSampleBufferDelegate

extension CameraPreviewUIView: AVCaptureVideoDataOutputSampleBufferDelegate {
  /// AVCaptureVideoDataOutputì—ì„œ í”„ë ˆìž„ì„ ë°›ëŠ” ë¸ë¦¬ê²Œì´íŠ¸ ë©”ì„œë“œ
  /// 
  /// **ì´ ë©”ì„œë“œì˜ ë‘ ê°€ì§€ ì—­í• :**
  /// 1. **í™”ë©´ ìº¡ì²˜ ëª¨ë“œ**: ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í”„ë ˆìž„ì„ ì €ìž¥í•˜ì—¬ UIì™€ í•©ì„±
  /// 2. **ì¼ë°˜ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ**: HaishinKitì— í”„ë ˆìž„ í†µê³„ ì •ë³´ ì „ë‹¬
  ///
  /// **ì„±ëŠ¥ ìµœì í™”:**
  /// - í™”ë©´ ìº¡ì²˜ ì¤‘ì¼ ë•Œë§Œ í”„ë ˆìž„ì„ ì €ìž¥í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì†Œí™”
  /// - ë°±ê·¸ë¼ìš´ë“œ íì—ì„œ í”„ë ˆìž„ ì €ìž¥ ìž‘ì—… ìˆ˜í–‰í•˜ì—¬ ë©”ì¸ ìŠ¤ë ˆë“œ ë¸”ë¡í‚¹ ë°©ì§€
  ///
  /// - Parameter output: ì¶œë ¥ ê°ì²´ (AVCaptureVideoDataOutput)
  /// - Parameter sampleBuffer: ì¹´ë©”ë¼ì—ì„œ ìº¡ì²˜ëœ í”„ë ˆìž„ ë°ì´í„°
  /// - Parameter connection: ìž…ë ¥ê³¼ ì¶œë ¥ ê°„ì˜ ì—°ê²° ì •ë³´
  func captureOutput(
    _ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer,
    from connection: AVCaptureConnection
  ) {
    // ðŸŽ¬ í™”ë©´ ìº¡ì²˜ ëª¨ë“œ: ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í”„ë ˆìž„ ì €ìž¥
    // UIì™€ í•©ì„±í•˜ê¸° ìœ„í•´ ìµœì‹  í”„ë ˆìž„ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì €ìž¥
    if isScreenCapturing {
      guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { 
        print("âš ï¸ [í”„ë ˆìž„ì €ìž¥] CMSampleBufferì—ì„œ pixelBuffer ì¶”ì¶œ ì‹¤íŒ¨")
        return 
      }
      
      // ë°±ê·¸ë¼ìš´ë“œ íì—ì„œ í”„ë ˆìž„ ì €ìž¥ (ë©”ì¸ ìŠ¤ë ˆë“œ ë¸”ë¡í‚¹ ë°©ì§€)
      frameProcessingQueue.async { [weak self] in
        self?.latestCameraFrame = pixelBuffer
        // print("âœ… [í”„ë ˆìž„ì €ìž¥] ìµœì‹  ì¹´ë©”ë¼ í”„ë ˆìž„ ì—…ë°ì´íŠ¸ë¨") // ë„ˆë¬´ ë¹ˆë²ˆí•œ ë¡œê·¸ëŠ” ì£¼ì„ ì²˜ë¦¬
      }
    }
    
    // ðŸ“¡ ì¼ë°˜ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ: HaishinKitì— í”„ë ˆìž„ í†µê³„ ì „ë‹¬
    // í™”ë©´ ìº¡ì²˜ê°€ ì•„ë‹Œ ì¼ë°˜ ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¬ë° ì‹œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ìš©
    guard isStreaming, let manager = haishinKitManager else { return }

    // HaishinKitì— í”„ë ˆìž„ í†µê³„ ì •ë³´ ì „ë‹¬ (ë¹„ë™ê¸° ì²˜ë¦¬)
    Task {
      await manager.processVideoFrame(sampleBuffer)
    }
  }

  func captureOutput(
    _ output: AVCaptureOutput, didDrop sampleBuffer: CMSampleBuffer,
    from connection: AVCaptureConnection
  ) {
    print("âš ï¸ [CameraPreview] ë¹„ë””ì˜¤ í”„ë ˆìž„ ë“œë¡­ë¨ - ì„±ëŠ¥ ìµœì í™” í•„ìš”í•  ìˆ˜ ìžˆìŒ")
  }
}

// MARK: - Supporting Views

/// ì¹´ë©”ë¼ ì»¨íŠ¸ë¡¤ ì˜¤ë²„ë ˆì´
protocol CameraControlOverlayDelegate: AnyObject {
  func didTapRecord()
}

final class CameraControlOverlay: UIView {
  weak var delegate: CameraControlOverlayDelegate?

  override init(frame: CGRect) {
    super.init(frame: frame)
    setupView()
  }

  required init?(coder: NSCoder) {
    super.init(coder: coder)
    setupView()
  }

  private func setupView() {
    // ë²„íŠ¼ë“¤ì„ ì œê±°í–ˆìœ¼ë¯€ë¡œ ë¹ˆ ë·°ë¡œ ì„¤ì •
  }
}

/// ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ í‘œì‹œ ë·°
final class StreamingStatusView: UIView {

  private lazy var containerView: UIView = {
    let view = UIView()
    view.backgroundColor = UIColor.red.withAlphaComponent(0.8)
    view.layer.cornerRadius = 8
    view.translatesAutoresizingMaskIntoConstraints = false
    return view
  }()

  private lazy var liveLabel: UILabel = {
    let label = UILabel()
    label.text = "ðŸ”´ LIVE"
    label.textColor = .white
    label.font = .boldSystemFont(ofSize: 14)
    label.translatesAutoresizingMaskIntoConstraints = false
    return label
  }()

  private lazy var statsLabel: UILabel = {
    let label = UILabel()
    label.textColor = .white
    label.font = .systemFont(ofSize: 12)
    label.numberOfLines = 2
    label.translatesAutoresizingMaskIntoConstraints = false
    return label
  }()

  override init(frame: CGRect) {
    super.init(frame: frame)
    setupView()
  }

  required init?(coder: NSCoder) {
    super.init(coder: coder)
    setupView()
  }

  private func setupView() {
    addSubview(containerView)
    containerView.addSubview(liveLabel)
    containerView.addSubview(statsLabel)

    NSLayoutConstraint.activate([
      containerView.topAnchor.constraint(equalTo: topAnchor),
      containerView.leadingAnchor.constraint(equalTo: leadingAnchor),
      containerView.trailingAnchor.constraint(equalTo: trailingAnchor),
      containerView.bottomAnchor.constraint(equalTo: bottomAnchor),

      liveLabel.topAnchor.constraint(equalTo: containerView.topAnchor, constant: 8),
      liveLabel.leadingAnchor.constraint(equalTo: containerView.leadingAnchor, constant: 8),
      liveLabel.trailingAnchor.constraint(equalTo: containerView.trailingAnchor, constant: -8),

      statsLabel.topAnchor.constraint(equalTo: liveLabel.bottomAnchor, constant: 4),
      statsLabel.leadingAnchor.constraint(equalTo: containerView.leadingAnchor, constant: 8),
      statsLabel.trailingAnchor.constraint(equalTo: containerView.trailingAnchor, constant: -8),
      statsLabel.bottomAnchor.constraint(equalTo: containerView.bottomAnchor, constant: -8),
    ])
  }

  func updateStatus(_ status: String) {
    liveLabel.text = status
  }

  /// ìž¬ì—°ê²° ìƒíƒœ ì—…ë°ì´íŠ¸
  func updateReconnectingStatus(_ attempt: Int, _ maxAttempts: Int, _ delay: Int) {
    liveLabel.text = "ðŸ”„ ìž¬ì—°ê²° ì¤‘"
    statsLabel.text = "ì‹œë„: \(attempt)/\(maxAttempts)\n\(delay)ì´ˆ í›„ ìž¬ì‹œë„"

    // ìž¬ì—°ê²° ì¤‘ì¼ ë•Œ ë°°ê²½ìƒ‰ì„ ì£¼í™©ìƒ‰ìœ¼ë¡œ ë³€ê²½
    containerView.backgroundColor = UIColor.orange.withAlphaComponent(0.8)
  }

  /// ì—°ê²° ì‹¤íŒ¨ ìƒíƒœ ì—…ë°ì´íŠ¸
  func updateFailedStatus(_ message: String) {
    liveLabel.text = "âŒ ì—°ê²° ì‹¤íŒ¨"
    statsLabel.text = message

    // ì‹¤íŒ¨ ì‹œ ë°°ê²½ìƒ‰ì„ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ ë³€ê²½
    containerView.backgroundColor = UIColor.red.withAlphaComponent(0.8)
  }

  /// ì •ìƒ ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœë¡œ ë³µì›
  func updateStreamingStatus() {
    liveLabel.text = "ðŸ”´ LIVE"

    // ì •ìƒ ìƒíƒœë¡œ ë°°ê²½ìƒ‰ ë³µì›
    containerView.backgroundColor = UIColor.red.withAlphaComponent(0.8)
  }

  func updateStats(_ stats: StreamStats) {
    let duration = formatDuration(Int(stats.duration))
    statsLabel.text = "\(duration)\n\(Int(stats.videoBitrate))kbps"
  }

  private func formatDuration(_ seconds: Int) -> String {
    let hours = seconds / 3600
    let minutes = (seconds % 3600) / 60
    let secs = seconds % 60

    if hours > 0 {
      return String(format: "%02d:%02d:%02d", hours, minutes, secs)
    } else {
      return String(format: "%02d:%02d", minutes, secs)
    }
  }
}

/// í¬ì»¤ìŠ¤ ì¸ë””ì¼€ì´í„° ë·°
final class FocusIndicatorView: UIView {

  override init(frame: CGRect) {
    super.init(frame: frame)
    setupView()
  }

  required init?(coder: NSCoder) {
    super.init(coder: coder)
    setupView()
  }

  private func setupView() {
    backgroundColor = .clear
    layer.borderColor = UIColor.yellow.cgColor
    layer.borderWidth = 2
    alpha = 0
  }

  func animate(completion: @escaping () -> Void) {
    UIView.animate(
      withDuration: 0.2,
      animations: {
        self.alpha = 1.0
        self.transform = CGAffineTransform(scaleX: 1.2, y: 1.2)
      }
    ) { _ in
      UIView.animate(
        withDuration: 0.3,
        animations: {
          self.alpha = 0.8
          self.transform = CGAffineTransform.identity
        }
      ) { _ in
        UIView.animate(
          withDuration: 1.0,
          animations: {
            self.alpha = 0
          },
          completion: { _ in
            completion()
          })
      }
    }
  }
}

/// ë…¸ì¶œ ì¸ë””ì¼€ì´í„° ë·°
final class ExposureIndicatorView: UIView {

  override init(frame: CGRect) {
    super.init(frame: frame)
    setupView()
  }

  required init?(coder: NSCoder) {
    super.init(coder: coder)
    setupView()
  }

  private func setupView() {
    backgroundColor = .clear
    layer.borderColor = UIColor.orange.cgColor
    layer.borderWidth = 2
    layer.cornerRadius = 30
    alpha = 0

    let sunIcon = UILabel()
    sunIcon.text = "â˜€ï¸"
    sunIcon.font = .systemFont(ofSize: 24)
    sunIcon.textAlignment = .center
    sunIcon.translatesAutoresizingMaskIntoConstraints = false
    addSubview(sunIcon)

    NSLayoutConstraint.activate([
      sunIcon.centerXAnchor.constraint(equalTo: centerXAnchor),
      sunIcon.centerYAnchor.constraint(equalTo: centerYAnchor),
    ])
  }

  func animate(completion: @escaping () -> Void) {
    UIView.animate(
      withDuration: 0.2,
      animations: {
        self.alpha = 1.0
        self.transform = CGAffineTransform(scaleX: 1.1, y: 1.1)
      }
    ) { _ in
      UIView.animate(
        withDuration: 0.3,
        animations: {
          self.alpha = 0.8
          self.transform = CGAffineTransform.identity
        }
      ) { _ in
        UIView.animate(
          withDuration: 1.0,
          animations: {
            self.alpha = 0
          },
          completion: { _ in
            completion()
          })
      }
    }
  }
}

// MARK: - Extensions

/// CVPixelBufferë¥¼ UIImageë¡œ ë³€í™˜í•˜ëŠ” í™•ìž¥
/// 
/// **ìš©ë„:**
/// - ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í”„ë ˆìž„(CVPixelBuffer)ì„ UI í•©ì„±ì´ ê°€ëŠ¥í•œ UIImageë¡œ ë³€í™˜
/// - AVCaptureVideoDataOutputì—ì„œ ë°›ì€ í”„ë ˆìž„ì„ í™”ë©´ ìº¡ì²˜ ì‹œ ì‚¬ìš©
///
/// **ë³€í™˜ ê³¼ì •:**
/// 1. CVPixelBuffer â†’ CIImage ë³€í™˜
/// 2. CIImage â†’ CGImage ë³€í™˜ (Core Graphics í˜¸í™˜)
/// 3. CGImage â†’ UIImage ë³€í™˜ (UIKit í˜¸í™˜)
extension CVPixelBuffer {
  
  /// CVPixelBufferë¥¼ UIImageë¡œ ë³€í™˜
  /// 
  /// Core Image í”„ë ˆìž„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í”½ì…€ ë²„í¼ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
  /// ì´ ê³¼ì •ì€ GPU ê°€ì†ì„ í™œìš©í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜í–‰ë©ë‹ˆë‹¤.
  ///
  /// **ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­:**
  /// - CIContextëŠ” GPU ë¦¬ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ìž¬ì‚¬ìš© ê¶Œìž¥
  /// - í˜„ìž¬ëŠ” ë§¤ë²ˆ ìƒˆë¡œ ìƒì„±í•˜ì§€ë§Œ, í–¥í›„ ìºì‹± ìµœì í™” ê°€ëŠ¥
  ///
  /// - Returns: ë³€í™˜ëœ UIImage ë˜ëŠ” ë³€í™˜ ì‹¤íŒ¨ ì‹œ nil
  func toUIImage() -> UIImage? {
    // Step 1: CVPixelBufferë¥¼ CIImageë¡œ ë³€í™˜
    // Core Imageê°€ í”½ì…€ ë²„í¼ë¥¼ ì§ì ‘ ì²˜ë¦¬í•  ìˆ˜ ìžˆëŠ” í˜•íƒœë¡œ ë³€í™˜
    let ciImage = CIImage(cvPixelBuffer: self)
    
    // Step 2: CIContext ìƒì„± (GPU ê°€ì† í™œìš©)
    // TODO: ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ ì „ì—­ CIContext ìºì‹± ê³ ë ¤
    let context = CIContext()
    
    // Step 3: CIImageë¥¼ CGImageë¡œ ë³€í™˜
    // extent: ì´ë¯¸ì§€ì˜ ì „ì²´ ì˜ì—­ì„ ì˜ë¯¸ (ì›ë³¸ í¬ê¸° ìœ ì§€)
    guard let cgImage = context.createCGImage(ciImage, from: ciImage.extent) else {
      print("âŒ [CVPixelBuffer] CIImage â†’ CGImage ë³€í™˜ ì‹¤íŒ¨")
      return nil
    }
    
    // Step 4: CGImageë¥¼ UIImageë¡œ ë³€í™˜ (UIKit í˜¸í™˜)
    // ìµœì¢…ì ìœ¼ë¡œ UIKitì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜ ì™„ë£Œ
    return UIImage(cgImage: cgImage)
  }
}

/// UIImageë¥¼ CVPixelBufferë¡œ ë³€í™˜í•˜ëŠ” í™•ìž¥
extension UIImage {
  func toCVPixelBuffer() -> CVPixelBuffer? {
    let attrs =
      [
        kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue,
        kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue,
        kCVPixelBufferIOSurfacePropertiesKey: [:],
      ] as CFDictionary

    var pixelBuffer: CVPixelBuffer?

    // BGRA í¬ë§· ì‚¬ìš© (HaishinKitê³¼ í˜¸í™˜ì„± í–¥ìƒ)
    let status = CVPixelBufferCreate(
      kCFAllocatorDefault,
      Int(size.width),
      Int(size.height),
      kCVPixelFormatType_32BGRA,
      attrs,
      &pixelBuffer
    )

    guard status == kCVReturnSuccess, let buffer = pixelBuffer else {
      print("âŒ [CVPixelBuffer] ìƒì„± ì‹¤íŒ¨: \(status)")
      return nil
    }

    CVPixelBufferLockBaseAddress(buffer, CVPixelBufferLockFlags(rawValue: 0))
    defer {
      CVPixelBufferUnlockBaseAddress(buffer, CVPixelBufferLockFlags(rawValue: 0))
    }

    let pixelData = CVPixelBufferGetBaseAddress(buffer)
    let rgbColorSpace = CGColorSpaceCreateDeviceRGB()
    let bytesPerRow = CVPixelBufferGetBytesPerRow(buffer)

    // BGRA í¬ë§·ì— ë§žëŠ” ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    guard
      let context = CGContext(
        data: pixelData,
        width: Int(size.width),
        height: Int(size.height),
        bitsPerComponent: 8,
        bytesPerRow: bytesPerRow,
        space: rgbColorSpace,
        bitmapInfo: CGImageAlphaInfo.noneSkipFirst.rawValue
          | CGBitmapInfo.byteOrder32Little.rawValue
      )
    else {
      print("âŒ [CVPixelBuffer] CGContext ìƒì„± ì‹¤íŒ¨")
      return nil
    }

    // ì´ë¯¸ì§€ ê·¸ë¦¬ê¸° (Yì¶• ë’¤ì§‘ê¸°)
    context.translateBy(x: 0, y: size.height)
    context.scaleBy(x: 1.0, y: -1.0)

    UIGraphicsPushContext(context)
    draw(in: CGRect(x: 0, y: 0, width: size.width, height: size.height))
    UIGraphicsPopContext()

    print("âœ… [CVPixelBuffer] ìƒì„± ì„±ê³µ: \(Int(size.width))x\(Int(size.height)) BGRA")
    return buffer
  }
}
